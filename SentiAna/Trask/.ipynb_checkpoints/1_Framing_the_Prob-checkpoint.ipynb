{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define path to the data\n",
    "path = \"/home/isaac/UdacityDL/SentiAna/Trask/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path+\"reviews.txt\", \"r+\") as file:\n",
    "    reviews = file.readlines() \n",
    "    ##use readlines as it will be separated by \\n; read will read the whole thing as one big chunk of array\n",
    "    file.close()\n",
    "\n",
    "with open(path+\"labels.txt\", \"r+\") as file:\n",
    "    labels = file.readlines()\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0]\n",
    "## Notice \\n at the end of each review[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]\n",
    "## Notice \\n at the end of each label[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_clean = list(map(lambda x: x[:-1], reviews))\n",
    "reviews_clean[0][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_clean = list(map(lambda x: x[:-1], labels))\n",
    "labels_clean[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Theory Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7651,  6937,  1758,  6160,  3795,  2629, 13605, 14809,  2278, 22792])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_rand = np.random.randint(0,len(reviews_clean),10)\n",
    "my_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative : a demented scientist girlfriend is decapitated so he brings her head back to life . honest this is t\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "negative : be warned . this movie is such a mess . it  s a catastrophe . don  t waste your time with this one .\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "positive : good show  very entertaining . good marshal arts acting . good story plot . the entire main crew did\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "positive : horror omnibus films were popular in the seventies . i  m not very fond of them myself  but this one\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "negative : blows my mind how this movie got made . i watched it while i worked at home writing emails and answe\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "negative :   people i know  is a clunker with no one to root for and no one to care about   despite the game ef\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "negative : this is definitely a stupid  bad  taste movie . eddie murphy stars in what is written like a sitcom \n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "negative : this movie is even a big step down form the typical fare dished out by bollywood . the performances \n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "positive : cliffhanger is a decent action crime adventure with some flaws from director renny harlin whose admi\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "positive : this is the best movie i  ve seen since white and the best romantic comedy i  ve seen since the hair\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for num in my_rand:\n",
    "    print(labels_clean[num]+\" : \"+reviews_clean[num][:100]+\"\\n\")\n",
    "    print(\"-\"*110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Initialization\n",
    "positive_count = Counter()\n",
    "negative_count = Counter()\n",
    "total_count = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(reviews)):\n",
    "    if(labels_clean[i] == \"positive\"):\n",
    "        for word in reviews[i].split(\" \"):\n",
    "            positive_count[word] += 1\n",
    "            total_count[word] += 1\n",
    "    else:\n",
    "        for word in reviews[i].split(\" \"):\n",
    "            negative_count[word] += 1\n",
    "            total_count[word] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 537968),\n",
       " ('the', 173324),\n",
       " ('.', 159654),\n",
       " ('and', 89722),\n",
       " ('a', 83688),\n",
       " ('of', 76855),\n",
       " ('to', 66746),\n",
       " ('is', 57245),\n",
       " ('in', 50215),\n",
       " ('br', 49235),\n",
       " ('it', 48025),\n",
       " ('i', 40743),\n",
       " ('that', 35630),\n",
       " ('this', 35080),\n",
       " ('s', 33815),\n",
       " ('as', 26308),\n",
       " ('with', 23247),\n",
       " ('for', 22416),\n",
       " ('was', 21917),\n",
       " ('film', 20937),\n",
       " ('but', 20822),\n",
       " ('movie', 19074),\n",
       " ('his', 17227),\n",
       " ('on', 17008),\n",
       " ('you', 16681),\n",
       " ('he', 16282),\n",
       " ('are', 14807),\n",
       " ('not', 14272),\n",
       " ('t', 13720),\n",
       " ('one', 13655),\n",
       " ('have', 12587),\n",
       " ('\\n', 12500),\n",
       " ('be', 12416),\n",
       " ('by', 11997),\n",
       " ('all', 11942),\n",
       " ('who', 11464),\n",
       " ('an', 11294),\n",
       " ('at', 11234),\n",
       " ('from', 10767),\n",
       " ('her', 10474),\n",
       " ('they', 9895),\n",
       " ('has', 9186),\n",
       " ('so', 9154),\n",
       " ('like', 9038),\n",
       " ('about', 8313),\n",
       " ('very', 8305),\n",
       " ('out', 8134),\n",
       " ('there', 8057),\n",
       " ('she', 7779),\n",
       " ('what', 7737),\n",
       " ('or', 7732),\n",
       " ('good', 7720),\n",
       " ('more', 7521),\n",
       " ('when', 7456),\n",
       " ('some', 7441),\n",
       " ('if', 7285),\n",
       " ('just', 7152),\n",
       " ('can', 7001),\n",
       " ('story', 6780),\n",
       " ('time', 6515),\n",
       " ('my', 6488),\n",
       " ('great', 6419),\n",
       " ('well', 6405),\n",
       " ('up', 6321),\n",
       " ('which', 6267),\n",
       " ('their', 6107),\n",
       " ('see', 6026),\n",
       " ('also', 5550),\n",
       " ('we', 5531),\n",
       " ('really', 5476),\n",
       " ('would', 5400),\n",
       " ('will', 5218),\n",
       " ('me', 5167),\n",
       " ('had', 5148),\n",
       " ('only', 5137),\n",
       " ('him', 5018),\n",
       " ('even', 4964),\n",
       " ('most', 4864),\n",
       " ('other', 4858),\n",
       " ('were', 4782),\n",
       " ('first', 4755),\n",
       " ('than', 4736),\n",
       " ('much', 4685),\n",
       " ('its', 4622),\n",
       " ('no', 4574),\n",
       " ('into', 4544),\n",
       " ('people', 4479),\n",
       " ('best', 4319),\n",
       " ('love', 4301),\n",
       " ('get', 4272),\n",
       " ('how', 4213),\n",
       " ('life', 4199),\n",
       " ('been', 4189),\n",
       " ('because', 4079),\n",
       " ('way', 4036),\n",
       " ('do', 3941),\n",
       " ('made', 3823),\n",
       " ('films', 3813),\n",
       " ('them', 3805),\n",
       " ('after', 3800),\n",
       " ('many', 3766),\n",
       " ('two', 3733),\n",
       " ('too', 3659),\n",
       " ('think', 3655),\n",
       " ('movies', 3586),\n",
       " ('characters', 3560),\n",
       " ('character', 3514),\n",
       " ('don', 3468),\n",
       " ('man', 3460),\n",
       " ('show', 3432),\n",
       " ('watch', 3424),\n",
       " ('seen', 3414),\n",
       " ('then', 3358),\n",
       " ('little', 3341),\n",
       " ('still', 3340),\n",
       " ('make', 3303),\n",
       " ('could', 3237),\n",
       " ('never', 3226),\n",
       " ('being', 3217),\n",
       " ('where', 3173),\n",
       " ('does', 3069),\n",
       " ('over', 3017),\n",
       " ('any', 3002),\n",
       " ('while', 2899),\n",
       " ('know', 2833),\n",
       " ('did', 2790),\n",
       " ('years', 2758),\n",
       " ('here', 2740),\n",
       " ('ever', 2734),\n",
       " ('end', 2696),\n",
       " ('these', 2694),\n",
       " ('such', 2590),\n",
       " ('real', 2568),\n",
       " ('scene', 2567),\n",
       " ('back', 2547),\n",
       " ('those', 2485),\n",
       " ('though', 2475),\n",
       " ('off', 2463),\n",
       " ('new', 2458),\n",
       " ('your', 2453),\n",
       " ('go', 2440),\n",
       " ('acting', 2437),\n",
       " ('plot', 2432),\n",
       " ('world', 2429),\n",
       " ('scenes', 2427),\n",
       " ('say', 2414),\n",
       " ('through', 2409),\n",
       " ('makes', 2390),\n",
       " ('better', 2381),\n",
       " ('now', 2368),\n",
       " ('work', 2346),\n",
       " ('young', 2343),\n",
       " ('old', 2311),\n",
       " ('ve', 2307),\n",
       " ('find', 2272),\n",
       " ('both', 2248),\n",
       " ('before', 2177),\n",
       " ('us', 2162),\n",
       " ('again', 2158),\n",
       " ('series', 2153),\n",
       " ('quite', 2143),\n",
       " ('something', 2135),\n",
       " ('cast', 2133),\n",
       " ('should', 2121),\n",
       " ('part', 2098),\n",
       " ('always', 2088),\n",
       " ('lot', 2087),\n",
       " ('another', 2075),\n",
       " ('actors', 2047),\n",
       " ('director', 2040),\n",
       " ('family', 2032),\n",
       " ('between', 2016),\n",
       " ('own', 2016),\n",
       " ('m', 1998),\n",
       " ('may', 1997),\n",
       " ('same', 1972),\n",
       " ('role', 1967),\n",
       " ('watching', 1966),\n",
       " ('every', 1954),\n",
       " ('funny', 1953),\n",
       " ('doesn', 1935),\n",
       " ('performance', 1928),\n",
       " ('few', 1918),\n",
       " ('bad', 1907),\n",
       " ('look', 1900),\n",
       " ('re', 1884),\n",
       " ('why', 1855),\n",
       " ('things', 1849),\n",
       " ('times', 1832),\n",
       " ('big', 1815),\n",
       " ('however', 1795),\n",
       " ('actually', 1790),\n",
       " ('action', 1789),\n",
       " ('going', 1783),\n",
       " ('bit', 1757),\n",
       " ('comedy', 1742),\n",
       " ('down', 1740),\n",
       " ('music', 1738),\n",
       " ('must', 1728),\n",
       " ('take', 1709),\n",
       " ('saw', 1692),\n",
       " ('long', 1690),\n",
       " ('right', 1688),\n",
       " ('fun', 1686),\n",
       " ('fact', 1684),\n",
       " ('excellent', 1683),\n",
       " ('around', 1674),\n",
       " ('didn', 1672),\n",
       " ('without', 1671),\n",
       " ('thing', 1662),\n",
       " ('thought', 1639),\n",
       " ('got', 1635),\n",
       " ('each', 1630),\n",
       " ('day', 1614),\n",
       " ('feel', 1597),\n",
       " ('seems', 1596),\n",
       " ('come', 1594),\n",
       " ('done', 1586),\n",
       " ('beautiful', 1580),\n",
       " ('especially', 1572),\n",
       " ('played', 1571),\n",
       " ('almost', 1566),\n",
       " ('want', 1562),\n",
       " ('yet', 1556),\n",
       " ('give', 1553),\n",
       " ('pretty', 1549),\n",
       " ('last', 1543),\n",
       " ('since', 1519),\n",
       " ('different', 1504),\n",
       " ('although', 1501),\n",
       " ('gets', 1490),\n",
       " ('true', 1487),\n",
       " ('interesting', 1481),\n",
       " ('job', 1470),\n",
       " ('enough', 1455),\n",
       " ('our', 1454),\n",
       " ('shows', 1447),\n",
       " ('horror', 1441),\n",
       " ('woman', 1439),\n",
       " ('tv', 1400),\n",
       " ('probably', 1398),\n",
       " ('father', 1395),\n",
       " ('original', 1393),\n",
       " ('girl', 1390),\n",
       " ('point', 1379),\n",
       " ('plays', 1378),\n",
       " ('wonderful', 1372),\n",
       " ('far', 1358),\n",
       " ('course', 1358),\n",
       " ('john', 1350),\n",
       " ('rather', 1340),\n",
       " ('isn', 1328),\n",
       " ('ll', 1326),\n",
       " ('dvd', 1324),\n",
       " ('later', 1324),\n",
       " ('whole', 1310),\n",
       " ('war', 1310),\n",
       " ('d', 1307),\n",
       " ('away', 1306),\n",
       " ('found', 1306),\n",
       " ('screen', 1305),\n",
       " ('nothing', 1300),\n",
       " ('year', 1297),\n",
       " ('once', 1296),\n",
       " ('hard', 1294),\n",
       " ('together', 1280),\n",
       " ('am', 1277),\n",
       " ('set', 1277),\n",
       " ('having', 1266),\n",
       " ('making', 1265),\n",
       " ('place', 1263),\n",
       " ('comes', 1260),\n",
       " ('might', 1260),\n",
       " ('sure', 1253),\n",
       " ('american', 1248),\n",
       " ('play', 1245),\n",
       " ('kind', 1244),\n",
       " ('perfect', 1242),\n",
       " ('takes', 1242),\n",
       " ('performances', 1237),\n",
       " ('himself', 1230),\n",
       " ('worth', 1221),\n",
       " ('everyone', 1221),\n",
       " ('anyone', 1214),\n",
       " ('actor', 1203),\n",
       " ('three', 1201),\n",
       " ('wife', 1196),\n",
       " ('classic', 1192),\n",
       " ('goes', 1186),\n",
       " ('ending', 1178),\n",
       " ('version', 1168),\n",
       " ('star', 1149),\n",
       " ('enjoy', 1146),\n",
       " ('book', 1142),\n",
       " ('nice', 1132),\n",
       " ('everything', 1128),\n",
       " ('during', 1124),\n",
       " ('put', 1118),\n",
       " ('seeing', 1111),\n",
       " ('least', 1102),\n",
       " ('house', 1100),\n",
       " ('high', 1095),\n",
       " ('watched', 1094),\n",
       " ('loved', 1087),\n",
       " ('men', 1087),\n",
       " ('night', 1082),\n",
       " ('anything', 1075),\n",
       " ('believe', 1071),\n",
       " ('guy', 1071),\n",
       " ('top', 1063),\n",
       " ('amazing', 1058),\n",
       " ('hollywood', 1056),\n",
       " ('looking', 1053),\n",
       " ('main', 1044),\n",
       " ('definitely', 1043),\n",
       " ('gives', 1031),\n",
       " ('home', 1029),\n",
       " ('seem', 1028),\n",
       " ('episode', 1023),\n",
       " ('sense', 1020),\n",
       " ('audience', 1020),\n",
       " ('truly', 1017),\n",
       " ('special', 1011),\n",
       " ('short', 1009),\n",
       " ('second', 1009),\n",
       " ('fan', 1009),\n",
       " ('mind', 1005),\n",
       " ('human', 1001),\n",
       " ('recommend', 999),\n",
       " ('full', 996),\n",
       " ('black', 995),\n",
       " ('help', 991),\n",
       " ('along', 989),\n",
       " ('trying', 987),\n",
       " ('small', 986),\n",
       " ('death', 985),\n",
       " ('friends', 981),\n",
       " ('remember', 974),\n",
       " ('often', 970),\n",
       " ('said', 966),\n",
       " ('favorite', 962),\n",
       " ('heart', 959),\n",
       " ('early', 957),\n",
       " ('left', 956),\n",
       " ('until', 955),\n",
       " ('script', 954),\n",
       " ('let', 954),\n",
       " ('maybe', 937),\n",
       " ('today', 936),\n",
       " ('live', 934),\n",
       " ('less', 934),\n",
       " ('moments', 933),\n",
       " ('others', 929),\n",
       " ('brilliant', 926),\n",
       " ('shot', 925),\n",
       " ('liked', 923),\n",
       " ('become', 916),\n",
       " ('won', 915),\n",
       " ('used', 910),\n",
       " ('style', 907),\n",
       " ('mother', 895),\n",
       " ('lives', 894),\n",
       " ('came', 893),\n",
       " ('stars', 890),\n",
       " ('cinema', 889),\n",
       " ('looks', 885),\n",
       " ('perhaps', 884),\n",
       " ('read', 882),\n",
       " ('enjoyed', 879),\n",
       " ('boy', 875),\n",
       " ('drama', 873),\n",
       " ('highly', 871),\n",
       " ('given', 870),\n",
       " ('playing', 867),\n",
       " ('use', 864),\n",
       " ('next', 859),\n",
       " ('women', 858),\n",
       " ('fine', 857),\n",
       " ('effects', 856),\n",
       " ('kids', 854),\n",
       " ('entertaining', 853),\n",
       " ('need', 852),\n",
       " ('line', 850),\n",
       " ('works', 848),\n",
       " ('someone', 847),\n",
       " ('mr', 836),\n",
       " ('simply', 835),\n",
       " ('picture', 833),\n",
       " ('children', 833),\n",
       " ('keep', 831),\n",
       " ('friend', 831),\n",
       " ('face', 831),\n",
       " ('dark', 830),\n",
       " ('overall', 828),\n",
       " ('certainly', 828),\n",
       " ('minutes', 827),\n",
       " ('wasn', 824),\n",
       " ('history', 822),\n",
       " ('finally', 820),\n",
       " ('couple', 816),\n",
       " ('against', 815),\n",
       " ('son', 809),\n",
       " ('understand', 808),\n",
       " ('lost', 807),\n",
       " ('michael', 805),\n",
       " ('else', 801),\n",
       " ('throughout', 798),\n",
       " ('fans', 797),\n",
       " ('city', 792),\n",
       " ('reason', 789),\n",
       " ('written', 787),\n",
       " ('production', 787),\n",
       " ('several', 784),\n",
       " ('school', 783),\n",
       " ('based', 781),\n",
       " ('rest', 781),\n",
       " ('try', 780),\n",
       " ('dead', 776),\n",
       " ('hope', 775),\n",
       " ('strong', 768),\n",
       " ('white', 765),\n",
       " ('tell', 759),\n",
       " ('itself', 758),\n",
       " ('half', 753),\n",
       " ('person', 749),\n",
       " ('sometimes', 746),\n",
       " ('start', 744),\n",
       " ('past', 744),\n",
       " ('genre', 743),\n",
       " ('beginning', 739),\n",
       " ('final', 739),\n",
       " ('town', 738),\n",
       " ('art', 734),\n",
       " ('game', 732),\n",
       " ('humor', 732),\n",
       " ('idea', 731),\n",
       " ('yes', 731),\n",
       " ('late', 730),\n",
       " ('becomes', 729),\n",
       " ('despite', 729),\n",
       " ('case', 726),\n",
       " ('able', 726),\n",
       " ('money', 723),\n",
       " ('completely', 721),\n",
       " ('child', 721),\n",
       " ('side', 719),\n",
       " ('camera', 716),\n",
       " ('getting', 714),\n",
       " ('instead', 712),\n",
       " ('soon', 702),\n",
       " ('under', 700),\n",
       " ('viewer', 699),\n",
       " ('age', 697),\n",
       " ('days', 696),\n",
       " ('stories', 696),\n",
       " ('simple', 694),\n",
       " ('felt', 694),\n",
       " ('roles', 693),\n",
       " ('video', 688),\n",
       " ('name', 683),\n",
       " ('either', 683),\n",
       " ('doing', 677),\n",
       " ('turns', 674),\n",
       " ('close', 671),\n",
       " ('wants', 671),\n",
       " ('title', 669),\n",
       " ('wrong', 668),\n",
       " ('went', 666),\n",
       " ('james', 665),\n",
       " ('evil', 659),\n",
       " ('episodes', 657),\n",
       " ('budget', 657),\n",
       " ('relationship', 655),\n",
       " ('piece', 653),\n",
       " ('fantastic', 653),\n",
       " ('david', 651),\n",
       " ('turn', 648),\n",
       " ('murder', 646),\n",
       " ('parts', 645),\n",
       " ('brother', 644),\n",
       " ('head', 643),\n",
       " ('absolutely', 643),\n",
       " ('experience', 642),\n",
       " ('eyes', 641),\n",
       " ('sex', 638),\n",
       " ('called', 637),\n",
       " ('direction', 637),\n",
       " ('directed', 636),\n",
       " ('lines', 634),\n",
       " ('behind', 633),\n",
       " ('sort', 632),\n",
       " ('actress', 631),\n",
       " ('lead', 630),\n",
       " ('oscar', 628),\n",
       " ('example', 627),\n",
       " ('including', 627),\n",
       " ('musical', 625),\n",
       " ('known', 625),\n",
       " ('chance', 621),\n",
       " ('score', 620),\n",
       " ('feeling', 619),\n",
       " ('hit', 619),\n",
       " ('already', 619),\n",
       " ('voice', 615),\n",
       " ('moment', 612),\n",
       " ('living', 612),\n",
       " ('low', 610),\n",
       " ('supporting', 610),\n",
       " ('ago', 609),\n",
       " ('themselves', 608),\n",
       " ('reality', 605),\n",
       " ('hilarious', 605),\n",
       " ('jack', 604),\n",
       " ('told', 603),\n",
       " ('hand', 601),\n",
       " ('moving', 600),\n",
       " ('quality', 600),\n",
       " ('dialogue', 600),\n",
       " ('happy', 599),\n",
       " ('song', 599),\n",
       " ('paul', 598),\n",
       " ('matter', 598),\n",
       " ('light', 594),\n",
       " ('future', 593),\n",
       " ('entire', 592),\n",
       " ('finds', 591),\n",
       " ('gave', 589),\n",
       " ('laugh', 587),\n",
       " ('released', 586),\n",
       " ('expect', 584),\n",
       " ('fight', 581),\n",
       " ('particularly', 580),\n",
       " ('police', 579),\n",
       " ('cinematography', 579),\n",
       " ('type', 578),\n",
       " ('sound', 578),\n",
       " ('whose', 578),\n",
       " ('enjoyable', 573),\n",
       " ('view', 573),\n",
       " ('husband', 572),\n",
       " ('number', 572),\n",
       " ('daughter', 572),\n",
       " ('romantic', 572),\n",
       " ('documentary', 571),\n",
       " ('self', 570),\n",
       " ('superb', 569),\n",
       " ('took', 569),\n",
       " ('modern', 569),\n",
       " ('robert', 569),\n",
       " ('mean', 566),\n",
       " ('shown', 563),\n",
       " ('coming', 561),\n",
       " ('important', 560),\n",
       " ('king', 559),\n",
       " ('leave', 559),\n",
       " ('change', 558),\n",
       " ('somewhat', 555),\n",
       " ('wanted', 555),\n",
       " ('tells', 554),\n",
       " ('run', 552),\n",
       " ('career', 552),\n",
       " ('country', 552),\n",
       " ('events', 552),\n",
       " ('season', 550),\n",
       " ('heard', 550),\n",
       " ('greatest', 549),\n",
       " ('girls', 549),\n",
       " ('etc', 547),\n",
       " ('care', 546),\n",
       " ('starts', 545),\n",
       " ('english', 542),\n",
       " ('killer', 541),\n",
       " ('totally', 540),\n",
       " ('guys', 540),\n",
       " ('tale', 540),\n",
       " ('animation', 540),\n",
       " ('usual', 539),\n",
       " ('opinion', 535),\n",
       " ('miss', 535),\n",
       " ('violence', 531),\n",
       " ('easy', 531),\n",
       " ('songs', 530),\n",
       " ('british', 528),\n",
       " ('says', 526),\n",
       " ('realistic', 525),\n",
       " ('writing', 524),\n",
       " ('writer', 522),\n",
       " ('act', 522),\n",
       " ('comic', 521),\n",
       " ('thriller', 519),\n",
       " ('television', 517),\n",
       " ('power', 516),\n",
       " ('ones', 515),\n",
       " ('kid', 514),\n",
       " ('novel', 513),\n",
       " ('york', 513),\n",
       " ('alone', 512),\n",
       " ('problem', 512),\n",
       " ('attention', 509),\n",
       " ('involved', 508),\n",
       " ('kill', 507),\n",
       " ('extremely', 507),\n",
       " ('seemed', 506),\n",
       " ('french', 505),\n",
       " ('hero', 505),\n",
       " ('rock', 504),\n",
       " ('stuff', 501),\n",
       " ('wish', 499),\n",
       " ('begins', 498),\n",
       " ('sad', 497),\n",
       " ('taken', 497),\n",
       " ('ways', 496),\n",
       " ('richard', 495),\n",
       " ('knows', 494),\n",
       " ('atmosphere', 493),\n",
       " ('similar', 491),\n",
       " ('car', 491),\n",
       " ('taking', 491),\n",
       " ('surprised', 491),\n",
       " ('perfectly', 490),\n",
       " ('george', 490),\n",
       " ('eye', 489),\n",
       " ('team', 489),\n",
       " ('across', 489),\n",
       " ('sequence', 489),\n",
       " ('powerful', 488),\n",
       " ('room', 488),\n",
       " ('serious', 488),\n",
       " ('among', 488),\n",
       " ('due', 488),\n",
       " ('b', 487),\n",
       " ('order', 487),\n",
       " ('strange', 487),\n",
       " ('cannot', 487),\n",
       " ('beauty', 486),\n",
       " ('famous', 485),\n",
       " ('herself', 484),\n",
       " ('happened', 484),\n",
       " ('myself', 484),\n",
       " ('tries', 484),\n",
       " ('class', 483),\n",
       " ('four', 482),\n",
       " ('cool', 481),\n",
       " ('theme', 479),\n",
       " ('anyway', 479),\n",
       " ('release', 479),\n",
       " ('opening', 478),\n",
       " ('entertainment', 477),\n",
       " ('slow', 475),\n",
       " ('ends', 475),\n",
       " ('unique', 475),\n",
       " ('exactly', 475),\n",
       " ('red', 474),\n",
       " ('easily', 474),\n",
       " ('o', 474),\n",
       " ('level', 474),\n",
       " ('interest', 472),\n",
       " ('happen', 471),\n",
       " ('crime', 470),\n",
       " ('viewing', 468),\n",
       " ('memorable', 467),\n",
       " ('sets', 467),\n",
       " ('group', 466),\n",
       " ('stop', 466),\n",
       " ('sister', 463),\n",
       " ('message', 463),\n",
       " ('working', 463),\n",
       " ('dance', 463),\n",
       " ('problems', 463),\n",
       " ('knew', 462),\n",
       " ('mystery', 461),\n",
       " ('nature', 461),\n",
       " ('bring', 460),\n",
       " ('thinking', 459),\n",
       " ('brought', 459),\n",
       " ('believable', 459),\n",
       " ('mostly', 458),\n",
       " ('disney', 457),\n",
       " ('couldn', 457),\n",
       " ('society', 456),\n",
       " ('lady', 455),\n",
       " ('within', 455),\n",
       " ('blood', 454),\n",
       " ('viewers', 453),\n",
       " ('upon', 453),\n",
       " ('parents', 453),\n",
       " ('tom', 452),\n",
       " ('usually', 452),\n",
       " ('soundtrack', 452),\n",
       " ('form', 452),\n",
       " ('meets', 452),\n",
       " ('peter', 452),\n",
       " ('local', 450),\n",
       " ('follow', 448),\n",
       " ('certain', 448),\n",
       " ('whether', 447),\n",
       " ('possible', 446),\n",
       " ('emotional', 445),\n",
       " ('killed', 444),\n",
       " ('de', 444),\n",
       " ('above', 444),\n",
       " ('middle', 443),\n",
       " ('god', 443),\n",
       " ('flick', 442),\n",
       " ('needs', 442),\n",
       " ('happens', 442),\n",
       " ('masterpiece', 441),\n",
       " ('period', 440),\n",
       " ('major', 440),\n",
       " ('named', 439),\n",
       " ('haven', 439),\n",
       " ('particular', 438),\n",
       " ('th', 438),\n",
       " ('earth', 437),\n",
       " ('feature', 437),\n",
       " ('stand', 436),\n",
       " ('typical', 435),\n",
       " ('words', 435),\n",
       " ('obviously', 433),\n",
       " ('elements', 433),\n",
       " ('romance', 431),\n",
       " ('jane', 430),\n",
       " ('yourself', 427),\n",
       " ('showing', 427),\n",
       " ('fantasy', 426),\n",
       " ('brings', 426),\n",
       " ('america', 423),\n",
       " ('guess', 423),\n",
       " ('unfortunately', 422),\n",
       " ('huge', 422),\n",
       " ('running', 421),\n",
       " ('indeed', 421),\n",
       " ('talent', 420),\n",
       " ('stage', 419),\n",
       " ('started', 418),\n",
       " ('sweet', 417),\n",
       " ('japanese', 417),\n",
       " ('leads', 417),\n",
       " ('poor', 416),\n",
       " ('deal', 416),\n",
       " ('incredible', 413),\n",
       " ('personal', 413),\n",
       " ('fast', 412),\n",
       " ('deep', 410),\n",
       " ('became', 410),\n",
       " ('hours', 409),\n",
       " ('giving', 408),\n",
       " ('dream', 408),\n",
       " ('nearly', 408),\n",
       " ('clearly', 407),\n",
       " ('turned', 407),\n",
       " ('obvious', 406),\n",
       " ('near', 406),\n",
       " ('surprise', 405),\n",
       " ('cut', 405),\n",
       " ('era', 404),\n",
       " ('body', 404),\n",
       " ('female', 403),\n",
       " ('hour', 403),\n",
       " ('five', 403),\n",
       " ('note', 399),\n",
       " ('learn', 398),\n",
       " ('truth', 398),\n",
       " ('match', 397),\n",
       " ('tony', 397),\n",
       " ('feels', 397),\n",
       " ('except', 397),\n",
       " ('complete', 394),\n",
       " ('filmed', 394),\n",
       " ('clear', 394),\n",
       " ('street', 393),\n",
       " ('older', 393),\n",
       " ('eventually', 393),\n",
       " ('keeps', 393),\n",
       " ('lots', 393),\n",
       " ('buy', 392),\n",
       " ('stewart', 391),\n",
       " ('william', 391),\n",
       " ('meet', 390),\n",
       " ('joe', 390),\n",
       " ('fall', 390),\n",
       " ('difficult', 389),\n",
       " ('rating', 389),\n",
       " ('unlike', 389),\n",
       " ('shots', 389),\n",
       " ('talking', 389),\n",
       " ('dramatic', 388),\n",
       " ('means', 388),\n",
       " ('situation', 386),\n",
       " ('wonder', 386),\n",
       " ('present', 386),\n",
       " ('subject', 386),\n",
       " ('appears', 386),\n",
       " ('comments', 385),\n",
       " ('sequences', 383),\n",
       " ('general', 383),\n",
       " ('lee', 383),\n",
       " ('earlier', 382),\n",
       " ('points', 382),\n",
       " ('check', 379),\n",
       " ('gone', 379),\n",
       " ('suspense', 378),\n",
       " ('recommended', 378),\n",
       " ('ten', 378),\n",
       " ('business', 377),\n",
       " ('third', 377),\n",
       " ('talk', 375),\n",
       " ('beyond', 375),\n",
       " ('leaves', 375),\n",
       " ('portrayal', 374),\n",
       " ('beautifully', 373),\n",
       " ('single', 372),\n",
       " ('bill', 372),\n",
       " ('plenty', 371),\n",
       " ('word', 371),\n",
       " ('whom', 370),\n",
       " ('falls', 370),\n",
       " ('scary', 369),\n",
       " ('figure', 369),\n",
       " ('non', 369),\n",
       " ('battle', 369),\n",
       " ('return', 368),\n",
       " ('using', 368),\n",
       " ('add', 367),\n",
       " ('doubt', 367),\n",
       " ('hear', 366),\n",
       " ('solid', 366),\n",
       " ('success', 366),\n",
       " ('jokes', 365),\n",
       " ('political', 365),\n",
       " ('touching', 365),\n",
       " ('oh', 365),\n",
       " ('awesome', 364),\n",
       " ('hell', 364),\n",
       " ('boys', 364),\n",
       " ('dog', 362),\n",
       " ('sexual', 362),\n",
       " ('recently', 362),\n",
       " ('wouldn', 361),\n",
       " ('straight', 361),\n",
       " ('please', 361),\n",
       " ('features', 361),\n",
       " ('lack', 360),\n",
       " ('forget', 360),\n",
       " ('setting', 360),\n",
       " ('married', 359),\n",
       " ('mark', 359),\n",
       " ('social', 357),\n",
       " ('adventure', 356),\n",
       " ('interested', 356),\n",
       " ('brothers', 355),\n",
       " ('actual', 355),\n",
       " ('terrific', 355),\n",
       " ('sees', 355),\n",
       " ('move', 354),\n",
       " ('call', 354),\n",
       " ('theater', 353),\n",
       " ('dr', 353),\n",
       " ('various', 353),\n",
       " ('animated', 352),\n",
       " ('western', 351),\n",
       " ('space', 350),\n",
       " ('baby', 350),\n",
       " ('disappointed', 348),\n",
       " ('leading', 348),\n",
       " ('aren', 346),\n",
       " ('portrayed', 346),\n",
       " ('screenplay', 345),\n",
       " ('smith', 345),\n",
       " ('hate', 344),\n",
       " ('towards', 344),\n",
       " ('noir', 343),\n",
       " ('kelly', 342),\n",
       " ('outstanding', 342),\n",
       " ('decent', 342),\n",
       " ('journey', 341),\n",
       " ('directors', 341),\n",
       " ('looked', 340),\n",
       " ('none', 340),\n",
       " ('effective', 340),\n",
       " ('caught', 339),\n",
       " ('storyline', 339),\n",
       " ('cold', 339),\n",
       " ('sci', 339),\n",
       " ('fi', 339),\n",
       " ('mary', 339),\n",
       " ('rich', 338),\n",
       " ('charming', 338),\n",
       " ('rare', 337),\n",
       " ('harry', 337),\n",
       " ('popular', 337),\n",
       " ('manages', 337),\n",
       " ('spirit', 336),\n",
       " ('appreciate', 335),\n",
       " ('open', 335),\n",
       " ('acted', 334),\n",
       " ('basically', 334),\n",
       " ('moves', 334),\n",
       " ('pace', 333),\n",
       " ('subtle', 333),\n",
       " ('inside', 333),\n",
       " ('boring', 333),\n",
       " ('deserves', 333),\n",
       " ('century', 333),\n",
       " ('mention', 333),\n",
       " ('background', 332),\n",
       " ('familiar', 332),\n",
       " ('ben', 331),\n",
       " ('supposed', 330),\n",
       " ('creepy', 330),\n",
       " ('secret', 329),\n",
       " ('jim', 328),\n",
       " ('die', 328),\n",
       " ('question', 327),\n",
       " ('effect', 327),\n",
       " ('natural', 327),\n",
       " ('language', 326),\n",
       " ('impressive', 326),\n",
       " ('rate', 326),\n",
       " ('saying', 325),\n",
       " ('intelligent', 325),\n",
       " ('scott', 324),\n",
       " ('telling', 324),\n",
       " ('material', 324),\n",
       " ('realize', 324),\n",
       " ('singing', 323),\n",
       " ('dancing', 322),\n",
       " ('adult', 321),\n",
       " ('visual', 321),\n",
       " ('imagine', 321),\n",
       " ('office', 320),\n",
       " ('kept', 320),\n",
       " ('uses', 319),\n",
       " ('stunning', 318),\n",
       " ('pure', 318),\n",
       " ('wait', 318),\n",
       " ('copy', 317),\n",
       " ('seriously', 317),\n",
       " ('previous', 317),\n",
       " ('review', 317),\n",
       " ('somehow', 316),\n",
       " ('magic', 316),\n",
       " ('hot', 316),\n",
       " ('create', 316),\n",
       " ('reading', 316),\n",
       " ('created', 316),\n",
       " ('air', 315),\n",
       " ('escape', 315),\n",
       " ('crazy', 315),\n",
       " ('stay', 315),\n",
       " ('frank', 315),\n",
       " ('attempt', 315),\n",
       " ('hands', 314),\n",
       " ('filled', 313),\n",
       " ('surprisingly', 312),\n",
       " ('expected', 312),\n",
       " ('average', 312),\n",
       " ('complex', 311),\n",
       " ('quickly', 310),\n",
       " ('studio', 310),\n",
       " ('successful', 310),\n",
       " ('plus', 309),\n",
       " ('male', 309),\n",
       " ('co', 307),\n",
       " ('images', 306),\n",
       " ('exciting', 306),\n",
       " ('casting', 306),\n",
       " ('minute', 306),\n",
       " ('following', 306),\n",
       " ('themes', 305),\n",
       " ('german', 305),\n",
       " ('reasons', 305),\n",
       " ('follows', 305),\n",
       " ('e', 305),\n",
       " ('members', 305),\n",
       " ('free', 304),\n",
       " ('touch', 304),\n",
       " ('genius', 304),\n",
       " ('edge', 304),\n",
       " ('cute', 304),\n",
       " ('outside', 303),\n",
       " ('ok', 302),\n",
       " ('admit', 302),\n",
       " ('reviews', 302),\n",
       " ('younger', 302),\n",
       " ('odd', 301),\n",
       " ('fighting', 301),\n",
       " ('master', 301),\n",
       " ('recent', 300),\n",
       " ('comment', 300),\n",
       " ('break', 300),\n",
       " ('thanks', 300),\n",
       " ('apart', 299),\n",
       " ('emotions', 298),\n",
       " ('begin', 298),\n",
       " ('lovely', 298),\n",
       " ('doctor', 297),\n",
       " ('italian', 297),\n",
       " ('party', 297),\n",
       " ('missed', 296),\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_count.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 548962),\n",
       " ('.', 167538),\n",
       " ('the', 163389),\n",
       " ('a', 79321),\n",
       " ('and', 74385),\n",
       " ('of', 69009),\n",
       " ('to', 68974),\n",
       " ('br', 52637),\n",
       " ('is', 50083),\n",
       " ('it', 48327),\n",
       " ('i', 46880),\n",
       " ('in', 43753),\n",
       " ('this', 40920),\n",
       " ('that', 37615),\n",
       " ('s', 31546),\n",
       " ('was', 26291),\n",
       " ('movie', 24965),\n",
       " ('for', 21927),\n",
       " ('but', 21781),\n",
       " ('with', 20878),\n",
       " ('as', 20625),\n",
       " ('t', 20361),\n",
       " ('film', 19218),\n",
       " ('you', 17549),\n",
       " ('on', 17192),\n",
       " ('not', 16354),\n",
       " ('have', 15144),\n",
       " ('are', 14623),\n",
       " ('be', 14541),\n",
       " ('he', 13856),\n",
       " ('one', 13134),\n",
       " ('they', 13011),\n",
       " ('\\n', 12500),\n",
       " ('at', 12279),\n",
       " ('his', 12147),\n",
       " ('all', 12036),\n",
       " ('so', 11463),\n",
       " ('like', 11238),\n",
       " ('there', 10775),\n",
       " ('just', 10619),\n",
       " ('by', 10549),\n",
       " ('or', 10272),\n",
       " ('an', 10266),\n",
       " ('who', 9969),\n",
       " ('from', 9731),\n",
       " ('if', 9518),\n",
       " ('about', 9061),\n",
       " ('out', 8979),\n",
       " ('what', 8422),\n",
       " ('some', 8306),\n",
       " ('no', 8143),\n",
       " ('her', 7947),\n",
       " ('even', 7687),\n",
       " ('can', 7653),\n",
       " ('has', 7604),\n",
       " ('good', 7423),\n",
       " ('bad', 7401),\n",
       " ('would', 7036),\n",
       " ('up', 6970),\n",
       " ('only', 6781),\n",
       " ('more', 6730),\n",
       " ('when', 6726),\n",
       " ('she', 6444),\n",
       " ('really', 6262),\n",
       " ('time', 6209),\n",
       " ('had', 6142),\n",
       " ('my', 6015),\n",
       " ('were', 6001),\n",
       " ('which', 5780),\n",
       " ('very', 5764),\n",
       " ('me', 5606),\n",
       " ('see', 5452),\n",
       " ('don', 5336),\n",
       " ('we', 5328),\n",
       " ('their', 5278),\n",
       " ('do', 5236),\n",
       " ('story', 5208),\n",
       " ('than', 5183),\n",
       " ('been', 5100),\n",
       " ('much', 5078),\n",
       " ('get', 5037),\n",
       " ('because', 4966),\n",
       " ('people', 4806),\n",
       " ('then', 4761),\n",
       " ('make', 4722),\n",
       " ('how', 4688),\n",
       " ('could', 4686),\n",
       " ('any', 4658),\n",
       " ('into', 4567),\n",
       " ('made', 4541),\n",
       " ('first', 4306),\n",
       " ('other', 4305),\n",
       " ('well', 4254),\n",
       " ('too', 4174),\n",
       " ('them', 4165),\n",
       " ('plot', 4154),\n",
       " ('movies', 4080),\n",
       " ('acting', 4056),\n",
       " ('will', 3993),\n",
       " ('way', 3989),\n",
       " ('most', 3919),\n",
       " ('him', 3858),\n",
       " ('after', 3838),\n",
       " ('its', 3655),\n",
       " ('think', 3643),\n",
       " ('also', 3608),\n",
       " ('characters', 3600),\n",
       " ('off', 3567),\n",
       " ('watch', 3550),\n",
       " ('did', 3506),\n",
       " ('character', 3506),\n",
       " ('why', 3463),\n",
       " ('being', 3393),\n",
       " ('better', 3358),\n",
       " ('know', 3334),\n",
       " ('over', 3316),\n",
       " ('seen', 3265),\n",
       " ('ever', 3263),\n",
       " ('never', 3259),\n",
       " ('your', 3233),\n",
       " ('where', 3219),\n",
       " ('two', 3173),\n",
       " ('little', 3096),\n",
       " ('films', 3077),\n",
       " ('here', 3027),\n",
       " ('m', 3000),\n",
       " ('nothing', 2990),\n",
       " ('say', 2982),\n",
       " ('end', 2954),\n",
       " ('something', 2942),\n",
       " ('should', 2920),\n",
       " ('many', 2909),\n",
       " ('does', 2871),\n",
       " ('thing', 2866),\n",
       " ('show', 2862),\n",
       " ('ve', 2829),\n",
       " ('scene', 2816),\n",
       " ('scenes', 2785),\n",
       " ('these', 2724),\n",
       " ('go', 2717),\n",
       " ('didn', 2646),\n",
       " ('great', 2640),\n",
       " ('watching', 2640),\n",
       " ('re', 2620),\n",
       " ('doesn', 2601),\n",
       " ('through', 2560),\n",
       " ('such', 2544),\n",
       " ('man', 2516),\n",
       " ('worst', 2480),\n",
       " ('actually', 2449),\n",
       " ('actors', 2437),\n",
       " ('life', 2429),\n",
       " ('back', 2424),\n",
       " ('while', 2418),\n",
       " ('director', 2405),\n",
       " ('funny', 2336),\n",
       " ('going', 2319),\n",
       " ('still', 2283),\n",
       " ('another', 2254),\n",
       " ('look', 2247),\n",
       " ('now', 2237),\n",
       " ('old', 2215),\n",
       " ('those', 2212),\n",
       " ('real', 2170),\n",
       " ('few', 2158),\n",
       " ('love', 2152),\n",
       " ('horror', 2150),\n",
       " ('before', 2147),\n",
       " ('want', 2141),\n",
       " ('minutes', 2126),\n",
       " ('pretty', 2115),\n",
       " ('best', 2094),\n",
       " ('though', 2091),\n",
       " ('same', 2081),\n",
       " ('script', 2074),\n",
       " ('work', 2027),\n",
       " ('every', 2025),\n",
       " ('seems', 2023),\n",
       " ('least', 2011),\n",
       " ('enough', 1997),\n",
       " ('down', 1988),\n",
       " ('original', 1983),\n",
       " ('guy', 1964),\n",
       " ('got', 1952),\n",
       " ('around', 1943),\n",
       " ('part', 1942),\n",
       " ('lot', 1892),\n",
       " ('anything', 1874),\n",
       " ('find', 1860),\n",
       " ('new', 1854),\n",
       " ('isn', 1849),\n",
       " ('again', 1849),\n",
       " ('point', 1845),\n",
       " ('fact', 1839),\n",
       " ('things', 1839),\n",
       " ('give', 1823),\n",
       " ('makes', 1814),\n",
       " ('take', 1800),\n",
       " ('thought', 1798),\n",
       " ('d', 1770),\n",
       " ('whole', 1768),\n",
       " ('long', 1761),\n",
       " ('years', 1759),\n",
       " ('however', 1740),\n",
       " ('gets', 1714),\n",
       " ('making', 1695),\n",
       " ('cast', 1694),\n",
       " ('big', 1662),\n",
       " ('might', 1658),\n",
       " ('interesting', 1648),\n",
       " ('money', 1638),\n",
       " ('us', 1628),\n",
       " ('right', 1625),\n",
       " ('far', 1619),\n",
       " ('quite', 1596),\n",
       " ('without', 1595),\n",
       " ('come', 1595),\n",
       " ('almost', 1574),\n",
       " ('ll', 1567),\n",
       " ('action', 1566),\n",
       " ('awful', 1557),\n",
       " ('kind', 1539),\n",
       " ('reason', 1534),\n",
       " ('am', 1530),\n",
       " ('looks', 1528),\n",
       " ('must', 1522),\n",
       " ('done', 1510),\n",
       " ('comedy', 1504),\n",
       " ('someone', 1490),\n",
       " ('trying', 1486),\n",
       " ('wasn', 1484),\n",
       " ('poor', 1481),\n",
       " ('boring', 1478),\n",
       " ('instead', 1478),\n",
       " ('saw', 1475),\n",
       " ('away', 1469),\n",
       " ('girl', 1463),\n",
       " ('probably', 1444),\n",
       " ('believe', 1434),\n",
       " ('sure', 1433),\n",
       " ('looking', 1430),\n",
       " ('stupid', 1428),\n",
       " ('anyone', 1418),\n",
       " ('times', 1406),\n",
       " ('world', 1404),\n",
       " ('maybe', 1404),\n",
       " ('rather', 1394),\n",
       " ('terrible', 1391),\n",
       " ('last', 1390),\n",
       " ('may', 1390),\n",
       " ('since', 1388),\n",
       " ('let', 1385),\n",
       " ('tv', 1382),\n",
       " ('between', 1374),\n",
       " ('hard', 1374),\n",
       " ('waste', 1358),\n",
       " ('woman', 1356),\n",
       " ('feel', 1354),\n",
       " ('effects', 1348),\n",
       " ('half', 1341),\n",
       " ('own', 1333),\n",
       " ('young', 1317),\n",
       " ('music', 1316),\n",
       " ('idea', 1312),\n",
       " ('sense', 1306),\n",
       " ('bit', 1298),\n",
       " ('having', 1280),\n",
       " ('book', 1278),\n",
       " ('found', 1267),\n",
       " ('series', 1263),\n",
       " ('put', 1263),\n",
       " ('goes', 1256),\n",
       " ('worse', 1249),\n",
       " ('said', 1230),\n",
       " ('comes', 1224),\n",
       " ('role', 1222),\n",
       " ('main', 1220),\n",
       " ('else', 1199),\n",
       " ('everything', 1197),\n",
       " ('yet', 1196),\n",
       " ('low', 1189),\n",
       " ('screen', 1188),\n",
       " ('supposed', 1186),\n",
       " ('actor', 1185),\n",
       " ('either', 1183),\n",
       " ('budget', 1179),\n",
       " ('ending', 1179),\n",
       " ('audience', 1178),\n",
       " ('set', 1177),\n",
       " ('family', 1170),\n",
       " ('left', 1169),\n",
       " ('completely', 1168),\n",
       " ('both', 1158),\n",
       " ('wrong', 1155),\n",
       " ('always', 1151),\n",
       " ('course', 1148),\n",
       " ('place', 1148),\n",
       " ('seem', 1147),\n",
       " ('watched', 1142),\n",
       " ('day', 1132),\n",
       " ('simply', 1130),\n",
       " ('shot', 1126),\n",
       " ('mean', 1117),\n",
       " ('special', 1102),\n",
       " ('dead', 1101),\n",
       " ('three', 1094),\n",
       " ('house', 1085),\n",
       " ('oh', 1084),\n",
       " ('night', 1083),\n",
       " ('read', 1082),\n",
       " ('less', 1067),\n",
       " ('high', 1066),\n",
       " ('year', 1064),\n",
       " ('camera', 1061),\n",
       " ('worth', 1057),\n",
       " ('our', 1056),\n",
       " ('try', 1051),\n",
       " ('horrible', 1046),\n",
       " ('sex', 1046),\n",
       " ('video', 1043),\n",
       " ('black', 1039),\n",
       " ('although', 1036),\n",
       " ('couldn', 1036),\n",
       " ('once', 1033),\n",
       " ('rest', 1022),\n",
       " ('dvd', 1021),\n",
       " ('line', 1018),\n",
       " ('played', 1017),\n",
       " ('fun', 1007),\n",
       " ('during', 1006),\n",
       " ('production', 1003),\n",
       " ('everyone', 1002),\n",
       " ('play', 993),\n",
       " ('mind', 990),\n",
       " ('kids', 989),\n",
       " ('version', 989),\n",
       " ('seeing', 988),\n",
       " ('american', 980),\n",
       " ('given', 978),\n",
       " ('used', 969),\n",
       " ('performance', 968),\n",
       " ('especially', 963),\n",
       " ('together', 963),\n",
       " ('tell', 959),\n",
       " ('women', 958),\n",
       " ('start', 956),\n",
       " ('need', 955),\n",
       " ('second', 953),\n",
       " ('each', 950),\n",
       " ('takes', 950),\n",
       " ('wife', 944),\n",
       " ('dialogue', 942),\n",
       " ('use', 940),\n",
       " ('problem', 938),\n",
       " ('star', 934),\n",
       " ('unfortunately', 931),\n",
       " ('himself', 929),\n",
       " ('doing', 926),\n",
       " ('death', 922),\n",
       " ('name', 921),\n",
       " ('lines', 919),\n",
       " ('killer', 914),\n",
       " ('getting', 913),\n",
       " ('help', 905),\n",
       " ('couple', 902),\n",
       " ('fan', 902),\n",
       " ('head', 898),\n",
       " ('crap', 895),\n",
       " ('guess', 888),\n",
       " ('piece', 884),\n",
       " ('nice', 880),\n",
       " ('different', 878),\n",
       " ('school', 876),\n",
       " ('later', 875),\n",
       " ('entire', 869),\n",
       " ('shows', 860),\n",
       " ('john', 858),\n",
       " ('next', 858),\n",
       " ('short', 857),\n",
       " ('seemed', 857),\n",
       " ('hollywood', 850),\n",
       " ('home', 848),\n",
       " ('true', 846),\n",
       " ('person', 846),\n",
       " ('absolutely', 842),\n",
       " ('sort', 840),\n",
       " ('care', 839),\n",
       " ('understand', 836),\n",
       " ('plays', 835),\n",
       " ('felt', 834),\n",
       " ('written', 829),\n",
       " ('title', 828),\n",
       " ('men', 822),\n",
       " ('until', 821),\n",
       " ('flick', 816),\n",
       " ('decent', 815),\n",
       " ('face', 814),\n",
       " ('friends', 810),\n",
       " ('job', 807),\n",
       " ('case', 807),\n",
       " ('stars', 807),\n",
       " ('itself', 804),\n",
       " ('yes', 801),\n",
       " ('perhaps', 800),\n",
       " ('went', 797),\n",
       " ('wanted', 797),\n",
       " ('called', 796),\n",
       " ('annoying', 795),\n",
       " ('ridiculous', 790),\n",
       " ('tries', 790),\n",
       " ('laugh', 788),\n",
       " ('evil', 787),\n",
       " ('along', 786),\n",
       " ('top', 785),\n",
       " ('hour', 784),\n",
       " ('full', 783),\n",
       " ('came', 780),\n",
       " ('writing', 780),\n",
       " ('keep', 770),\n",
       " ('totally', 767),\n",
       " ('playing', 766),\n",
       " ('god', 765),\n",
       " ('won', 764),\n",
       " ('guys', 763),\n",
       " ('already', 762),\n",
       " ('gore', 757),\n",
       " ('direction', 748),\n",
       " ('save', 746),\n",
       " ('lost', 745),\n",
       " ('example', 744),\n",
       " ('sound', 742),\n",
       " ('war', 741),\n",
       " ('attempt', 735),\n",
       " ('except', 733),\n",
       " ('car', 733),\n",
       " ('moments', 732),\n",
       " ('blood', 732),\n",
       " ('obviously', 730),\n",
       " ('act', 729),\n",
       " ('remember', 728),\n",
       " ('kill', 727),\n",
       " ('white', 726),\n",
       " ('truly', 726),\n",
       " ('father', 726),\n",
       " ('b', 725),\n",
       " ('thinking', 720),\n",
       " ('ok', 716),\n",
       " ('finally', 716),\n",
       " ('turn', 711),\n",
       " ('quality', 701),\n",
       " ('lack', 698),\n",
       " ('style', 694),\n",
       " ('wouldn', 693),\n",
       " ('cheap', 691),\n",
       " ('none', 690),\n",
       " ('please', 686),\n",
       " ('kid', 686),\n",
       " ('boy', 685),\n",
       " ('seriously', 684),\n",
       " ('lead', 680),\n",
       " ('dull', 677),\n",
       " ('children', 676),\n",
       " ('starts', 675),\n",
       " ('stuff', 673),\n",
       " ('hope', 672),\n",
       " ('looked', 670),\n",
       " ('recommend', 669),\n",
       " ('under', 668),\n",
       " ('killed', 667),\n",
       " ('run', 667),\n",
       " ('others', 666),\n",
       " ('enjoy', 666),\n",
       " ('myself', 663),\n",
       " ('etc', 663),\n",
       " ('beginning', 662),\n",
       " ('against', 662),\n",
       " ('girls', 662),\n",
       " ('obvious', 660),\n",
       " ('small', 660),\n",
       " ('hell', 659),\n",
       " ('slow', 657),\n",
       " ('hand', 656),\n",
       " ('lame', 652),\n",
       " ('wonder', 652),\n",
       " ('becomes', 651),\n",
       " ('picture', 651),\n",
       " ('based', 650),\n",
       " ('early', 648),\n",
       " ('behind', 646),\n",
       " ('poorly', 644),\n",
       " ('avoid', 642),\n",
       " ('apparently', 640),\n",
       " ('complete', 640),\n",
       " ('happens', 639),\n",
       " ('anyway', 638),\n",
       " ('classic', 637),\n",
       " ('several', 636),\n",
       " ('episode', 635),\n",
       " ('despite', 635),\n",
       " ('certainly', 635),\n",
       " ('often', 631),\n",
       " ('writer', 630),\n",
       " ('cut', 630),\n",
       " ('predictable', 628),\n",
       " ('gave', 628),\n",
       " ('mother', 628),\n",
       " ('become', 627),\n",
       " ('close', 625),\n",
       " ('fans', 624),\n",
       " ('saying', 621),\n",
       " ('scary', 619),\n",
       " ('stop', 618),\n",
       " ('live', 618),\n",
       " ('wants', 617),\n",
       " ('self', 615),\n",
       " ('mr', 612),\n",
       " ('jokes', 611),\n",
       " ('friend', 611),\n",
       " ('cannot', 610),\n",
       " ('overall', 609),\n",
       " ('cinema', 604),\n",
       " ('child', 603),\n",
       " ('silly', 601),\n",
       " ('beautiful', 596),\n",
       " ('human', 595),\n",
       " ('expect', 594),\n",
       " ('liked', 593),\n",
       " ('happened', 592),\n",
       " ('entertaining', 590),\n",
       " ('bunch', 590),\n",
       " ('actress', 588),\n",
       " ('final', 588),\n",
       " ('performances', 584),\n",
       " ('says', 584),\n",
       " ('turns', 577),\n",
       " ('humor', 577),\n",
       " ('eyes', 576),\n",
       " ('themselves', 576),\n",
       " ('hours', 574),\n",
       " ('happen', 573),\n",
       " ('basically', 572),\n",
       " ('days', 572),\n",
       " ('running', 571),\n",
       " ('disappointed', 569),\n",
       " ('involved', 569),\n",
       " ('call', 569),\n",
       " ('group', 568),\n",
       " ('directed', 568),\n",
       " ('fight', 567),\n",
       " ('daughter', 566),\n",
       " ('talking', 566),\n",
       " ('body', 566),\n",
       " ('sorry', 565),\n",
       " ('badly', 565),\n",
       " ('viewer', 563),\n",
       " ('throughout', 563),\n",
       " ('yourself', 562),\n",
       " ('extremely', 562),\n",
       " ('violence', 561),\n",
       " ('interest', 561),\n",
       " ('heard', 561),\n",
       " ('shots', 559),\n",
       " ('side', 557),\n",
       " ('word', 556),\n",
       " ('art', 555),\n",
       " ('possible', 554),\n",
       " ('game', 551),\n",
       " ('dark', 551),\n",
       " ('hero', 550),\n",
       " ('alone', 549),\n",
       " ('son', 547),\n",
       " ('leave', 547),\n",
       " ('type', 547),\n",
       " ('parts', 546),\n",
       " ('gives', 546),\n",
       " ('single', 546),\n",
       " ('started', 545),\n",
       " ('female', 543),\n",
       " ('rating', 541),\n",
       " ('voice', 541),\n",
       " ('mess', 541),\n",
       " ('aren', 540),\n",
       " ('town', 540),\n",
       " ('drama', 538),\n",
       " ('definitely', 537),\n",
       " ('unless', 536),\n",
       " ('review', 534),\n",
       " ('effort', 533),\n",
       " ('weak', 533),\n",
       " ('able', 533),\n",
       " ('took', 531),\n",
       " ('non', 530),\n",
       " ('five', 530),\n",
       " ('usually', 529),\n",
       " ('matter', 529),\n",
       " ('michael', 528),\n",
       " ('feeling', 526),\n",
       " ('huge', 523),\n",
       " ('sequel', 522),\n",
       " ('soon', 521),\n",
       " ('exactly', 520),\n",
       " ('past', 519),\n",
       " ('turned', 518),\n",
       " ('police', 518),\n",
       " ('tried', 515),\n",
       " ('middle', 513),\n",
       " ('talent', 513),\n",
       " ('genre', 512),\n",
       " ('zombie', 510),\n",
       " ('ends', 509),\n",
       " ('history', 509),\n",
       " ('straight', 503),\n",
       " ('coming', 501),\n",
       " ('serious', 501),\n",
       " ('opening', 501),\n",
       " ('moment', 500),\n",
       " ('lives', 499),\n",
       " ('sad', 499),\n",
       " ('dialog', 498),\n",
       " ('particularly', 498),\n",
       " ('editing', 493),\n",
       " ('clearly', 492),\n",
       " ('earth', 491),\n",
       " ('beyond', 491),\n",
       " ('taken', 490),\n",
       " ('cool', 490),\n",
       " ('level', 489),\n",
       " ('dumb', 489),\n",
       " ('okay', 488),\n",
       " ('major', 487),\n",
       " ('fast', 485),\n",
       " ('premise', 485),\n",
       " ('joke', 484),\n",
       " ('stories', 484),\n",
       " ('wasted', 483),\n",
       " ('minute', 483),\n",
       " ('across', 482),\n",
       " ('mostly', 482),\n",
       " ('rent', 482),\n",
       " ('fails', 481),\n",
       " ('falls', 481),\n",
       " ('late', 481),\n",
       " ('mention', 478),\n",
       " ('theater', 475),\n",
       " ('sometimes', 472),\n",
       " ('stay', 472),\n",
       " ('hit', 468),\n",
       " ('fine', 467),\n",
       " ('talk', 467),\n",
       " ('die', 466),\n",
       " ('pointless', 465),\n",
       " ('storyline', 465),\n",
       " ('taking', 464),\n",
       " ('order', 462),\n",
       " ('brother', 461),\n",
       " ('whatever', 460),\n",
       " ('told', 460),\n",
       " ('wish', 458),\n",
       " ('room', 456),\n",
       " ('career', 455),\n",
       " ('write', 455),\n",
       " ('appears', 455),\n",
       " ('husband', 454),\n",
       " ('known', 454),\n",
       " ('living', 451),\n",
       " ('ten', 450),\n",
       " ('sit', 450),\n",
       " ('words', 449),\n",
       " ('chance', 448),\n",
       " ('monster', 448),\n",
       " ('novel', 444),\n",
       " ('hate', 444),\n",
       " ('add', 443),\n",
       " ('english', 443),\n",
       " ('somehow', 441),\n",
       " ('strange', 440),\n",
       " ('imdb', 438),\n",
       " ('actual', 438),\n",
       " ('ones', 437),\n",
       " ('killing', 437),\n",
       " ('total', 437),\n",
       " ('material', 437),\n",
       " ('knew', 436),\n",
       " ('number', 434),\n",
       " ('king', 434),\n",
       " ('using', 433),\n",
       " ('giving', 431),\n",
       " ('power', 431),\n",
       " ('works', 431),\n",
       " ('shown', 431),\n",
       " ('lee', 431),\n",
       " ('possibly', 430),\n",
       " ('points', 430),\n",
       " ('kept', 430),\n",
       " ('four', 429),\n",
       " ('local', 427),\n",
       " ('usual', 426),\n",
       " ('including', 425),\n",
       " ('ago', 424),\n",
       " ('opinion', 424),\n",
       " ('problems', 424),\n",
       " ('nudity', 423),\n",
       " ('age', 422),\n",
       " ('due', 421),\n",
       " ('roles', 420),\n",
       " ('decided', 419),\n",
       " ('writers', 419),\n",
       " ('flat', 418),\n",
       " ('easily', 418),\n",
       " ('near', 418),\n",
       " ('murder', 417),\n",
       " ('experience', 417),\n",
       " ('reviews', 416),\n",
       " ('imagine', 415),\n",
       " ('feels', 413),\n",
       " ('somewhat', 411),\n",
       " ('plain', 411),\n",
       " ('class', 410),\n",
       " ('score', 410),\n",
       " ('song', 409),\n",
       " ('bring', 409),\n",
       " ('whether', 409),\n",
       " ('otherwise', 408),\n",
       " ('average', 408),\n",
       " ('whose', 408),\n",
       " ('pathetic', 407),\n",
       " ('knows', 407),\n",
       " ('nearly', 407),\n",
       " ('zombies', 407),\n",
       " ('cinematography', 406),\n",
       " ('upon', 406),\n",
       " ('cheesy', 406),\n",
       " ('space', 405),\n",
       " ('city', 405),\n",
       " ('credits', 404),\n",
       " ('james', 403),\n",
       " ('lots', 403),\n",
       " ('change', 403),\n",
       " ('nor', 402),\n",
       " ('entertainment', 402),\n",
       " ('wait', 401),\n",
       " ('released', 400),\n",
       " ('needs', 399),\n",
       " ('shame', 398),\n",
       " ('attention', 396),\n",
       " ('comments', 394),\n",
       " ('free', 393),\n",
       " ('bored', 393),\n",
       " ('lady', 393),\n",
       " ('expected', 392),\n",
       " ('clear', 392),\n",
       " ('needed', 392),\n",
       " ('view', 391),\n",
       " ('check', 390),\n",
       " ('doubt', 390),\n",
       " ('development', 390),\n",
       " ('figure', 389),\n",
       " ('mystery', 389),\n",
       " ('garbage', 388),\n",
       " ('excellent', 388),\n",
       " ('sequence', 386),\n",
       " ('television', 386),\n",
       " ('o', 385),\n",
       " ('sets', 385),\n",
       " ('laughable', 384),\n",
       " ('potential', 384),\n",
       " ('reality', 382),\n",
       " ('documentary', 382),\n",
       " ('country', 382),\n",
       " ('robert', 382),\n",
       " ('light', 382),\n",
       " ('ask', 381),\n",
       " ('general', 381),\n",
       " ('comic', 380),\n",
       " ('begin', 380),\n",
       " ('fall', 380),\n",
       " ('stand', 379),\n",
       " ('forced', 379),\n",
       " ('remake', 379),\n",
       " ('trash', 379),\n",
       " ('footage', 379),\n",
       " ('songs', 378),\n",
       " ('thriller', 378),\n",
       " ('gay', 377),\n",
       " ('within', 377),\n",
       " ('hardly', 376),\n",
       " ('gone', 375),\n",
       " ('above', 375),\n",
       " ('george', 374),\n",
       " ('means', 373),\n",
       " ('sounds', 373),\n",
       " ('david', 372),\n",
       " ('move', 372),\n",
       " ('directing', 372),\n",
       " ('buy', 372),\n",
       " ('forward', 371),\n",
       " ('important', 371),\n",
       " ('rock', 371),\n",
       " ('filmed', 370),\n",
       " ('haven', 370),\n",
       " ('british', 370),\n",
       " ('hot', 370),\n",
       " ('heart', 369),\n",
       " ('fake', 369),\n",
       " ('reading', 369),\n",
       " ('hear', 368),\n",
       " ('weird', 368),\n",
       " ('incredibly', 368),\n",
       " ('enjoyed', 367),\n",
       " ('musical', 367),\n",
       " ('cop', 367),\n",
       " ('hilarious', 367),\n",
       " ('happy', 366),\n",
       " ('message', 366),\n",
       " ('pay', 366),\n",
       " ('box', 365),\n",
       " ('laughs', 365),\n",
       " ('sadly', 363),\n",
       " ('suspense', 363),\n",
       " ('eye', 362),\n",
       " ('similar', 361),\n",
       " ('named', 361),\n",
       " ('third', 361),\n",
       " ('modern', 360),\n",
       " ('failed', 359),\n",
       " ('events', 359),\n",
       " ('forget', 358),\n",
       " ('question', 358),\n",
       " ('finds', 357),\n",
       " ('male', 357),\n",
       " ('perfect', 356),\n",
       " ('sister', 355),\n",
       " ('spent', 355),\n",
       " ('result', 354),\n",
       " ('feature', 354),\n",
       " ('comment', 353),\n",
       " ('girlfriend', 353),\n",
       " ('sexual', 352),\n",
       " ('richard', 351),\n",
       " ('attempts', 351),\n",
       " ('neither', 351),\n",
       " ('screenplay', 350),\n",
       " ('elements', 350),\n",
       " ('spoilers', 349),\n",
       " ('filmmakers', 348),\n",
       " ('brain', 348),\n",
       " ('showing', 348),\n",
       " ('christmas', 347),\n",
       " ('miss', 347),\n",
       " ('dr', 347),\n",
       " ('cover', 345),\n",
       " ('sequences', 344),\n",
       " ('red', 344),\n",
       " ('typical', 343),\n",
       " ('excuse', 343),\n",
       " ('ideas', 342),\n",
       " ('baby', 342),\n",
       " ('crazy', 342),\n",
       " ('meant', 341),\n",
       " ('loved', 341),\n",
       " ('worked', 340),\n",
       " ('fire', 340),\n",
       " ('follow', 339),\n",
       " ('unbelievable', 339),\n",
       " ('theme', 337),\n",
       " ('plus', 336),\n",
       " ('producers', 336),\n",
       " ('twist', 336),\n",
       " ('appear', 336),\n",
       " ('barely', 336),\n",
       " ('team', 335),\n",
       " ('directors', 335),\n",
       " ('viewers', 333),\n",
       " ('tom', 332),\n",
       " ('leads', 332),\n",
       " ('slasher', 332),\n",
       " ('wrote', 331),\n",
       " ('villain', 331),\n",
       " ('working', 331),\n",
       " ('gun', 331),\n",
       " ('open', 330),\n",
       " ('island', 330),\n",
       " ('realize', 330),\n",
       " ('strong', 330),\n",
       " ('positive', 329),\n",
       " ('quickly', 329),\n",
       " ('disappointing', 329),\n",
       " ('yeah', 329),\n",
       " ('weren', 328),\n",
       " ('simple', 328),\n",
       " ('release', 328),\n",
       " ('honestly', 328),\n",
       " ('period', 327),\n",
       " ('eventually', 327),\n",
       " ('kills', 327),\n",
       " ('doctor', 327),\n",
       " ('tells', 327),\n",
       " ('herself', 326),\n",
       " ('acted', 326),\n",
       " ('list', 326),\n",
       " ('nowhere', 326),\n",
       " ('dog', 326),\n",
       " ('walk', 325),\n",
       " ('air', 324),\n",
       " ('apart', 324),\n",
       " ('makers', 323),\n",
       " ('subject', 323),\n",
       " ('fi', 322),\n",
       " ('learn', 322),\n",
       " ('admit', 319),\n",
       " ('bother', 319),\n",
       " ('sci', 319),\n",
       " ('disappointment', 318),\n",
       " ('hands', 318),\n",
       " ('note', 318),\n",
       " ('jack', 318),\n",
       " ('e', 317),\n",
       " ('certain', 317),\n",
       " ('casting', 317),\n",
       " ('value', 317),\n",
       " ('grade', 316),\n",
       " ('peter', 316),\n",
       " ('missing', 315),\n",
       " ('suddenly', 315),\n",
       " ('form', 313),\n",
       " ('previous', 313),\n",
       " ('break', 313),\n",
       " ('stick', 313),\n",
       " ('soundtrack', 312),\n",
       " ('surprised', 311),\n",
       " ('front', 311),\n",
       " ('expecting', 311),\n",
       " ('surprise', 310),\n",
       " ('relationship', 310),\n",
       " ('parents', 310),\n",
       " ('today', 309),\n",
       " ('shoot', 309),\n",
       " ('painful', 308),\n",
       " ('somewhere', 308),\n",
       " ('ways', 308),\n",
       " ('concept', 308),\n",
       " ('leaves', 308),\n",
       " ('ended', 308),\n",
       " ('creepy', 308),\n",
       " ('vampire', 308),\n",
       " ('th', 307),\n",
       " ('spend', 307),\n",
       " ('difficult', 306),\n",
       " ('future', 306),\n",
       " ('effect', 306),\n",
       " ('fighting', 306),\n",
       " ('street', 306),\n",
       " ('america', 305),\n",
       " ('c', 305),\n",
       " ('accent', 304),\n",
       " ('project', 302),\n",
       " ('truth', 302),\n",
       " ('joe', 301),\n",
       " ('indeed', 301),\n",
       " ('deal', 301),\n",
       " ('f', 301),\n",
       " ('rate', 300),\n",
       " ('biggest', 300),\n",
       " ('japanese', 299),\n",
       " ('paul', 299),\n",
       " ('utterly', 298),\n",
       " ('begins', 298),\n",
       " ('redeeming', 298),\n",
       " ('college', 298),\n",
       " ('disney', 297),\n",
       " ('york', 297),\n",
       " ('fairly', 297),\n",
       " ('revenge', 296),\n",
       " ('crew', 296),\n",
       " ('create', 296),\n",
       " ('cartoon', 296),\n",
       " ('outside', 295),\n",
       " ('co', 295),\n",
       " ('computer', 295),\n",
       " ('stage', 295),\n",
       " ('interested', 295),\n",
       " ('considering', 294),\n",
       " ('speak', 294),\n",
       " ('among', 294),\n",
       " ('channel', 293),\n",
       " ('towards', 293),\n",
       " ('sick', 293),\n",
       " ('particular', 292),\n",
       " ('van', 292),\n",
       " ('cause', 292),\n",
       " ('talented', 292),\n",
       " ('hair', 292),\n",
       " ('bottom', 291),\n",
       " ('reasons', 291),\n",
       " ('telling', 290),\n",
       " ('cat', 290),\n",
       " ('mediocre', 290),\n",
       " ('store', 289),\n",
       " ('supporting', 289),\n",
       " ('waiting', 288),\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_count.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_neg_ratios = Counter()\n",
    "\n",
    "for term, count in list(total_count.most_common()):\n",
    "    if(count > 100):\n",
    "        pos_neg_ratio = positive_count[term] / (negative_count[term] + 1)\n",
    "        pos_neg_ratios[term] = pos_neg_ratio\n",
    "\n",
    "for word, ratio in pos_neg_ratios.most_common():\n",
    "    if(ratio > 1):\n",
    "        pos_neg_ratios[word] = np.log(ratio)\n",
    "    else:\n",
    "        pos_neg_ratios[word] = - np.log(1/(ratio+0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('edie', 4.6913478822291435),\n",
       " ('paulie', 4.0775374439057197),\n",
       " ('felix', 3.1527360223636558),\n",
       " ('polanski', 2.8233610476132043),\n",
       " ('matthau', 2.8067217286092401),\n",
       " ('victoria', 2.6810215287142909),\n",
       " ('mildred', 2.6026896854443837),\n",
       " ('gandhi', 2.5389738710582761),\n",
       " ('flawless', 2.451005098112319),\n",
       " ('superbly', 2.2600254785752498),\n",
       " ('perfection', 2.1594842493533721),\n",
       " ('astaire', 2.1400661634962708),\n",
       " ('captures', 2.0386195471595809),\n",
       " ('voight', 2.0301704926730531),\n",
       " ('wonderfully', 2.0218960560332353),\n",
       " ('powell', 1.9783454248084671),\n",
       " ('brosnan', 1.9547990964725592),\n",
       " ('lily', 1.9203768470501485),\n",
       " ('bakshi', 1.9029851043382795),\n",
       " ('lincoln', 1.9014583864844796),\n",
       " ('refreshing', 1.8551812956655511),\n",
       " ('breathtaking', 1.8481124057791867),\n",
       " ('bourne', 1.8478489358790986),\n",
       " ('lemmon', 1.8458266904983307),\n",
       " ('delightful', 1.8002701588959635),\n",
       " ('flynn', 1.7996646487351682),\n",
       " ('andrews', 1.7764919970972666),\n",
       " ('homer', 1.7692866133759964),\n",
       " ('beautifully', 1.7626953362841438),\n",
       " ('soccer', 1.7578579175523736)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_ratios.most_common()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boll', -4.0778152602708904),\n",
       " ('uwe', -3.9218753018711578),\n",
       " ('seagal', -3.3202501058581921),\n",
       " ('unwatchable', -3.0269848170580955),\n",
       " ('stinker', -2.9876839403711624),\n",
       " ('mst', -2.7753833211707968),\n",
       " ('incoherent', -2.7641396677532537),\n",
       " ('unfunny', -2.5545257844967644),\n",
       " ('waste', -2.4907515123361046),\n",
       " ('blah', -2.4475792789485005),\n",
       " ('horrid', -2.3715779644809971),\n",
       " ('pointless', -2.3451073877136341),\n",
       " ('atrocious', -2.3187369339642556),\n",
       " ('redeeming', -2.2667790015910296),\n",
       " ('prom', -2.2601040980178784),\n",
       " ('drivel', -2.2476029585766928),\n",
       " ('lousy', -2.2118080125207054),\n",
       " ('worst', -2.1930856334332267),\n",
       " ('laughable', -2.172468615469592),\n",
       " ('awful', -2.1385076866397488),\n",
       " ('poorly', -2.1326133844207011),\n",
       " ('wasting', -2.1178155545614512),\n",
       " ('remotely', -2.111046881095167),\n",
       " ('existent', -2.0024805005437076),\n",
       " ('boredom', -1.9241486572738005),\n",
       " ('miserably', -1.9216610938019989),\n",
       " ('sucks', -1.9166645809588516),\n",
       " ('uninspired', -1.9131499212248517),\n",
       " ('lame', -1.9117232884159072),\n",
       " ('insult', -1.9085323769376259)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reversed(pos_neg_ratios.most_common()))[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Text into Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74075\n"
     ]
    }
   ],
   "source": [
    "vocab = set(total_count.keys())\n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create empty vector\n",
    "import numpy as np\n",
    "layer_0 = np.zeros((1,vocab_size))\n",
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " 'rancor': 1,\n",
       " 'tomato': 2,\n",
       " 'kassar': 3,\n",
       " 'hellman': 24401,\n",
       " 'chambermaid': 4,\n",
       " 'conquer': 5,\n",
       " 'bhatti': 49373,\n",
       " 'circulating': 9,\n",
       " 'time': 10,\n",
       " 'unyielding': 11,\n",
       " 'recapitulates': 12,\n",
       " 'arklie': 13,\n",
       " 'treeline': 14,\n",
       " 'uncomprehensible': 19,\n",
       " 'rehashes': 17,\n",
       " 'kridge': 18,\n",
       " 'accepts': 20,\n",
       " 'congregate': 57377,\n",
       " 'panoply': 22,\n",
       " 'boom': 23,\n",
       " 'camelot': 24,\n",
       " 'delarue': 25,\n",
       " 'outflanking': 28,\n",
       " 'maybee': 36802,\n",
       " 'beauteous': 30,\n",
       " 'tooled': 31,\n",
       " 'avery': 32,\n",
       " 'ghostwritten': 34,\n",
       " 'cavities': 35,\n",
       " 'molotov': 36,\n",
       " 'ktla': 37,\n",
       " 'permanently': 38,\n",
       " 'listened': 40,\n",
       " 'pauley': 42,\n",
       " 'shiva': 71519,\n",
       " 'priests': 44,\n",
       " 'recession': 24408,\n",
       " 'adoptee': 48,\n",
       " 'warping': 50,\n",
       " 'gingivitis': 6,\n",
       " 'savant': 70069,\n",
       " 'hodges': 51,\n",
       " 'adalbert': 52,\n",
       " 'kirshner': 53,\n",
       " 'junior': 56,\n",
       " 'cheesier': 57,\n",
       " 'machinations': 36809,\n",
       " 'seast': 58,\n",
       " 'roman': 59,\n",
       " 'fretful': 60,\n",
       " 'strongbox': 61,\n",
       " 'srbljanovic': 63,\n",
       " 'confusion': 64,\n",
       " 'posses': 65,\n",
       " 'waaaaaaaaaaay': 70,\n",
       " 'evaluate': 69,\n",
       " 'atkins': 68158,\n",
       " 'kitaparaporn': 71,\n",
       " 'flamed': 72,\n",
       " 'wisbar': 78,\n",
       " 'bissonnette': 74,\n",
       " 'gypsies': 75,\n",
       " 'unowns': 76,\n",
       " 'catty': 80,\n",
       " 'dart': 49385,\n",
       " 'uchida': 79,\n",
       " 'raincoat': 84,\n",
       " 'humiliates': 82,\n",
       " 'twice': 83,\n",
       " 'tripods': 85,\n",
       " 'hydro': 86,\n",
       " 'carvings': 87,\n",
       " 'buffaloes': 12138,\n",
       " 'ling': 88,\n",
       " 'nukem': 62057,\n",
       " 'trespasses': 91,\n",
       " 'amnesic': 90,\n",
       " 'ashes': 55021,\n",
       " 'koun': 24418,\n",
       " 'cus': 93,\n",
       " 'advance': 94,\n",
       " 'latimore': 12142,\n",
       " 'wrightly': 95,\n",
       " 'whizzpopping': 97,\n",
       " 'nibelungen': 100,\n",
       " 'automata': 101,\n",
       " 'drillers': 102,\n",
       " 'postscript': 105,\n",
       " 'tamakwa': 104,\n",
       " 'catholic': 61099,\n",
       " 'presumptuous': 107,\n",
       " 'hamer': 55171,\n",
       " 'daeseleire': 108,\n",
       " 'theorically': 110,\n",
       " 'synthesized': 5848,\n",
       " 'indellible': 115,\n",
       " 'refuel': 112,\n",
       " 'killing': 113,\n",
       " 'pictured': 24424,\n",
       " 'decoding': 36818,\n",
       " 'gasmann': 116,\n",
       " 'liebe': 117,\n",
       " 'entertain': 118,\n",
       " 'ingratiating': 16,\n",
       " 'madchen': 65460,\n",
       " 'optic': 119,\n",
       " 'beng': 120,\n",
       " 'travestite': 125,\n",
       " 'lao': 61806,\n",
       " 'modesty': 123,\n",
       " 'poutily': 124,\n",
       " 'shian': 126,\n",
       " 'exploitive': 128,\n",
       " 'cant': 129,\n",
       " 'goethe': 130,\n",
       " 'courius': 131,\n",
       " 'hamlet': 132,\n",
       " 'disasterous': 134,\n",
       " 'sufferings': 135,\n",
       " 'chicka': 28268,\n",
       " 'genre': 137,\n",
       " 'glenda': 12150,\n",
       " 'je': 138,\n",
       " 'hohl': 139,\n",
       " 'anxieties': 140,\n",
       " 'atley': 141,\n",
       " 'insisted': 65526,\n",
       " 'hmmmmmmmmm': 142,\n",
       " 'mendez': 143,\n",
       " 'handycams': 144,\n",
       " 'ensigns': 145,\n",
       " 'concur': 52632,\n",
       " 'cellular': 146,\n",
       " 'kaal': 147,\n",
       " 'mushy': 148,\n",
       " 'feast': 149,\n",
       " 'talkative': 150,\n",
       " 'tiags': 153,\n",
       " 'proportionately': 156,\n",
       " 'formation': 154,\n",
       " 'sences': 155,\n",
       " 'misjudges': 157,\n",
       " 'cowards': 158,\n",
       " 'fanu': 159,\n",
       " 'crawl': 160,\n",
       " 'drainpipe': 61817,\n",
       " 'frightens': 61816,\n",
       " 'preplanning': 161,\n",
       " 'caledon': 163,\n",
       " 'abattoirs': 164,\n",
       " 'discolored': 63704,\n",
       " 'garrison': 165,\n",
       " 'divider': 167,\n",
       " 'turgidly': 168,\n",
       " 'stan': 169,\n",
       " 'cattleman': 64471,\n",
       " 'dunning': 170,\n",
       " 'lanza': 171,\n",
       " 'kiran': 172,\n",
       " 'biljana': 173,\n",
       " 'embarrassment': 174,\n",
       " 'tirade': 175,\n",
       " 'acquiring': 49399,\n",
       " 'hirehotmail': 178,\n",
       " 'hayami': 179,\n",
       " 'jeunet': 12157,\n",
       " 'continents': 180,\n",
       " 'cannell': 182,\n",
       " 'parkers': 183,\n",
       " 'christopher': 67406,\n",
       " 'inarticulated': 184,\n",
       " 'kennedy': 72447,\n",
       " 'namaste': 185,\n",
       " 'cuddling': 186,\n",
       " 'hoof': 26,\n",
       " 'militaries': 189,\n",
       " 'hier': 190,\n",
       " 'spines': 191,\n",
       " 'gladiatorial': 28890,\n",
       " 'antiwar': 193,\n",
       " 'acquire': 10981,\n",
       " 'prospect': 68300,\n",
       " 'handwriting': 12162,\n",
       " 'whisker': 194,\n",
       " 'erhardt': 197,\n",
       " 'spam': 196,\n",
       " 'franfreako': 200,\n",
       " 'compositing': 201,\n",
       " 'cran': 30342,\n",
       " 'shirtless': 24445,\n",
       " 'replayable': 202,\n",
       " 'beamont': 28106,\n",
       " 'enquiry': 203,\n",
       " 'elaborately': 204,\n",
       " 'mend': 205,\n",
       " 'crimany': 206,\n",
       " 'yali': 208,\n",
       " 'mclellan': 211,\n",
       " 'charting': 212,\n",
       " 'misconstrued': 24449,\n",
       " 'untrue': 213,\n",
       " 'overstimulate': 33,\n",
       " 'each': 214,\n",
       " 'anglicised': 215,\n",
       " 'underlie': 216,\n",
       " 'publicised': 217,\n",
       " 'subcontracted': 218,\n",
       " 'verst': 61827,\n",
       " 'cyclon': 49589,\n",
       " 'jonas': 49409,\n",
       " 'discharged': 219,\n",
       " 'galen': 221,\n",
       " 'guietary': 222,\n",
       " 'theodore': 223,\n",
       " 'collen': 224,\n",
       " 'counting': 225,\n",
       " 'ignite': 226,\n",
       " 'receptionist': 228,\n",
       " 'drunkard': 49412,\n",
       " 'tratment': 229,\n",
       " 'chocked': 232,\n",
       " 'appereantly': 231,\n",
       " 'flipping': 233,\n",
       " 'fancies': 235,\n",
       " 'lascher': 36839,\n",
       " 'wastrels': 236,\n",
       " 'airphone': 40018,\n",
       " 'celia': 237,\n",
       " 'willoughby': 238,\n",
       " 'unjustly': 239,\n",
       " 'justification': 39,\n",
       " 'hrithik': 242,\n",
       " 'reilly': 241,\n",
       " 'pickers': 244,\n",
       " 'capably': 245,\n",
       " 'tarp': 246,\n",
       " 'banality': 61835,\n",
       " 'makeout': 41,\n",
       " 'giamatti': 247,\n",
       " 'incoherently': 248,\n",
       " 'galactic': 249,\n",
       " 'huitieme': 69261,\n",
       " 'amoeba': 250,\n",
       " 'indelicate': 257,\n",
       " 'mes': 252,\n",
       " 'retirony': 256,\n",
       " 'thermal': 255,\n",
       " 'pervasive': 65914,\n",
       " 'dunwich': 258,\n",
       " 'sudhir': 259,\n",
       " 'aloo': 261,\n",
       " 'repudiation': 45,\n",
       " 'fercryinoutloud': 65313,\n",
       " 'smarmy': 263,\n",
       " 'coulier': 264,\n",
       " 'widman': 265,\n",
       " 'muddily': 267,\n",
       " 'swanston': 61109,\n",
       " 'splitting': 70745,\n",
       " 'gentileschi': 269,\n",
       " 'phocion': 270,\n",
       " 'garvin': 271,\n",
       " 'enabled': 273,\n",
       " 'desu': 49421,\n",
       " 'pedagogue': 274,\n",
       " 'scrambles': 275,\n",
       " 'epitomized': 276,\n",
       " 'vejigante': 61844,\n",
       " 'french': 278,\n",
       " 'concerts': 280,\n",
       " 'pawnshop': 64479,\n",
       " 'denom': 281,\n",
       " 'disappearing': 47,\n",
       " 'addendum': 282,\n",
       " 'forensics': 283,\n",
       " 'alow': 284,\n",
       " 'baz': 285,\n",
       " 'calibration': 16591,\n",
       " 'uality': 286,\n",
       " 'preview': 287,\n",
       " 'sand': 57949,\n",
       " 'helipad': 291,\n",
       " 'looonnnggg': 49423,\n",
       " 'upswept': 293,\n",
       " 'ones': 49,\n",
       " 'squirt': 295,\n",
       " 'tannen': 296,\n",
       " 'kodak': 298,\n",
       " 'complicitor': 301,\n",
       " 'picard': 302,\n",
       " 'sasha': 303,\n",
       " 'tingles': 304,\n",
       " 'responsibility': 305,\n",
       " 'garishly': 306,\n",
       " 'jambalaya': 308,\n",
       " 'aortic': 309,\n",
       " 'silverstone': 53946,\n",
       " 'inaccessible': 310,\n",
       " 'confessing': 70077,\n",
       " 'retina': 312,\n",
       " 'eagerly': 49429,\n",
       " 'beter': 313,\n",
       " 'disliked': 59508,\n",
       " 'generous': 315,\n",
       " 'hardwick': 60052,\n",
       " 'lackies': 54,\n",
       " 'pelican': 318,\n",
       " 'splintered': 319,\n",
       " 'dogeared': 46925,\n",
       " 'dartboard': 55,\n",
       " 'orin': 52452,\n",
       " 'snort': 320,\n",
       " 'mutters': 321,\n",
       " 'restricting': 322,\n",
       " 'friggin': 323,\n",
       " 'cote': 326,\n",
       " 'jangling': 24478,\n",
       " 'wolitzer': 327,\n",
       " 'conceive': 328,\n",
       " 'unapologetically': 329,\n",
       " 'orenji': 330,\n",
       " 'welcomed': 331,\n",
       " 'conceals': 24480,\n",
       " 'interactive': 49434,\n",
       " 'cspan': 332,\n",
       " 'kolchack': 36857,\n",
       " 'guilgud': 333,\n",
       " 'cred': 24481,\n",
       " 'dubious': 12188,\n",
       " 'haberland': 334,\n",
       " 'alock': 336,\n",
       " 'progressives': 64616,\n",
       " 'finishers': 36862,\n",
       " 'occupation': 337,\n",
       " 'shaved': 339,\n",
       " 'acurately': 65528,\n",
       " 'macneille': 340,\n",
       " 'rewinds': 12190,\n",
       " 'hyeong': 36861,\n",
       " 'churchman': 61858,\n",
       " 'manipulation': 341,\n",
       " 'cindi': 24489,\n",
       " 'ballerina': 342,\n",
       " 'vying': 343,\n",
       " 'titian': 344,\n",
       " 'bochner': 12193,\n",
       " 'oppressing': 55579,\n",
       " 'midkiff': 346,\n",
       " 'seed': 347,\n",
       " 'profanity': 348,\n",
       " 'closeup': 350,\n",
       " 'tintin': 352,\n",
       " 'summum': 353,\n",
       " 'dishum': 61863,\n",
       " 'computability': 31446,\n",
       " 'drewbie': 357,\n",
       " 'vaughan': 355,\n",
       " 'combusts': 362,\n",
       " 'bytch': 361,\n",
       " 'galumphing': 359,\n",
       " 'goings': 360,\n",
       " 'thierot': 363,\n",
       " 'hearse': 49443,\n",
       " 'guilts': 364,\n",
       " 'weave': 365,\n",
       " 'particulare': 66,\n",
       " 'eeyore': 366,\n",
       " 'loach': 367,\n",
       " 'kindled': 368,\n",
       " 'disinformation': 24494,\n",
       " 'ulrike': 370,\n",
       " 'conway': 12201,\n",
       " 'hollander': 373,\n",
       " 'christers': 374,\n",
       " 'snickers': 51693,\n",
       " 'infantryman': 375,\n",
       " 'herriman': 376,\n",
       " 'rehire': 377,\n",
       " 'indulgently': 67733,\n",
       " 'bosnian': 378,\n",
       " 'proudest': 380,\n",
       " 'meters': 381,\n",
       " 'pyromaniac': 382,\n",
       " 'coldness': 383,\n",
       " 'wouters': 384,\n",
       " 'migrates': 12203,\n",
       " 'cyphers': 36873,\n",
       " 'fixing': 385,\n",
       " 'nutters': 390,\n",
       " 'munster': 387,\n",
       " 'furtive': 389,\n",
       " 'rb': 391,\n",
       " 'avariciously': 393,\n",
       " 'cothk': 394,\n",
       " 'descas': 73,\n",
       " 'experimenter': 395,\n",
       " 'caultron': 396,\n",
       " 'audrey': 397,\n",
       " 'bwahahha': 72631,\n",
       " 'vinyl': 48170,\n",
       " 'tvnz': 398,\n",
       " 'polygamist': 399,\n",
       " 'explorative': 400,\n",
       " 'sigfried': 401,\n",
       " 'happen': 402,\n",
       " 'qian': 404,\n",
       " 'plying': 405,\n",
       " 'stayer': 406,\n",
       " 'pennslyvania': 410,\n",
       " 'harltey': 408,\n",
       " 'outrunning': 409,\n",
       " 'nogami': 411,\n",
       " 'gualtieri': 61870,\n",
       " 'balcony': 412,\n",
       " 'orloff': 413,\n",
       " 'snowy': 414,\n",
       " 'satta': 36878,\n",
       " 'hagerthy': 415,\n",
       " 'mails': 417,\n",
       " 'mileage': 418,\n",
       " 'romero': 419,\n",
       " 'grenades': 420,\n",
       " 'sequiter': 421,\n",
       " 'yugonostalgic': 422,\n",
       " 'latch': 423,\n",
       " 'unobserved': 424,\n",
       " 'jongchan': 425,\n",
       " 'malcontent': 426,\n",
       " 'kalmus': 427,\n",
       " 'echos': 428,\n",
       " 'quinns': 429,\n",
       " 'denting': 433,\n",
       " 'minigenre': 431,\n",
       " 'reclaiming': 432,\n",
       " 'deliberate': 49453,\n",
       " 'machiavellian': 36884,\n",
       " 'helpfully': 436,\n",
       " 'nagase': 438,\n",
       " 'meant': 439,\n",
       " 'breaths': 440,\n",
       " 'logon': 441,\n",
       " 'droney': 442,\n",
       " 'purposefully': 444,\n",
       " 'snowbank': 445,\n",
       " 'jd': 446,\n",
       " 'contend': 447,\n",
       " 'cheesie': 24502,\n",
       " 'ruphert': 448,\n",
       " 'tolerates': 449,\n",
       " 'jmes': 450,\n",
       " 'mammals': 451,\n",
       " 'compromises': 452,\n",
       " 'cashiers': 456,\n",
       " 'geno': 457,\n",
       " 'annapolis': 455,\n",
       " 'yeeshhhhhhhhhhhhhhhhh': 458,\n",
       " 'raja': 459,\n",
       " 'compton': 463,\n",
       " 'comming': 464,\n",
       " 'dubiously': 462,\n",
       " 'heeding': 467,\n",
       " 'khushi': 468,\n",
       " 'apologises': 469,\n",
       " 'aestheticism': 470,\n",
       " 'came': 471,\n",
       " 'moralising': 473,\n",
       " 'nymphet': 475,\n",
       " 'nickelodeon': 478,\n",
       " 'vuissa': 479,\n",
       " 'cleo': 480,\n",
       " 'lugacy': 481,\n",
       " 'zarustica': 483,\n",
       " 'confess': 25812,\n",
       " 'gavin': 484,\n",
       " 'barricading': 89,\n",
       " 'comedienne': 485,\n",
       " 'thatwasjunk': 486,\n",
       " 'hssh': 24508,\n",
       " 'shimkus': 488,\n",
       " 'protective': 72122,\n",
       " 'leaping': 489,\n",
       " 'kitagawa': 490,\n",
       " 'fruit': 12219,\n",
       " 'convicting': 491,\n",
       " 'fountainhead': 492,\n",
       " 'revolved': 493,\n",
       " 'razzies': 494,\n",
       " 'thinks': 495,\n",
       " 'levitating': 496,\n",
       " 'serum': 497,\n",
       " 'gentlemanlike': 498,\n",
       " 'proofs': 499,\n",
       " 'redemptions': 500,\n",
       " 'stef': 502,\n",
       " 'whites': 503,\n",
       " 'welch': 505,\n",
       " 'toppan': 507,\n",
       " 'dispositions': 508,\n",
       " 'sorceries': 509,\n",
       " 'opined': 71304,\n",
       " 'distinctly': 510,\n",
       " 'brendan': 24515,\n",
       " 'kutuzov': 49465,\n",
       " 'condescending': 511,\n",
       " 'consensus': 70162,\n",
       " 'strive': 64306,\n",
       " 'ajeeb': 515,\n",
       " 'annunziata': 513,\n",
       " 'scaredy': 514,\n",
       " 'rigg': 516,\n",
       " 'hypothermic': 12224,\n",
       " 'brideless': 517,\n",
       " 'externals': 518,\n",
       " 'sauraus': 24517,\n",
       " 'collectivity': 23681,\n",
       " 'yaayyyyy': 12228,\n",
       " 'clasic': 67710,\n",
       " 'cocker': 524,\n",
       " 'fatality': 521,\n",
       " 'pack': 522,\n",
       " 'firewood': 523,\n",
       " 'acquittal': 525,\n",
       " 'michalka': 526,\n",
       " 'sniping': 527,\n",
       " 'calcified': 529,\n",
       " 'ismael': 530,\n",
       " 'dredd': 531,\n",
       " 'countdown': 532,\n",
       " 'ayurvedic': 49468,\n",
       " 'benefiting': 533,\n",
       " 'reputationally': 534,\n",
       " 'dangan': 72794,\n",
       " 'paragraphs': 535,\n",
       " 'disnefluff': 61883,\n",
       " 'laudenbach': 536,\n",
       " 'lada': 537,\n",
       " 'chased': 61885,\n",
       " 'batmobile': 538,\n",
       " 'ganja': 539,\n",
       " 'dines': 540,\n",
       " 'rooker': 541,\n",
       " 'scrotal': 543,\n",
       " 'kohara': 544,\n",
       " 'implants': 545,\n",
       " 'nontheless': 25499,\n",
       " 'kursk': 547,\n",
       " 'candlesticks': 17356,\n",
       " 'parlour': 550,\n",
       " 'wishy': 549,\n",
       " 'unamusing': 551,\n",
       " 'nandini': 49472,\n",
       " 'micawbers': 554,\n",
       " 'scala': 553,\n",
       " 'hedley': 555,\n",
       " 'hippie': 556,\n",
       " 'boozer': 557,\n",
       " 'incovenient': 61888,\n",
       " 'unwholesome': 559,\n",
       " 'friends': 560,\n",
       " 'orphaned': 568,\n",
       " 'kirchenbauer': 564,\n",
       " 'homeys': 565,\n",
       " 'blandings': 566,\n",
       " 'overlooking': 569,\n",
       " 'invaluable': 570,\n",
       " 'vw': 571,\n",
       " 'ornamental': 572,\n",
       " 'roemenian': 573,\n",
       " 'nacho': 574,\n",
       " 'undefeatable': 575,\n",
       " 'sarcasm': 576,\n",
       " 'immerse': 61890,\n",
       " 'bandaged': 577,\n",
       " 'channel': 578,\n",
       " 'cultures': 103,\n",
       " 'stapes': 4870,\n",
       " 'jaws': 580,\n",
       " 'cultivating': 581,\n",
       " 'amp': 583,\n",
       " 'odysessy': 106,\n",
       " 'understating': 586,\n",
       " 'nines': 587,\n",
       " 'sadoul': 588,\n",
       " 'breathable': 589,\n",
       " 'sleazeball': 590,\n",
       " 'hierarchical': 4522,\n",
       " 'rhetorically': 12240,\n",
       " 'dod': 591,\n",
       " 'williams': 592,\n",
       " 'boundary': 61894,\n",
       " 'balanchine': 593,\n",
       " 'foodie': 30134,\n",
       " 'gwtw': 595,\n",
       " 'expires': 596,\n",
       " 'pelicule': 597,\n",
       " 'resuming': 68321,\n",
       " 'cimarron': 12243,\n",
       " 'reminisces': 598,\n",
       " 'threaten': 599,\n",
       " 'savored': 602,\n",
       " 'rolffes': 603,\n",
       " 'gwizdo': 604,\n",
       " 'shahrukh': 607,\n",
       " 'becouse': 608,\n",
       " 'negro': 68981,\n",
       " 'glimpse': 609,\n",
       " 'jacuzzi': 611,\n",
       " 'boulevardier': 61900,\n",
       " 'punster': 612,\n",
       " 'trapeze': 614,\n",
       " 'luncheon': 615,\n",
       " 'anteroom': 616,\n",
       " 'leaner': 618,\n",
       " 'toughed': 61903,\n",
       " 'squadrons': 619,\n",
       " 'caudillos': 61550,\n",
       " 'nobodies': 36918,\n",
       " 'perfectionist': 620,\n",
       " 'tenenbaums': 19663,\n",
       " 'strut': 621,\n",
       " 'boondocks': 622,\n",
       " 'burress': 623,\n",
       " 'ryszard': 52074,\n",
       " 'fixes': 49486,\n",
       " 'elkam': 624,\n",
       " 'stogumber': 54582,\n",
       " 'fims': 60380,\n",
       " 'alimony': 626,\n",
       " 'fish': 627,\n",
       " 'relationships': 628,\n",
       " 'slained': 629,\n",
       " 'relocates': 630,\n",
       " 'eggbert': 631,\n",
       " 'offense': 36921,\n",
       " 'overstep': 633,\n",
       " 'birkin': 638,\n",
       " 'laughting': 634,\n",
       " 'seize': 635,\n",
       " 'eschews': 636,\n",
       " 'joiner': 111,\n",
       " 'gunning': 639,\n",
       " 'durden': 640,\n",
       " 'jasbir': 114,\n",
       " 'capitalizing': 641,\n",
       " 'overworked': 642,\n",
       " 'marit': 643,\n",
       " 'audley': 644,\n",
       " 'enthusiasm': 645,\n",
       " 'recherche': 652,\n",
       " 'laster': 647,\n",
       " 'francen': 649,\n",
       " 'squat': 42070,\n",
       " 'ites': 650,\n",
       " 'gabbing': 68093,\n",
       " 'mcgavin': 57564,\n",
       " 'waggoner': 653,\n",
       " 'thunk': 12256,\n",
       " 'hesitation': 654,\n",
       " 'gross': 655,\n",
       " 'astutely': 72970,\n",
       " 'impacting': 658,\n",
       " 'knowledgeable': 24534,\n",
       " 'unflashy': 660,\n",
       " 'tin': 661,\n",
       " 'trudged': 662,\n",
       " 'bonk': 664,\n",
       " 'stale': 665,\n",
       " 'sufficient': 34903,\n",
       " 'gringoire': 667,\n",
       " 'rescuers': 668,\n",
       " 'downright': 672,\n",
       " 'wetters': 670,\n",
       " 'commendations': 671,\n",
       " 'jinx': 673,\n",
       " 'storage': 674,\n",
       " 'gantlet': 24537,\n",
       " 'myspace': 676,\n",
       " 'dango': 677,\n",
       " 'randomized': 679,\n",
       " 'flickering': 36927,\n",
       " 'myc': 681,\n",
       " 'woch': 682,\n",
       " 'sophisticated': 683,\n",
       " 'showiness': 684,\n",
       " 'elicited': 685,\n",
       " 'adnausem': 12261,\n",
       " 'minding': 686,\n",
       " 'shane': 687,\n",
       " 'shrubbery': 688,\n",
       " 'furtherance': 690,\n",
       " 'scriptures': 691,\n",
       " 'respects': 24541,\n",
       " 'effluvia': 692,\n",
       " 'mentality': 693,\n",
       " 'discombobulation': 694,\n",
       " 'landholdings': 695,\n",
       " 'pickaxes': 696,\n",
       " 'basicly': 698,\n",
       " 'algerians': 699,\n",
       " 'shaul': 700,\n",
       " 'gubbels': 122,\n",
       " 'clarinett': 24544,\n",
       " 'griffiths': 701,\n",
       " 'ooky': 703,\n",
       " 'kells': 61915,\n",
       " 'stockpile': 705,\n",
       " 'fairbrass': 706,\n",
       " 'megahit': 707,\n",
       " 'drifts': 710,\n",
       " 'di': 711,\n",
       " 'chairs': 53172,\n",
       " 'successor': 61919,\n",
       " 'impetus': 712,\n",
       " 'chabrol': 61920,\n",
       " 'niece': 713,\n",
       " 'sautet': 49501,\n",
       " 'understood': 715,\n",
       " 'michaelango': 716,\n",
       " 'viral': 40258,\n",
       " 'fizzy': 54631,\n",
       " 'reliable': 718,\n",
       " 'watanbe': 719,\n",
       " 'noirish': 720,\n",
       " 'inches': 721,\n",
       " 'luciferian': 722,\n",
       " 'tgmb': 726,\n",
       " 'keel': 725,\n",
       " 'amateuristic': 727,\n",
       " 'buccaneering': 729,\n",
       " 'popistasu': 730,\n",
       " 'sweatshirt': 731,\n",
       " 'sentimentalising': 732,\n",
       " 'perrineau': 740,\n",
       " 'bufford': 734,\n",
       " 'fit': 735,\n",
       " 'insector': 736,\n",
       " 'fronts': 737,\n",
       " 'informer': 738,\n",
       " 'cinemablend': 739,\n",
       " 'pessimism': 741,\n",
       " 'havegotten': 742,\n",
       " 'goodspeed': 743,\n",
       " 'twinkies': 745,\n",
       " 'befriends': 127,\n",
       " 'tobias': 61924,\n",
       " 'precluded': 49507,\n",
       " 'settles': 746,\n",
       " 'thingee': 747,\n",
       " 'pleasantvillesque': 24555,\n",
       " 'kf': 749,\n",
       " 'satirising': 750,\n",
       " 'combats': 754,\n",
       " 'kelly': 752,\n",
       " 'abvious': 753,\n",
       " 'bohemia': 755,\n",
       " 'umaga': 760,\n",
       " 'venezuelan': 757,\n",
       " 'miiko': 759,\n",
       " 'censors': 761,\n",
       " 'schlub': 762,\n",
       " 'dismay': 51851,\n",
       " 'baldly': 763,\n",
       " 'caretaker': 764,\n",
       " 'outback': 765,\n",
       " 'hither': 766,\n",
       " 'shihomi': 767,\n",
       " 'giannini': 768,\n",
       " 'essenay': 769,\n",
       " 'branaughs': 771,\n",
       " 'salton': 774,\n",
       " 'percepts': 773,\n",
       " 'steep': 776,\n",
       " 'puppetry': 777,\n",
       " 'wolfy': 24562,\n",
       " 'attilla': 39483,\n",
       " 'arranges': 778,\n",
       " 'blueprints': 48254,\n",
       " 'filmfest': 779,\n",
       " 'meaney': 36016,\n",
       " 'roar': 780,\n",
       " 'bloody': 781,\n",
       " 'nyugen': 24564,\n",
       " 'umbrella': 782,\n",
       " 'bambou': 784,\n",
       " 'gamezone': 785,\n",
       " 'tyrranical': 790,\n",
       " 'fetching': 789,\n",
       " 'elpidia': 136,\n",
       " 'indefensible': 793,\n",
       " 'samu': 794,\n",
       " 'germinates': 795,\n",
       " 'unformulaic': 796,\n",
       " 'crave': 797,\n",
       " 'quarrel': 799,\n",
       " 'pendragon': 800,\n",
       " 'hastings': 801,\n",
       " 'sagely': 24568,\n",
       " 'baseline': 803,\n",
       " 'chauffeured': 804,\n",
       " 'manfish': 805,\n",
       " 'daoism': 807,\n",
       " 'unnaturally': 808,\n",
       " 'kusakari': 809,\n",
       " 'responsive': 811,\n",
       " 'freakish': 812,\n",
       " 'alldredge': 813,\n",
       " 'puffing': 814,\n",
       " 'rauschen': 817,\n",
       " 'condoned': 54646,\n",
       " 'ramboesque': 821,\n",
       " 'jal': 819,\n",
       " 'topless': 820,\n",
       " 'shanty': 822,\n",
       " 'fours': 823,\n",
       " 'duperrey': 825,\n",
       " 'hearsay': 49521,\n",
       " 'rascally': 826,\n",
       " 'heartbreakingly': 51428,\n",
       " 'phallus': 827,\n",
       " 'stripteases': 39395,\n",
       " 'neilsen': 828,\n",
       " 'hypothesizing': 829,\n",
       " 'matheson': 36951,\n",
       " 'videodisc': 830,\n",
       " 'vulneable': 831,\n",
       " 'parasitic': 832,\n",
       " 'schlingensief': 833,\n",
       " 'fomenting': 834,\n",
       " 'contingent': 51797,\n",
       " 'sadists': 835,\n",
       " 'trys': 63379,\n",
       " 'vice': 36954,\n",
       " 'attic': 28368,\n",
       " 'crap': 49524,\n",
       " 'suess': 836,\n",
       " 'exterior': 837,\n",
       " 'auteil': 838,\n",
       " 'tuff': 839,\n",
       " 'diffidence': 842,\n",
       " 'enlivened': 841,\n",
       " 'corrado': 843,\n",
       " 'backgrounds': 844,\n",
       " 'mics': 49527,\n",
       " 'handpicks': 845,\n",
       " 'sodium': 847,\n",
       " 'potenta': 848,\n",
       " 'forged': 850,\n",
       " 'buisnesswoman': 852,\n",
       " 'daily': 853,\n",
       " 'steenky': 20378,\n",
       " 'macintosh': 24577,\n",
       " 'devilment': 54935,\n",
       " 'gentlemenin': 854,\n",
       " 'guitry': 855,\n",
       " 'moldy': 61796,\n",
       " 'obfuscated': 856,\n",
       " 'lost': 857,\n",
       " 'rubbishes': 858,\n",
       " 'entomologist': 24581,\n",
       " 'invisibly': 861,\n",
       " 'photoshop': 862,\n",
       " 'multimedia': 863,\n",
       " 'breakdowns': 61944,\n",
       " 'danvers': 865,\n",
       " 'lovelace': 12295,\n",
       " 'couturie': 866,\n",
       " 'dysfunctional': 867,\n",
       " 'defecate': 868,\n",
       " 'shipped': 869,\n",
       " 'easterners': 24582,\n",
       " 'sedahl': 870,\n",
       " 'maidens': 871,\n",
       " 'consults': 872,\n",
       " 'humanizing': 873,\n",
       " 'firmament': 877,\n",
       " 'takashima': 876,\n",
       " 'cp': 878,\n",
       " 'theodorakis': 879,\n",
       " 'elem': 880,\n",
       " 'winfield': 881,\n",
       " 'walken': 49535,\n",
       " 'maneur': 882,\n",
       " 'denial': 883,\n",
       " 'putain': 65393,\n",
       " 'sob': 887,\n",
       " 'magna': 885,\n",
       " 'defecated': 886,\n",
       " 'paltrow': 889,\n",
       " 'thieriot': 890,\n",
       " 'balthasar': 891,\n",
       " 'wimmen': 892,\n",
       " 'coasted': 893,\n",
       " 'roam': 894,\n",
       " 'unrecommended': 36966,\n",
       " 'waterworld': 895,\n",
       " 'rigor': 896,\n",
       " 'lena': 897,\n",
       " 'similar': 898,\n",
       " 'trueness': 899,\n",
       " 'vajna': 51604,\n",
       " 'noise': 900,\n",
       " 'vandeuvres': 52517,\n",
       " 'mckim': 72266,\n",
       " 'artists': 901,\n",
       " 'fusing': 902,\n",
       " 'joyously': 903,\n",
       " 'doped': 904,\n",
       " 'canet': 905,\n",
       " 'wound': 57707,\n",
       " 'quintet': 906,\n",
       " 'wiliams': 909,\n",
       " 'contemplations': 908,\n",
       " 'ohh': 912,\n",
       " 'moshimo': 911,\n",
       " 'golino': 916,\n",
       " 'preys': 914,\n",
       " 'lengthened': 915,\n",
       " 'tedesco': 917,\n",
       " 'chineseness': 918,\n",
       " 'vaccination': 919,\n",
       " 'illuminates': 920,\n",
       " 'filmfare': 921,\n",
       " 'levenstein': 922,\n",
       " 'nolan': 923,\n",
       " 'imam': 924,\n",
       " 'yuzna': 925,\n",
       " 'opine': 927,\n",
       " 'authored': 61958,\n",
       " 'subgenera': 928,\n",
       " 'vladimr': 929,\n",
       " 'violante': 930,\n",
       " 'transgenic': 931,\n",
       " 'speaker': 935,\n",
       " 'shitters': 933,\n",
       " 'illuminations': 934,\n",
       " 'portfolio': 151,\n",
       " 'tollinger': 936,\n",
       " 'nauseated': 937,\n",
       " 'perkins': 152,\n",
       " 'niall': 939,\n",
       " 'welk': 943,\n",
       " 'norden': 941,\n",
       " 'uber': 942,\n",
       " 'turnings': 944,\n",
       " 'jiggly': 945,\n",
       " 'tediously': 947,\n",
       " 'fuddy': 948,\n",
       " 'raghavan': 950,\n",
       " 'talker': 36971,\n",
       " 'smugness': 951,\n",
       " 'mclagen': 952,\n",
       " 'howarth': 953,\n",
       " 'eine': 954,\n",
       " 'villians': 956,\n",
       " 'nirmal': 61960,\n",
       " 'moisture': 957,\n",
       " 'mascot': 958,\n",
       " 'dario': 959,\n",
       " 'kayaks': 960,\n",
       " 'orsen': 961,\n",
       " 'international': 49548,\n",
       " 'impkins': 962,\n",
       " 'pierce': 5687,\n",
       " 'pm': 49549,\n",
       " 'purply': 965,\n",
       " 'karaindrou': 964,\n",
       " 'tableware': 61963,\n",
       " 'manged': 966,\n",
       " 'itching': 967,\n",
       " 'bettger': 52407,\n",
       " 'mortgage': 968,\n",
       " 'voluntarily': 969,\n",
       " 'maltese': 970,\n",
       " 'chutzpah': 49551,\n",
       " 'frollo': 971,\n",
       " 'knowable': 972,\n",
       " 'braid': 973,\n",
       " 'agonizingly': 974,\n",
       " 'acknowledgment': 975,\n",
       " 'initiate': 976,\n",
       " 'valrie': 977,\n",
       " 'thunderdome': 50618,\n",
       " 'dreamquest': 978,\n",
       " 'dolemite': 979,\n",
       " 'shiina': 980,\n",
       " 'duminic': 982,\n",
       " 'fredos': 983,\n",
       " 'blossomed': 984,\n",
       " 'taayla': 985,\n",
       " 'dressing': 986,\n",
       " 'springing': 987,\n",
       " 'disharmoniously': 989,\n",
       " 'valentina': 990,\n",
       " 'glria': 991,\n",
       " 'trademarked': 992,\n",
       " 'delighted': 993,\n",
       " 'mispronunciation': 53217,\n",
       " 'edtv': 994,\n",
       " 'hauptmann': 73530,\n",
       " ...}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create word to index\n",
    "word2index = {}\n",
    "\n",
    "for i, word in enumerate(vocab):\n",
    "    word2index[word] = i\n",
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18.,   0.,   0., ...,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_input_layer(review):\n",
    "    global layer_0\n",
    "    layer_0 *= 0\n",
    "    for word in review.split(\" \"):\n",
    "        layer_0[0][word2index[word]] += 1\n",
    "\n",
    "update_input_layer(reviews_clean[0])\n",
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_target_for_label(label):\n",
    "    if(label == \"positive\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "get_target_for_label(labels_clean[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Let's tweak our network from before to model these phenomena\n",
    "class SentimentNetwork:\n",
    "    def __init__(self, reviews,labels,hidden_nodes = 10, learning_rate = 0.1):\n",
    "       \n",
    "        # set our random number generator \n",
    "        np.random.seed(1)\n",
    "    \n",
    "        self.pre_process_data(reviews, labels)\n",
    "        \n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "        \n",
    "        \n",
    "    def pre_process_data(self, reviews, labels):\n",
    "        \n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                review_vocab.add(word)\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "         \n",
    "        \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "    \n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "    \n",
    "        \n",
    "    def update_input_layer(self,review):\n",
    "\n",
    "        # clear out previous state, reset the layer to be all 0s\n",
    "        self.layer_0 *= 0\n",
    "        for word in review.split(\" \"):\n",
    "            if(word in self.word2index.keys()):\n",
    "                self.layer_0[0][self.word2index[word]] += 1\n",
    "                \n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'positive'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def train(self, training_reviews, training_labels):\n",
    "        \n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        correct_so_far = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            #### Implement the forward pass here ####\n",
    "            ### Forward pass ###\n",
    "\n",
    "            # Input Layer\n",
    "            self.update_input_layer(review)\n",
    "\n",
    "            # Hidden layer\n",
    "            layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "            # Output layer\n",
    "            layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "\n",
    "            #### Implement the backward pass here ####\n",
    "            ### Backward pass ###\n",
    "\n",
    "            # TODO: Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # TODO: Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) # errors propagated to the hidden layer\n",
    "            layer_1_delta = layer_1_error # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "\n",
    "            # TODO: Update the weights\n",
    "            self.weights_1_2 -= layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "            self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
    "\n",
    "            if(np.abs(layer_2_error) < 0.5):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \n",
    "        correct = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                            + \"% #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \n",
    "        # Input Layer\n",
    "        self.update_input_layer(review.lower())\n",
    "\n",
    "        # Hidden layer\n",
    "        layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        if(layer_2[0] > 0.5):\n",
    "            return \"positive\"\n",
    "        else:\n",
    "            return \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp = SentimentNetwork(reviews_clean[:-1000], labels_clean[:-1000], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):535.9% #Correct:500 #Tested:1000 Testing Accuracy:50.0%"
     ]
    }
   ],
   "source": [
    "# evaluate our model before training (just to show how horrible it is)\n",
    "mlp.test(reviews_clean[-1000:],labels_clean[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n",
      "Progress:1.87% Speed(reviews/sec):79.63 #Correct:225 #Trained:452 Training Accuracy:49.7%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isaac/anaconda3/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:75: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:10.4% Speed(reviews/sec):83.27 #Correct:1249 #Trained:2501 Training Accuracy:49.9%\n",
      "Progress:14.2% Speed(reviews/sec):82.15 #Correct:1709 #Trained:3421 Training Accuracy:49.9%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-22fad3e31860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-791649e0dc3b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_reviews, training_labels)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m# TODO: Update the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_1_2\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlayer_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_2_delta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;31m# update hidden-to-output weights with gradient descent step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_0_1\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_1_delta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;31m# update input-to-hidden weights with gradient descent step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_2_error\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp.train(reviews_clean[:-1000],labels_clean[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = SentimentNetwork(reviews_clean[:-1000],labels_clean[:-1000], learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n",
      "Progress:10.4% Speed(reviews/sec):87.76 #Correct:1247 #Trained:2501 Training Accuracy:49.8%\n",
      "Progress:20.8% Speed(reviews/sec):86.57 #Correct:2497 #Trained:5001 Training Accuracy:49.9%\n",
      "Progress:21.1% Speed(reviews/sec):86.50 #Correct:2532 #Trained:5070 Training Accuracy:49.9%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-dccd702b61f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-791649e0dc3b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_reviews, training_labels)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# Hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mlayer_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_0_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# Output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "mlp.train(reviews_clean[:-1000],labels_clean[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = SentimentNetwork(reviews_clean[:-1000],labels_clean[:-1000], learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n",
      "Progress:10.4% Speed(reviews/sec):83.26 #Correct:1265 #Trained:2501 Training Accuracy:50.5%\n",
      "Progress:20.8% Speed(reviews/sec):81.42 #Correct:2651 #Trained:5001 Training Accuracy:53.0%\n",
      "Progress:23.0% Speed(reviews/sec):80.91 #Correct:2960 #Trained:5521 Training Accuracy:53.6%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-dccd702b61f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-791649e0dc3b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_reviews, training_labels)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mreviews_per_second\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\rProgress:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"% Speed(reviews/sec):\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_per_second\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" #Correct:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_so_far\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" #Trained:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Training Accuracy:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_so_far\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/isaac/anaconda3/envs/tflearn/lib/python3.5/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                 \u001b[0;31m# newlines imply flush in subprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/isaac/anaconda3/envs/tflearn/lib/python3.5/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mevent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevent_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send (zmq/backend/cython/socket.c:7305)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send (zmq/backend/cython/socket.c:7048)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy (zmq/backend/cython/socket.c:2920)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/isaac/anaconda3/envs/tflearn/lib/python3.5/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:9621)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "mlp.train(reviews_clean[:-1000],labels_clean[:-1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By reducing the learning rate, the neural network is not improving the accuracy fast enough, so we need to change the structure to improve the model\n",
    "\n",
    "### Analyze the signal vs. noise\n",
    "\n",
    "## Understand Neural Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18.,   0.,   0., ...,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vocab)[0]\n",
    "# A noise here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bromwell',\n",
       " 'high',\n",
       " 'is',\n",
       " 'a',\n",
       " 'cartoon',\n",
       " 'comedy',\n",
       " '.',\n",
       " 'it',\n",
       " 'ran',\n",
       " 'at',\n",
       " 'the',\n",
       " 'same',\n",
       " 'time',\n",
       " 'as',\n",
       " 'some',\n",
       " 'other',\n",
       " 'programs',\n",
       " 'about',\n",
       " 'school',\n",
       " 'life',\n",
       " '',\n",
       " 'such',\n",
       " 'as',\n",
       " '',\n",
       " 'teachers',\n",
       " '',\n",
       " '.',\n",
       " 'my',\n",
       " '',\n",
       " '',\n",
       " 'years',\n",
       " 'in',\n",
       " 'the',\n",
       " 'teaching',\n",
       " 'profession',\n",
       " 'lead',\n",
       " 'me',\n",
       " 'to',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'bromwell',\n",
       " 'high',\n",
       " '',\n",
       " 's',\n",
       " 'satire',\n",
       " 'is',\n",
       " 'much',\n",
       " 'closer',\n",
       " 'to',\n",
       " 'reality',\n",
       " 'than',\n",
       " 'is',\n",
       " '',\n",
       " 'teachers',\n",
       " '',\n",
       " '.',\n",
       " 'the',\n",
       " 'scramble',\n",
       " 'to',\n",
       " 'survive',\n",
       " 'financially',\n",
       " '',\n",
       " 'the',\n",
       " 'insightful',\n",
       " 'students',\n",
       " 'who',\n",
       " 'can',\n",
       " 'see',\n",
       " 'right',\n",
       " 'through',\n",
       " 'their',\n",
       " 'pathetic',\n",
       " 'teachers',\n",
       " '',\n",
       " 'pomp',\n",
       " '',\n",
       " 'the',\n",
       " 'pettiness',\n",
       " 'of',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'situation',\n",
       " '',\n",
       " 'all',\n",
       " 'remind',\n",
       " 'me',\n",
       " 'of',\n",
       " 'the',\n",
       " 'schools',\n",
       " 'i',\n",
       " 'knew',\n",
       " 'and',\n",
       " 'their',\n",
       " 'students',\n",
       " '.',\n",
       " 'when',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'the',\n",
       " 'episode',\n",
       " 'in',\n",
       " 'which',\n",
       " 'a',\n",
       " 'student',\n",
       " 'repeatedly',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'burn',\n",
       " 'down',\n",
       " 'the',\n",
       " 'school',\n",
       " '',\n",
       " 'i',\n",
       " 'immediately',\n",
       " 'recalled',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'at',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'high',\n",
       " '.',\n",
       " 'a',\n",
       " 'classic',\n",
       " 'line',\n",
       " 'inspector',\n",
       " 'i',\n",
       " '',\n",
       " 'm',\n",
       " 'here',\n",
       " 'to',\n",
       " 'sack',\n",
       " 'one',\n",
       " 'of',\n",
       " 'your',\n",
       " 'teachers',\n",
       " '.',\n",
       " 'student',\n",
       " 'welcome',\n",
       " 'to',\n",
       " 'bromwell',\n",
       " 'high',\n",
       " '.',\n",
       " 'i',\n",
       " 'expect',\n",
       " 'that',\n",
       " 'many',\n",
       " 'adults',\n",
       " 'of',\n",
       " 'my',\n",
       " 'age',\n",
       " 'think',\n",
       " 'that',\n",
       " 'bromwell',\n",
       " 'high',\n",
       " 'is',\n",
       " 'far',\n",
       " 'fetched',\n",
       " '.',\n",
       " 'what',\n",
       " 'a',\n",
       " 'pity',\n",
       " 'that',\n",
       " 'it',\n",
       " 'isn',\n",
       " '',\n",
       " 't',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_clean[0].split(\" \")\n",
    "# A lot of empty, period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 27),\n",
       " ('', 18),\n",
       " ('the', 9),\n",
       " ('to', 6),\n",
       " ('high', 5),\n",
       " ('i', 5),\n",
       " ('that', 4),\n",
       " ('teachers', 4),\n",
       " ('a', 4),\n",
       " ('bromwell', 4),\n",
       " ('of', 4),\n",
       " ('is', 4),\n",
       " ('me', 2),\n",
       " ('at', 2),\n",
       " ('in', 2),\n",
       " ('student', 2),\n",
       " ('students', 2),\n",
       " ('school', 2),\n",
       " ('my', 2),\n",
       " ('as', 2),\n",
       " ('their', 2),\n",
       " ('it', 2),\n",
       " ('pathetic', 1),\n",
       " ('see', 1),\n",
       " ('inspector', 1),\n",
       " ('much', 1),\n",
       " ('fetched', 1),\n",
       " ('satire', 1),\n",
       " ('reality', 1),\n",
       " ('time', 1),\n",
       " ('lead', 1),\n",
       " ('same', 1),\n",
       " ('isn', 1),\n",
       " ('episode', 1),\n",
       " ('knew', 1),\n",
       " ('which', 1),\n",
       " ('immediately', 1),\n",
       " ('programs', 1),\n",
       " ('classic', 1),\n",
       " ('who', 1),\n",
       " ('cartoon', 1),\n",
       " ('think', 1),\n",
       " ('pity', 1),\n",
       " ('t', 1),\n",
       " ('expect', 1),\n",
       " ('other', 1),\n",
       " ('burn', 1),\n",
       " ('here', 1),\n",
       " ('believe', 1),\n",
       " ('ran', 1),\n",
       " ('and', 1),\n",
       " ('tried', 1),\n",
       " ('many', 1),\n",
       " ('profession', 1),\n",
       " ('your', 1),\n",
       " ('remind', 1),\n",
       " ('life', 1),\n",
       " ('welcome', 1),\n",
       " ('one', 1),\n",
       " ('when', 1),\n",
       " ('saw', 1),\n",
       " ('years', 1),\n",
       " ('pomp', 1),\n",
       " ('down', 1),\n",
       " ('some', 1),\n",
       " ('financially', 1),\n",
       " ('s', 1),\n",
       " ('far', 1),\n",
       " ('what', 1),\n",
       " ('whole', 1),\n",
       " ('survive', 1),\n",
       " ('closer', 1),\n",
       " ('schools', 1),\n",
       " ('insightful', 1),\n",
       " ('repeatedly', 1),\n",
       " ('sack', 1),\n",
       " ('can', 1),\n",
       " ('right', 1),\n",
       " ('adults', 1),\n",
       " ('line', 1),\n",
       " ('teaching', 1),\n",
       " ('m', 1),\n",
       " ('pettiness', 1),\n",
       " ('scramble', 1),\n",
       " ('such', 1),\n",
       " ('about', 1),\n",
       " ('all', 1),\n",
       " ('recalled', 1),\n",
       " ('comedy', 1),\n",
       " ('age', 1),\n",
       " ('situation', 1),\n",
       " ('than', 1),\n",
       " ('through', 1)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many period is in the review\n",
    "review_counter = Counter()\n",
    "for word in reviews_clean[0].split(\" \"):\n",
    "    review_counter[word] += 1\n",
    "review_counter.most_common()\n",
    "# The result below shows the dominant word has nothing to do\n",
    "# with the sentiment, the weighting has a dominant effect on the hidden layer\n",
    "# the count weighs heavily on the noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Noise in the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Let's tweak our network from before to model these phenomena\n",
    "class SentimentNetwork_2:\n",
    "    def __init__(self, reviews,labels,hidden_nodes = 10, learning_rate = 0.1):\n",
    "       \n",
    "        # set our random number generator \n",
    "        np.random.seed(1)\n",
    "    \n",
    "        self.pre_process_data(reviews, labels)\n",
    "        \n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "        \n",
    "        \n",
    "    def pre_process_data(self, reviews, labels):\n",
    "        \n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                review_vocab.add(word)\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "         \n",
    "        \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "    \n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "    \n",
    "        \n",
    "    def update_input_layer(self,review):\n",
    "\n",
    "        # clear out previous state, reset the layer to be all 0s\n",
    "        self.layer_0 *= 0\n",
    "        for word in review.split(\" \"):\n",
    "            if(word in self.word2index.keys()):\n",
    "                self.layer_0[0][self.word2index[word]] = 1\n",
    "        # While update layers, do not increment, change the counts to binary\n",
    "        # eliminate neural noises\n",
    "        \n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'positive'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def train(self, training_reviews, training_labels):\n",
    "        \n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        correct_so_far = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            #### Implement the forward pass here ####\n",
    "            ### Forward pass ###\n",
    "\n",
    "            # Input Layer\n",
    "            self.update_input_layer(review)\n",
    "\n",
    "            # Hidden layer\n",
    "            layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "            # Output layer\n",
    "            layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "\n",
    "            #### Implement the backward pass here ####\n",
    "            ### Backward pass ###\n",
    "\n",
    "            # TODO: Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # TODO: Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) # errors propagated to the hidden layer\n",
    "            layer_1_delta = layer_1_error # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "\n",
    "            # TODO: Update the weights\n",
    "            self.weights_1_2 -= layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "            self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
    "\n",
    "            if(np.abs(layer_2_error) < 0.5):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \n",
    "        correct = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                            + \"% #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \n",
    "        # Input Layer\n",
    "        self.update_input_layer(review.lower())\n",
    "\n",
    "        # Hidden layer\n",
    "        layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        if(layer_2[0] > 0.5):\n",
    "            return \"positive\"\n",
    "        else:\n",
    "            return \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_2 = SentimentNetwork_2(reviews_clean[:-1000], labels_clean[:-1000], learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n",
      "Progress:10.4% Speed(reviews/sec):85.14 #Correct:1811 #Trained:2501 Training Accuracy:72.4%\n",
      "Progress:20.8% Speed(reviews/sec):83.53 #Correct:3799 #Trained:5001 Training Accuracy:75.9%\n",
      "Progress:31.2% Speed(reviews/sec):82.87 #Correct:5884 #Trained:7501 Training Accuracy:78.4%\n",
      "Progress:41.6% Speed(reviews/sec):86.69 #Correct:8029 #Trained:10001 Training Accuracy:80.2%\n",
      "Progress:52.0% Speed(reviews/sec):91.05 #Correct:10164 #Trained:12501 Training Accuracy:81.3%\n",
      "Progress:62.5% Speed(reviews/sec):94.44 #Correct:12284 #Trained:15001 Training Accuracy:81.8%\n",
      "Progress:72.9% Speed(reviews/sec):98.31 #Correct:14414 #Trained:17501 Training Accuracy:82.3%\n",
      "Progress:83.3% Speed(reviews/sec):101.3 #Correct:16589 #Trained:20001 Training Accuracy:82.9%\n",
      "Progress:93.7% Speed(reviews/sec):103.9 #Correct:18775 #Trained:22501 Training Accuracy:83.4%\n",
      "Progress:99.9% Speed(reviews/sec):105.2 #Correct:20091 #Trained:24000 Training Accuracy:83.7%"
     ]
    }
   ],
   "source": [
    "mlp_2.train(reviews_clean[:-1000], labels_clean[:-1000])\n",
    "#Significant improvement after removing noise\n",
    "#But the training speed seems really slow a.k.a inefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):504.1% #Correct:854 #Tested:1000 Testing Accuracy:85.4%"
     ]
    }
   ],
   "source": [
    "mlp_2.test(reviews_clean[-1000:], labels_clean[-1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inefficiency is caused by the large zeros input\n",
    "1. Only care about the non-zero input calculation in the neural network\n",
    "2. 1 multiplication is also wasting time\n",
    "\n",
    "## Increase code efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Let's tweak our network from before to model these phenomena\n",
    "class SentimentNetwork_3:\n",
    "    def __init__(self, reviews,labels,hidden_nodes = 10, learning_rate = 0.1):\n",
    "       \n",
    "        # set our random number generator \n",
    "        np.random.seed(1)\n",
    "    \n",
    "        self.pre_process_data(reviews, labels)\n",
    "        \n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "        \n",
    "        \n",
    "    def pre_process_data(self, reviews, labels):\n",
    "        \n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                review_vocab.add(word)\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "         \n",
    "        \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "    \n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "        self.layer_1 = np.zeros((1,hidden_nodes))\n",
    "        \n",
    "    def update_input_layer(self,review):\n",
    "\n",
    "        # clear out previous state, reset the layer to be all 0s\n",
    "        self.layer_0 *= 0\n",
    "        for word in review.split(\" \"):\n",
    "            if(word in self.word2index.keys()):\n",
    "                self.layer_0[0][self.word2index[word]] = 1\n",
    "        # While update layers, do not increment, change the counts to binary\n",
    "        # eliminate neural noises\n",
    "        \n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'positive'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def train(self, training_reviews_raw, training_labels):\n",
    "        \n",
    "        training_reviews = list()\n",
    "        \n",
    "        for review in training_reviews_raw:\n",
    "            indices = set()\n",
    "            for word in review.split(\" \"):\n",
    "                if(word in self.word2index.keys()):\n",
    "                    indices.add(self.word2index[word])\n",
    "            training_reviews.append(list(indices))\n",
    "        \n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        correct_so_far = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            #### Implement the forward pass here ####\n",
    "            ### Forward pass ###\n",
    "\n",
    "            # Input Layer\n",
    "            # Can completely skip generating input layer\n",
    "            # self.update_input_layer(review)\n",
    "\n",
    "            # Hidden layer\n",
    "            # layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "            self.layer_1 *= 0\n",
    "            for index in review:\n",
    "                self.layer_1 += self.weights_0_1[index]\n",
    "            \n",
    "            # Output layer\n",
    "            layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))\n",
    "\n",
    "            #### Implement the backward pass here ####\n",
    "            ### Backward pass ###\n",
    "\n",
    "            # TODO: Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # TODO: Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) # errors propagated to the hidden layer\n",
    "            layer_1_delta = layer_1_error # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "\n",
    "            # TODO: Update the weights\n",
    "            self.weights_1_2 -= self.layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "            #self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
    "            \n",
    "            for index in review:\n",
    "                self.weights_0_1[index] -= layer_1_delta[0] * self.learning_rate\n",
    "            \n",
    "            if(np.abs(layer_2_error) < 0.5):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \n",
    "        correct = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                            + \"% #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \n",
    "        # Input Layer\n",
    "        \n",
    "\n",
    "        # Hidden layer\n",
    "        self.layer_1 *= 0\n",
    "        unique_indices = set()\n",
    "        \n",
    "        for word in review.lower().split(\" \"):\n",
    "            if word in self.word2index.keys():\n",
    "                unique_indices.add(self.word2index[word])\n",
    "        for index in unique_indices:\n",
    "            self.layer_1 += self.weights_0_1[index]\n",
    "            \n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        if(layer_2[0] > 0.5):\n",
    "            return \"positive\"\n",
    "        else:\n",
    "            return \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp_3 = SentimentNetwork_3(reviews_clean[:-1000], labels_clean[:-1000], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n",
      "Progress:10.4% Speed(reviews/sec):767.0 #Correct:1819 #Trained:2501 Training Accuracy:72.7%\n",
      "Progress:20.8% Speed(reviews/sec):566.4 #Correct:3800 #Trained:5001 Training Accuracy:75.9%\n",
      "Progress:31.2% Speed(reviews/sec):557.6 #Correct:5882 #Trained:7501 Training Accuracy:78.4%\n",
      "Progress:41.6% Speed(reviews/sec):543.2 #Correct:8018 #Trained:10001 Training Accuracy:80.1%\n",
      "Progress:52.0% Speed(reviews/sec):529.9 #Correct:10162 #Trained:12501 Training Accuracy:81.2%\n",
      "Progress:62.5% Speed(reviews/sec):506.8 #Correct:12298 #Trained:15001 Training Accuracy:81.9%\n",
      "Progress:72.9% Speed(reviews/sec):498.1 #Correct:14420 #Trained:17501 Training Accuracy:82.3%\n",
      "Progress:83.3% Speed(reviews/sec):492.0 #Correct:16606 #Trained:20001 Training Accuracy:83.0%\n",
      "Progress:93.7% Speed(reviews/sec):484.7 #Correct:18796 #Trained:22501 Training Accuracy:83.5%\n",
      "Progress:99.9% Speed(reviews/sec):477.8 #Correct:20120 #Trained:24000 Training Accuracy:83.8%"
     ]
    }
   ],
   "source": [
    "mlp_3.train(reviews_clean[:-1000], labels_clean[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):454.9% #Correct:500 #Tested:1000 Testing Accuracy:50.0%"
     ]
    }
   ],
   "source": [
    "mlp_3.test(reviews_clean[-1000:], labels_clean[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "# Let's tweak our network from before to model these phenomena\n",
    "class SentimentNetwork_3T:\n",
    "    def __init__(self, reviews,labels,hidden_nodes = 10, learning_rate = 0.1):\n",
    "       \n",
    "        np.random.seed(1)\n",
    "    \n",
    "        self.pre_process_data(reviews)\n",
    "        \n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "        \n",
    "        \n",
    "    def pre_process_data(self,reviews):\n",
    "        \n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                review_vocab.add(word)\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "         \n",
    "        \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "    \n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "        self.layer_1 = np.zeros((1,hidden_nodes))\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def update_input_layer(self,review):\n",
    "\n",
    "        # clear out previous state, reset the layer to be all 0s\n",
    "        self.layer_0 *= 0\n",
    "        for word in review.split(\" \"):\n",
    "            self.layer_0[0][self.word2index[word]] = 1\n",
    "\n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'positive'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def train(self, training_reviews_raw, training_labels):\n",
    "        \n",
    "        training_reviews = list()\n",
    "        for review in training_reviews_raw:\n",
    "            indices = set()\n",
    "            for word in review.split(\" \"):\n",
    "                if(word in self.word2index.keys()):\n",
    "                    indices.add(self.word2index[word])\n",
    "            training_reviews.append(list(indices))\n",
    "        \n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        correct_so_far = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            #### Implement the forward pass here ####\n",
    "            ### Forward pass ###\n",
    "\n",
    "            # Input Layer\n",
    "\n",
    "            # Hidden layer\n",
    "#             layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "            self.layer_1 *= 0\n",
    "            for index in review:\n",
    "                self.layer_1 += self.weights_0_1[index]\n",
    "            \n",
    "            # Output layer\n",
    "            layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))\n",
    "\n",
    "            #### Implement the backward pass here ####\n",
    "            ### Backward pass ###\n",
    "\n",
    "            # Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) # errors propagated to the hidden layer\n",
    "            layer_1_delta = layer_1_error # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "\n",
    "            # Update the weights\n",
    "            self.weights_1_2 -= self.layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "            \n",
    "            for index in review:\n",
    "                self.weights_0_1[index] -= layer_1_delta[0] * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
    "\n",
    "            if(np.abs(layer_2_error) < 0.5):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "        \n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \n",
    "        correct = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                            + \"% #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \n",
    "        # Input Layer\n",
    "\n",
    "\n",
    "        # Hidden layer\n",
    "        self.layer_1 *= 0\n",
    "        unique_indices = set()\n",
    "        for word in review.lower().split(\" \"):\n",
    "            if word in self.word2index.keys():\n",
    "                unique_indices.add(self.word2index[word])\n",
    "        for index in unique_indices:\n",
    "            self.layer_1 += self.weights_0_1[index]\n",
    "        \n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        if(layer_2[0] > 0.5):\n",
    "            return \"positive\"\n",
    "        else:\n",
    "            return \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_3_T = SentimentNetwork_3T(reviews_clean[:-1000], labels_clean[:-1000], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):765.3 #Correct:20120 #Trained:24000 Training Accuracy:83.8%"
     ]
    }
   ],
   "source": [
    "mlp_3_T.train(reviews_clean[:-1000], labels_clean[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):991.1% #Correct:860 #Tested:1000 Testing Accuracy:86.0%"
     ]
    }
   ],
   "source": [
    "mlp_3_T.test(reviews_clean[-1000:], labels_clean[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tflearn]",
   "language": "python",
   "name": "conda-env-tflearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
