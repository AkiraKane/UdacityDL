{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define path to the data\n",
    "## Ubuntu path\n",
    "#path = \"/home/isaac/UdacityDL/SentiAna/Trask/\"\n",
    "## Windows path\n",
    "path = \"C:/UdacityDL/SentiAna/Trask/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(path+\"reviews.txt\", \"r+\") as file:\n",
    "    reviews = file.readlines() \n",
    "    ##use readlines as it will be separated by \\n; read will read the whole thing as one big chunk of array\n",
    "    file.close()\n",
    "\n",
    "with open(path+\"labels.txt\", \"r+\") as file:\n",
    "    labels = file.readlines()\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0]\n",
    "## Notice \\n at the end of each review[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]\n",
    "## Notice \\n at the end of each label[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_clean = list(map(lambda x: x[:-1], reviews))\n",
    "reviews_clean[0][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_clean = list(map(lambda x: x[:-1], labels))\n",
    "labels_clean[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Theory Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18244, 22412,  6544,  8154,  3746, 23707, 12420,   239, 15748, 16805])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_rand = np.random.randint(0,len(reviews_clean),10)\n",
    "my_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive : the title got my attention and then i wondered what will come out in the plot  as we have seen so ma\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "positive : my personal feeling is that you cannot divorce this movie from its political  historical underpinnin\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "positive : this is cult stuff . my friends and i get together once a year to enjoy this movie . its very funny \n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "positive : i  m tired of people judging films on their  historical accuracy  . it  s a movie people   the write\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "positive : my fondness for chris rock varies with his movies  i hated him after lethal weapon   but i hated eve\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "negative : i  d never heard of this  then found out it  s the man with the deadly lens  which i  d heard of but\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "positive : this is one of those rare movies  it  s lovely and compelling  dignified and quirky  a true gift . i\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "negative : last weekend i bought this  zombie movie  from the bargain bin and watched it with some friends thin\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "positive : it follows block  heads and a chump at oxford  two films that are hard to top . not that saps at sea\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "negative : over the last   years the majority of british films are about how horribly poverty stricken the uk i\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for num in my_rand:\n",
    "    print(labels_clean[num]+\" : \"+reviews_clean[num][:100]+\"\\n\")\n",
    "    print(\"-\"*110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Initialization\n",
    "positive_count = Counter()\n",
    "negative_count = Counter()\n",
    "total_count = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(reviews)):\n",
    "    if(labels_clean[i] == \"positive\"):\n",
    "        for word in reviews[i].split(\" \"):\n",
    "            positive_count[word] += 1\n",
    "            total_count[word] += 1\n",
    "    else:\n",
    "        for word in reviews[i].split(\" \"):\n",
    "            negative_count[word] += 1\n",
    "            total_count[word] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 537968),\n",
       " ('the', 173324),\n",
       " ('.', 159654),\n",
       " ('and', 89722),\n",
       " ('a', 83688),\n",
       " ('of', 76855),\n",
       " ('to', 66746),\n",
       " ('is', 57245),\n",
       " ('in', 50215),\n",
       " ('br', 49235),\n",
       " ('it', 48025),\n",
       " ('i', 40743),\n",
       " ('that', 35630),\n",
       " ('this', 35080),\n",
       " ('s', 33815),\n",
       " ('as', 26308),\n",
       " ('with', 23247),\n",
       " ('for', 22416),\n",
       " ('was', 21917),\n",
       " ('film', 20937),\n",
       " ('but', 20822),\n",
       " ('movie', 19074),\n",
       " ('his', 17227),\n",
       " ('on', 17008),\n",
       " ('you', 16681),\n",
       " ('he', 16282),\n",
       " ('are', 14807),\n",
       " ('not', 14272),\n",
       " ('t', 13720),\n",
       " ('one', 13655),\n",
       " ('have', 12587),\n",
       " ('\\n', 12500),\n",
       " ('be', 12416),\n",
       " ('by', 11997),\n",
       " ('all', 11942),\n",
       " ('who', 11464),\n",
       " ('an', 11294),\n",
       " ('at', 11234),\n",
       " ('from', 10767),\n",
       " ('her', 10474),\n",
       " ('they', 9895),\n",
       " ('has', 9186),\n",
       " ('so', 9154),\n",
       " ('like', 9038),\n",
       " ('about', 8313),\n",
       " ('very', 8305),\n",
       " ('out', 8134),\n",
       " ('there', 8057),\n",
       " ('she', 7779),\n",
       " ('what', 7737),\n",
       " ('or', 7732),\n",
       " ('good', 7720),\n",
       " ('more', 7521),\n",
       " ('when', 7456),\n",
       " ('some', 7441),\n",
       " ('if', 7285),\n",
       " ('just', 7152),\n",
       " ('can', 7001),\n",
       " ('story', 6780),\n",
       " ('time', 6515),\n",
       " ('my', 6488),\n",
       " ('great', 6419),\n",
       " ('well', 6405),\n",
       " ('up', 6321),\n",
       " ('which', 6267),\n",
       " ('their', 6107),\n",
       " ('see', 6026),\n",
       " ('also', 5550),\n",
       " ('we', 5531),\n",
       " ('really', 5476),\n",
       " ('would', 5400),\n",
       " ('will', 5218),\n",
       " ('me', 5167),\n",
       " ('had', 5148),\n",
       " ('only', 5137),\n",
       " ('him', 5018),\n",
       " ('even', 4964),\n",
       " ('most', 4864),\n",
       " ('other', 4858),\n",
       " ('were', 4782),\n",
       " ('first', 4755),\n",
       " ('than', 4736),\n",
       " ('much', 4685),\n",
       " ('its', 4622),\n",
       " ('no', 4574),\n",
       " ('into', 4544),\n",
       " ('people', 4479),\n",
       " ('best', 4319),\n",
       " ('love', 4301),\n",
       " ('get', 4272),\n",
       " ('how', 4213),\n",
       " ('life', 4199),\n",
       " ('been', 4189),\n",
       " ('because', 4079),\n",
       " ('way', 4036),\n",
       " ('do', 3941),\n",
       " ('made', 3823),\n",
       " ('films', 3813),\n",
       " ('them', 3805),\n",
       " ('after', 3800),\n",
       " ('many', 3766),\n",
       " ('two', 3733),\n",
       " ('too', 3659),\n",
       " ('think', 3655),\n",
       " ('movies', 3586),\n",
       " ('characters', 3560),\n",
       " ('character', 3514),\n",
       " ('don', 3468),\n",
       " ('man', 3460),\n",
       " ('show', 3432),\n",
       " ('watch', 3424),\n",
       " ('seen', 3414),\n",
       " ('then', 3358),\n",
       " ('little', 3341),\n",
       " ('still', 3340),\n",
       " ('make', 3303),\n",
       " ('could', 3237),\n",
       " ('never', 3226),\n",
       " ('being', 3217),\n",
       " ('where', 3173),\n",
       " ('does', 3069),\n",
       " ('over', 3017),\n",
       " ('any', 3002),\n",
       " ('while', 2899),\n",
       " ('know', 2833),\n",
       " ('did', 2790),\n",
       " ('years', 2758),\n",
       " ('here', 2740),\n",
       " ('ever', 2734),\n",
       " ('end', 2696),\n",
       " ('these', 2694),\n",
       " ('such', 2590),\n",
       " ('real', 2568),\n",
       " ('scene', 2567),\n",
       " ('back', 2547),\n",
       " ('those', 2485),\n",
       " ('though', 2475),\n",
       " ('off', 2463),\n",
       " ('new', 2458),\n",
       " ('your', 2453),\n",
       " ('go', 2440),\n",
       " ('acting', 2437),\n",
       " ('plot', 2432),\n",
       " ('world', 2429),\n",
       " ('scenes', 2427),\n",
       " ('say', 2414),\n",
       " ('through', 2409),\n",
       " ('makes', 2390),\n",
       " ('better', 2381),\n",
       " ('now', 2368),\n",
       " ('work', 2346),\n",
       " ('young', 2343),\n",
       " ('old', 2311),\n",
       " ('ve', 2307),\n",
       " ('find', 2272),\n",
       " ('both', 2248),\n",
       " ('before', 2177),\n",
       " ('us', 2162),\n",
       " ('again', 2158),\n",
       " ('series', 2153),\n",
       " ('quite', 2143),\n",
       " ('something', 2135),\n",
       " ('cast', 2133),\n",
       " ('should', 2121),\n",
       " ('part', 2098),\n",
       " ('always', 2088),\n",
       " ('lot', 2087),\n",
       " ('another', 2075),\n",
       " ('actors', 2047),\n",
       " ('director', 2040),\n",
       " ('family', 2032),\n",
       " ('between', 2016),\n",
       " ('own', 2016),\n",
       " ('m', 1998),\n",
       " ('may', 1997),\n",
       " ('same', 1972),\n",
       " ('role', 1967),\n",
       " ('watching', 1966),\n",
       " ('every', 1954),\n",
       " ('funny', 1953),\n",
       " ('doesn', 1935),\n",
       " ('performance', 1928),\n",
       " ('few', 1918),\n",
       " ('bad', 1907),\n",
       " ('look', 1900),\n",
       " ('re', 1884),\n",
       " ('why', 1855),\n",
       " ('things', 1849),\n",
       " ('times', 1832),\n",
       " ('big', 1815),\n",
       " ('however', 1795),\n",
       " ('actually', 1790),\n",
       " ('action', 1789),\n",
       " ('going', 1783),\n",
       " ('bit', 1757),\n",
       " ('comedy', 1742),\n",
       " ('down', 1740),\n",
       " ('music', 1738),\n",
       " ('must', 1728),\n",
       " ('take', 1709),\n",
       " ('saw', 1692),\n",
       " ('long', 1690),\n",
       " ('right', 1688),\n",
       " ('fun', 1686),\n",
       " ('fact', 1684),\n",
       " ('excellent', 1683),\n",
       " ('around', 1674),\n",
       " ('didn', 1672),\n",
       " ('without', 1671),\n",
       " ('thing', 1662),\n",
       " ('thought', 1639),\n",
       " ('got', 1635),\n",
       " ('each', 1630),\n",
       " ('day', 1614),\n",
       " ('feel', 1597),\n",
       " ('seems', 1596),\n",
       " ('come', 1594),\n",
       " ('done', 1586),\n",
       " ('beautiful', 1580),\n",
       " ('especially', 1572),\n",
       " ('played', 1571),\n",
       " ('almost', 1566),\n",
       " ('want', 1562),\n",
       " ('yet', 1556),\n",
       " ('give', 1553),\n",
       " ('pretty', 1549),\n",
       " ('last', 1543),\n",
       " ('since', 1519),\n",
       " ('different', 1504),\n",
       " ('although', 1501),\n",
       " ('gets', 1490),\n",
       " ('true', 1487),\n",
       " ('interesting', 1481),\n",
       " ('job', 1470),\n",
       " ('enough', 1455),\n",
       " ('our', 1454),\n",
       " ('shows', 1447),\n",
       " ('horror', 1441),\n",
       " ('woman', 1439),\n",
       " ('tv', 1400),\n",
       " ('probably', 1398),\n",
       " ('father', 1395),\n",
       " ('original', 1393),\n",
       " ('girl', 1390),\n",
       " ('point', 1379),\n",
       " ('plays', 1378),\n",
       " ('wonderful', 1372),\n",
       " ('far', 1358),\n",
       " ('course', 1358),\n",
       " ('john', 1350),\n",
       " ('rather', 1340),\n",
       " ('isn', 1328),\n",
       " ('ll', 1326),\n",
       " ('later', 1324),\n",
       " ('dvd', 1324),\n",
       " ('whole', 1310),\n",
       " ('war', 1310),\n",
       " ('d', 1307),\n",
       " ('found', 1306),\n",
       " ('away', 1306),\n",
       " ('screen', 1305),\n",
       " ('nothing', 1300),\n",
       " ('year', 1297),\n",
       " ('once', 1296),\n",
       " ('hard', 1294),\n",
       " ('together', 1280),\n",
       " ('set', 1277),\n",
       " ('am', 1277),\n",
       " ('having', 1266),\n",
       " ('making', 1265),\n",
       " ('place', 1263),\n",
       " ('might', 1260),\n",
       " ('comes', 1260),\n",
       " ('sure', 1253),\n",
       " ('american', 1248),\n",
       " ('play', 1245),\n",
       " ('kind', 1244),\n",
       " ('perfect', 1242),\n",
       " ('takes', 1242),\n",
       " ('performances', 1237),\n",
       " ('himself', 1230),\n",
       " ('worth', 1221),\n",
       " ('everyone', 1221),\n",
       " ('anyone', 1214),\n",
       " ('actor', 1203),\n",
       " ('three', 1201),\n",
       " ('wife', 1196),\n",
       " ('classic', 1192),\n",
       " ('goes', 1186),\n",
       " ('ending', 1178),\n",
       " ('version', 1168),\n",
       " ('star', 1149),\n",
       " ('enjoy', 1146),\n",
       " ('book', 1142),\n",
       " ('nice', 1132),\n",
       " ('everything', 1128),\n",
       " ('during', 1124),\n",
       " ('put', 1118),\n",
       " ('seeing', 1111),\n",
       " ('least', 1102),\n",
       " ('house', 1100),\n",
       " ('high', 1095),\n",
       " ('watched', 1094),\n",
       " ('loved', 1087),\n",
       " ('men', 1087),\n",
       " ('night', 1082),\n",
       " ('anything', 1075),\n",
       " ('believe', 1071),\n",
       " ('guy', 1071),\n",
       " ('top', 1063),\n",
       " ('amazing', 1058),\n",
       " ('hollywood', 1056),\n",
       " ('looking', 1053),\n",
       " ('main', 1044),\n",
       " ('definitely', 1043),\n",
       " ('gives', 1031),\n",
       " ('home', 1029),\n",
       " ('seem', 1028),\n",
       " ('episode', 1023),\n",
       " ('audience', 1020),\n",
       " ('sense', 1020),\n",
       " ('truly', 1017),\n",
       " ('special', 1011),\n",
       " ('second', 1009),\n",
       " ('short', 1009),\n",
       " ('fan', 1009),\n",
       " ('mind', 1005),\n",
       " ('human', 1001),\n",
       " ('recommend', 999),\n",
       " ('full', 996),\n",
       " ('black', 995),\n",
       " ('help', 991),\n",
       " ('along', 989),\n",
       " ('trying', 987),\n",
       " ('small', 986),\n",
       " ('death', 985),\n",
       " ('friends', 981),\n",
       " ('remember', 974),\n",
       " ('often', 970),\n",
       " ('said', 966),\n",
       " ('favorite', 962),\n",
       " ('heart', 959),\n",
       " ('early', 957),\n",
       " ('left', 956),\n",
       " ('until', 955),\n",
       " ('script', 954),\n",
       " ('let', 954),\n",
       " ('maybe', 937),\n",
       " ('today', 936),\n",
       " ('live', 934),\n",
       " ('less', 934),\n",
       " ('moments', 933),\n",
       " ('others', 929),\n",
       " ('brilliant', 926),\n",
       " ('shot', 925),\n",
       " ('liked', 923),\n",
       " ('become', 916),\n",
       " ('won', 915),\n",
       " ('used', 910),\n",
       " ('style', 907),\n",
       " ('mother', 895),\n",
       " ('lives', 894),\n",
       " ('came', 893),\n",
       " ('stars', 890),\n",
       " ('cinema', 889),\n",
       " ('looks', 885),\n",
       " ('perhaps', 884),\n",
       " ('read', 882),\n",
       " ('enjoyed', 879),\n",
       " ('boy', 875),\n",
       " ('drama', 873),\n",
       " ('highly', 871),\n",
       " ('given', 870),\n",
       " ('playing', 867),\n",
       " ('use', 864),\n",
       " ('next', 859),\n",
       " ('women', 858),\n",
       " ('fine', 857),\n",
       " ('effects', 856),\n",
       " ('kids', 854),\n",
       " ('entertaining', 853),\n",
       " ('need', 852),\n",
       " ('line', 850),\n",
       " ('works', 848),\n",
       " ('someone', 847),\n",
       " ('mr', 836),\n",
       " ('simply', 835),\n",
       " ('picture', 833),\n",
       " ('children', 833),\n",
       " ('face', 831),\n",
       " ('keep', 831),\n",
       " ('friend', 831),\n",
       " ('dark', 830),\n",
       " ('overall', 828),\n",
       " ('certainly', 828),\n",
       " ('minutes', 827),\n",
       " ('wasn', 824),\n",
       " ('history', 822),\n",
       " ('finally', 820),\n",
       " ('couple', 816),\n",
       " ('against', 815),\n",
       " ('son', 809),\n",
       " ('understand', 808),\n",
       " ('lost', 807),\n",
       " ('michael', 805),\n",
       " ('else', 801),\n",
       " ('throughout', 798),\n",
       " ('fans', 797),\n",
       " ('city', 792),\n",
       " ('reason', 789),\n",
       " ('written', 787),\n",
       " ('production', 787),\n",
       " ('several', 784),\n",
       " ('school', 783),\n",
       " ('based', 781),\n",
       " ('rest', 781),\n",
       " ('try', 780),\n",
       " ('dead', 776),\n",
       " ('hope', 775),\n",
       " ('strong', 768),\n",
       " ('white', 765),\n",
       " ('tell', 759),\n",
       " ('itself', 758),\n",
       " ('half', 753),\n",
       " ('person', 749),\n",
       " ('sometimes', 746),\n",
       " ('past', 744),\n",
       " ('start', 744),\n",
       " ('genre', 743),\n",
       " ('beginning', 739),\n",
       " ('final', 739),\n",
       " ('town', 738),\n",
       " ('art', 734),\n",
       " ('humor', 732),\n",
       " ('game', 732),\n",
       " ('yes', 731),\n",
       " ('idea', 731),\n",
       " ('late', 730),\n",
       " ('becomes', 729),\n",
       " ('despite', 729),\n",
       " ('able', 726),\n",
       " ('case', 726),\n",
       " ('money', 723),\n",
       " ('child', 721),\n",
       " ('completely', 721),\n",
       " ('side', 719),\n",
       " ('camera', 716),\n",
       " ('getting', 714),\n",
       " ('instead', 712),\n",
       " ('soon', 702),\n",
       " ('under', 700),\n",
       " ('viewer', 699),\n",
       " ('age', 697),\n",
       " ('days', 696),\n",
       " ('stories', 696),\n",
       " ('felt', 694),\n",
       " ('simple', 694),\n",
       " ('roles', 693),\n",
       " ('video', 688),\n",
       " ('name', 683),\n",
       " ('either', 683),\n",
       " ('doing', 677),\n",
       " ('turns', 674),\n",
       " ('wants', 671),\n",
       " ('close', 671),\n",
       " ('title', 669),\n",
       " ('wrong', 668),\n",
       " ('went', 666),\n",
       " ('james', 665),\n",
       " ('evil', 659),\n",
       " ('budget', 657),\n",
       " ('episodes', 657),\n",
       " ('relationship', 655),\n",
       " ('fantastic', 653),\n",
       " ('piece', 653),\n",
       " ('david', 651),\n",
       " ('turn', 648),\n",
       " ('murder', 646),\n",
       " ('parts', 645),\n",
       " ('brother', 644),\n",
       " ('absolutely', 643),\n",
       " ('head', 643),\n",
       " ('experience', 642),\n",
       " ('eyes', 641),\n",
       " ('sex', 638),\n",
       " ('direction', 637),\n",
       " ('called', 637),\n",
       " ('directed', 636),\n",
       " ('lines', 634),\n",
       " ('behind', 633),\n",
       " ('sort', 632),\n",
       " ('actress', 631),\n",
       " ('lead', 630),\n",
       " ('oscar', 628),\n",
       " ('including', 627),\n",
       " ('example', 627),\n",
       " ('known', 625),\n",
       " ('musical', 625),\n",
       " ('chance', 621),\n",
       " ('score', 620),\n",
       " ('already', 619),\n",
       " ('feeling', 619),\n",
       " ('hit', 619),\n",
       " ('voice', 615),\n",
       " ('moment', 612),\n",
       " ('living', 612),\n",
       " ('low', 610),\n",
       " ('supporting', 610),\n",
       " ('ago', 609),\n",
       " ('themselves', 608),\n",
       " ('reality', 605),\n",
       " ('hilarious', 605),\n",
       " ('jack', 604),\n",
       " ('told', 603),\n",
       " ('hand', 601),\n",
       " ('quality', 600),\n",
       " ('moving', 600),\n",
       " ('dialogue', 600),\n",
       " ('song', 599),\n",
       " ('happy', 599),\n",
       " ('matter', 598),\n",
       " ('paul', 598),\n",
       " ('light', 594),\n",
       " ('future', 593),\n",
       " ('entire', 592),\n",
       " ('finds', 591),\n",
       " ('gave', 589),\n",
       " ('laugh', 587),\n",
       " ('released', 586),\n",
       " ('expect', 584),\n",
       " ('fight', 581),\n",
       " ('particularly', 580),\n",
       " ('cinematography', 579),\n",
       " ('police', 579),\n",
       " ('whose', 578),\n",
       " ('type', 578),\n",
       " ('sound', 578),\n",
       " ('view', 573),\n",
       " ('enjoyable', 573),\n",
       " ('number', 572),\n",
       " ('romantic', 572),\n",
       " ('husband', 572),\n",
       " ('daughter', 572),\n",
       " ('documentary', 571),\n",
       " ('self', 570),\n",
       " ('superb', 569),\n",
       " ('modern', 569),\n",
       " ('took', 569),\n",
       " ('robert', 569),\n",
       " ('mean', 566),\n",
       " ('shown', 563),\n",
       " ('coming', 561),\n",
       " ('important', 560),\n",
       " ('king', 559),\n",
       " ('leave', 559),\n",
       " ('change', 558),\n",
       " ('somewhat', 555),\n",
       " ('wanted', 555),\n",
       " ('tells', 554),\n",
       " ('events', 552),\n",
       " ('run', 552),\n",
       " ('career', 552),\n",
       " ('country', 552),\n",
       " ('heard', 550),\n",
       " ('season', 550),\n",
       " ('greatest', 549),\n",
       " ('girls', 549),\n",
       " ('etc', 547),\n",
       " ('care', 546),\n",
       " ('starts', 545),\n",
       " ('english', 542),\n",
       " ('killer', 541),\n",
       " ('tale', 540),\n",
       " ('guys', 540),\n",
       " ('totally', 540),\n",
       " ('animation', 540),\n",
       " ('usual', 539),\n",
       " ('miss', 535),\n",
       " ('opinion', 535),\n",
       " ('easy', 531),\n",
       " ('violence', 531),\n",
       " ('songs', 530),\n",
       " ('british', 528),\n",
       " ('says', 526),\n",
       " ('realistic', 525),\n",
       " ('writing', 524),\n",
       " ('writer', 522),\n",
       " ('act', 522),\n",
       " ('comic', 521),\n",
       " ('thriller', 519),\n",
       " ('television', 517),\n",
       " ('power', 516),\n",
       " ('ones', 515),\n",
       " ('kid', 514),\n",
       " ('york', 513),\n",
       " ('novel', 513),\n",
       " ('alone', 512),\n",
       " ('problem', 512),\n",
       " ('attention', 509),\n",
       " ('involved', 508),\n",
       " ('kill', 507),\n",
       " ('extremely', 507),\n",
       " ('seemed', 506),\n",
       " ('hero', 505),\n",
       " ('french', 505),\n",
       " ('rock', 504),\n",
       " ('stuff', 501),\n",
       " ('wish', 499),\n",
       " ('begins', 498),\n",
       " ('taken', 497),\n",
       " ('sad', 497),\n",
       " ('ways', 496),\n",
       " ('richard', 495),\n",
       " ('knows', 494),\n",
       " ('atmosphere', 493),\n",
       " ('similar', 491),\n",
       " ('surprised', 491),\n",
       " ('taking', 491),\n",
       " ('car', 491),\n",
       " ('george', 490),\n",
       " ('perfectly', 490),\n",
       " ('across', 489),\n",
       " ('team', 489),\n",
       " ('eye', 489),\n",
       " ('sequence', 489),\n",
       " ('room', 488),\n",
       " ('due', 488),\n",
       " ('among', 488),\n",
       " ('serious', 488),\n",
       " ('powerful', 488),\n",
       " ('strange', 487),\n",
       " ('order', 487),\n",
       " ('cannot', 487),\n",
       " ('b', 487),\n",
       " ('beauty', 486),\n",
       " ('famous', 485),\n",
       " ('happened', 484),\n",
       " ('tries', 484),\n",
       " ('herself', 484),\n",
       " ('myself', 484),\n",
       " ('class', 483),\n",
       " ('four', 482),\n",
       " ('cool', 481),\n",
       " ('release', 479),\n",
       " ('anyway', 479),\n",
       " ('theme', 479),\n",
       " ('opening', 478),\n",
       " ('entertainment', 477),\n",
       " ('slow', 475),\n",
       " ('ends', 475),\n",
       " ('unique', 475),\n",
       " ('exactly', 475),\n",
       " ('easily', 474),\n",
       " ('level', 474),\n",
       " ('o', 474),\n",
       " ('red', 474),\n",
       " ('interest', 472),\n",
       " ('happen', 471),\n",
       " ('crime', 470),\n",
       " ('viewing', 468),\n",
       " ('sets', 467),\n",
       " ('memorable', 467),\n",
       " ('stop', 466),\n",
       " ('group', 466),\n",
       " ('problems', 463),\n",
       " ('dance', 463),\n",
       " ('working', 463),\n",
       " ('sister', 463),\n",
       " ('message', 463),\n",
       " ('knew', 462),\n",
       " ('mystery', 461),\n",
       " ('nature', 461),\n",
       " ('bring', 460),\n",
       " ('believable', 459),\n",
       " ('thinking', 459),\n",
       " ('brought', 459),\n",
       " ('mostly', 458),\n",
       " ('disney', 457),\n",
       " ('couldn', 457),\n",
       " ('society', 456),\n",
       " ('lady', 455),\n",
       " ('within', 455),\n",
       " ('blood', 454),\n",
       " ('parents', 453),\n",
       " ('upon', 453),\n",
       " ('viewers', 453),\n",
       " ('meets', 452),\n",
       " ('form', 452),\n",
       " ('peter', 452),\n",
       " ('tom', 452),\n",
       " ('usually', 452),\n",
       " ('soundtrack', 452),\n",
       " ('local', 450),\n",
       " ('certain', 448),\n",
       " ('follow', 448),\n",
       " ('whether', 447),\n",
       " ('possible', 446),\n",
       " ('emotional', 445),\n",
       " ('killed', 444),\n",
       " ('above', 444),\n",
       " ('de', 444),\n",
       " ('god', 443),\n",
       " ('middle', 443),\n",
       " ('needs', 442),\n",
       " ('happens', 442),\n",
       " ('flick', 442),\n",
       " ('masterpiece', 441),\n",
       " ('period', 440),\n",
       " ('major', 440),\n",
       " ('named', 439),\n",
       " ('haven', 439),\n",
       " ('particular', 438),\n",
       " ('th', 438),\n",
       " ('earth', 437),\n",
       " ('feature', 437),\n",
       " ('stand', 436),\n",
       " ('words', 435),\n",
       " ('typical', 435),\n",
       " ('elements', 433),\n",
       " ('obviously', 433),\n",
       " ('romance', 431),\n",
       " ('jane', 430),\n",
       " ('yourself', 427),\n",
       " ('showing', 427),\n",
       " ('brings', 426),\n",
       " ('fantasy', 426),\n",
       " ('guess', 423),\n",
       " ('america', 423),\n",
       " ('unfortunately', 422),\n",
       " ('huge', 422),\n",
       " ('indeed', 421),\n",
       " ('running', 421),\n",
       " ('talent', 420),\n",
       " ('stage', 419),\n",
       " ('started', 418),\n",
       " ('leads', 417),\n",
       " ('sweet', 417),\n",
       " ('japanese', 417),\n",
       " ('poor', 416),\n",
       " ('deal', 416),\n",
       " ('incredible', 413),\n",
       " ('personal', 413),\n",
       " ('fast', 412),\n",
       " ('became', 410),\n",
       " ('deep', 410),\n",
       " ('hours', 409),\n",
       " ('giving', 408),\n",
       " ('nearly', 408),\n",
       " ('dream', 408),\n",
       " ('clearly', 407),\n",
       " ('turned', 407),\n",
       " ('obvious', 406),\n",
       " ('near', 406),\n",
       " ('cut', 405),\n",
       " ('surprise', 405),\n",
       " ('era', 404),\n",
       " ('body', 404),\n",
       " ('hour', 403),\n",
       " ('female', 403),\n",
       " ('five', 403),\n",
       " ('note', 399),\n",
       " ('learn', 398),\n",
       " ('truth', 398),\n",
       " ('except', 397),\n",
       " ('feels', 397),\n",
       " ('match', 397),\n",
       " ('tony', 397),\n",
       " ('filmed', 394),\n",
       " ('clear', 394),\n",
       " ('complete', 394),\n",
       " ('street', 393),\n",
       " ('eventually', 393),\n",
       " ('keeps', 393),\n",
       " ('older', 393),\n",
       " ('lots', 393),\n",
       " ('buy', 392),\n",
       " ('william', 391),\n",
       " ('stewart', 391),\n",
       " ('fall', 390),\n",
       " ('joe', 390),\n",
       " ('meet', 390),\n",
       " ('unlike', 389),\n",
       " ('talking', 389),\n",
       " ('shots', 389),\n",
       " ('rating', 389),\n",
       " ('difficult', 389),\n",
       " ('dramatic', 388),\n",
       " ('means', 388),\n",
       " ('situation', 386),\n",
       " ('wonder', 386),\n",
       " ('present', 386),\n",
       " ('appears', 386),\n",
       " ('subject', 386),\n",
       " ('comments', 385),\n",
       " ('general', 383),\n",
       " ('sequences', 383),\n",
       " ('lee', 383),\n",
       " ('points', 382),\n",
       " ('earlier', 382),\n",
       " ('gone', 379),\n",
       " ('check', 379),\n",
       " ('suspense', 378),\n",
       " ('recommended', 378),\n",
       " ('ten', 378),\n",
       " ('third', 377),\n",
       " ('business', 377),\n",
       " ('talk', 375),\n",
       " ('leaves', 375),\n",
       " ('beyond', 375),\n",
       " ('portrayal', 374),\n",
       " ('beautifully', 373),\n",
       " ('single', 372),\n",
       " ('bill', 372),\n",
       " ('plenty', 371),\n",
       " ('word', 371),\n",
       " ('whom', 370),\n",
       " ('falls', 370),\n",
       " ('scary', 369),\n",
       " ('non', 369),\n",
       " ('figure', 369),\n",
       " ('battle', 369),\n",
       " ('using', 368),\n",
       " ('return', 368),\n",
       " ('doubt', 367),\n",
       " ('add', 367),\n",
       " ('hear', 366),\n",
       " ('solid', 366),\n",
       " ('success', 366),\n",
       " ('jokes', 365),\n",
       " ('oh', 365),\n",
       " ('touching', 365),\n",
       " ('political', 365),\n",
       " ('hell', 364),\n",
       " ('awesome', 364),\n",
       " ('boys', 364),\n",
       " ('sexual', 362),\n",
       " ('recently', 362),\n",
       " ('dog', 362),\n",
       " ('please', 361),\n",
       " ('wouldn', 361),\n",
       " ('straight', 361),\n",
       " ('features', 361),\n",
       " ('forget', 360),\n",
       " ('setting', 360),\n",
       " ('lack', 360),\n",
       " ('married', 359),\n",
       " ('mark', 359),\n",
       " ('social', 357),\n",
       " ('interested', 356),\n",
       " ('adventure', 356),\n",
       " ('actual', 355),\n",
       " ('terrific', 355),\n",
       " ('sees', 355),\n",
       " ('brothers', 355),\n",
       " ('move', 354),\n",
       " ('call', 354),\n",
       " ('various', 353),\n",
       " ('theater', 353),\n",
       " ('dr', 353),\n",
       " ('animated', 352),\n",
       " ('western', 351),\n",
       " ('baby', 350),\n",
       " ('space', 350),\n",
       " ('leading', 348),\n",
       " ('disappointed', 348),\n",
       " ('portrayed', 346),\n",
       " ('aren', 346),\n",
       " ('screenplay', 345),\n",
       " ('smith', 345),\n",
       " ('towards', 344),\n",
       " ('hate', 344),\n",
       " ('noir', 343),\n",
       " ('outstanding', 342),\n",
       " ('decent', 342),\n",
       " ('kelly', 342),\n",
       " ('directors', 341),\n",
       " ('journey', 341),\n",
       " ('none', 340),\n",
       " ('looked', 340),\n",
       " ('effective', 340),\n",
       " ('storyline', 339),\n",
       " ('caught', 339),\n",
       " ('sci', 339),\n",
       " ('fi', 339),\n",
       " ('cold', 339),\n",
       " ('mary', 339),\n",
       " ('rich', 338),\n",
       " ('charming', 338),\n",
       " ('popular', 337),\n",
       " ('rare', 337),\n",
       " ('manages', 337),\n",
       " ('harry', 337),\n",
       " ('spirit', 336),\n",
       " ('appreciate', 335),\n",
       " ('open', 335),\n",
       " ('moves', 334),\n",
       " ('basically', 334),\n",
       " ('acted', 334),\n",
       " ('inside', 333),\n",
       " ('boring', 333),\n",
       " ('century', 333),\n",
       " ('mention', 333),\n",
       " ('deserves', 333),\n",
       " ('subtle', 333),\n",
       " ('pace', 333),\n",
       " ('familiar', 332),\n",
       " ('background', 332),\n",
       " ('ben', 331),\n",
       " ('creepy', 330),\n",
       " ('supposed', 330),\n",
       " ('secret', 329),\n",
       " ('die', 328),\n",
       " ('jim', 328),\n",
       " ('question', 327),\n",
       " ('effect', 327),\n",
       " ('natural', 327),\n",
       " ('impressive', 326),\n",
       " ('rate', 326),\n",
       " ('language', 326),\n",
       " ('saying', 325),\n",
       " ('intelligent', 325),\n",
       " ('telling', 324),\n",
       " ('realize', 324),\n",
       " ('material', 324),\n",
       " ('scott', 324),\n",
       " ('singing', 323),\n",
       " ('dancing', 322),\n",
       " ('visual', 321),\n",
       " ('adult', 321),\n",
       " ('imagine', 321),\n",
       " ('kept', 320),\n",
       " ('office', 320),\n",
       " ('uses', 319),\n",
       " ('pure', 318),\n",
       " ('wait', 318),\n",
       " ('stunning', 318),\n",
       " ('review', 317),\n",
       " ('previous', 317),\n",
       " ('copy', 317),\n",
       " ('seriously', 317),\n",
       " ('reading', 316),\n",
       " ('create', 316),\n",
       " ('hot', 316),\n",
       " ('created', 316),\n",
       " ('magic', 316),\n",
       " ('somehow', 316),\n",
       " ('stay', 315),\n",
       " ('attempt', 315),\n",
       " ('escape', 315),\n",
       " ('crazy', 315),\n",
       " ('air', 315),\n",
       " ('frank', 315),\n",
       " ('hands', 314),\n",
       " ('filled', 313),\n",
       " ('expected', 312),\n",
       " ('average', 312),\n",
       " ('surprisingly', 312),\n",
       " ('complex', 311),\n",
       " ('quickly', 310),\n",
       " ('successful', 310),\n",
       " ('studio', 310),\n",
       " ('plus', 309),\n",
       " ('male', 309),\n",
       " ('co', 307),\n",
       " ('images', 306),\n",
       " ('casting', 306),\n",
       " ('following', 306),\n",
       " ('minute', 306),\n",
       " ('exciting', 306),\n",
       " ('members', 305),\n",
       " ('follows', 305),\n",
       " ('themes', 305),\n",
       " ('german', 305),\n",
       " ('reasons', 305),\n",
       " ('e', 305),\n",
       " ('touch', 304),\n",
       " ('edge', 304),\n",
       " ('free', 304),\n",
       " ('cute', 304),\n",
       " ('genius', 304),\n",
       " ('outside', 303),\n",
       " ('reviews', 302),\n",
       " ('admit', 302),\n",
       " ('ok', 302),\n",
       " ('younger', 302),\n",
       " ('fighting', 301),\n",
       " ('odd', 301),\n",
       " ('master', 301),\n",
       " ('recent', 300),\n",
       " ('thanks', 300),\n",
       " ('break', 300),\n",
       " ('comment', 300),\n",
       " ('apart', 299),\n",
       " ('emotions', 298),\n",
       " ('lovely', 298),\n",
       " ('begin', 298),\n",
       " ('doctor', 297),\n",
       " ('party', 297),\n",
       " ('italian', 297),\n",
       " ('la', 296),\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_count.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 548962),\n",
       " ('.', 167538),\n",
       " ('the', 163389),\n",
       " ('a', 79321),\n",
       " ('and', 74385),\n",
       " ('of', 69009),\n",
       " ('to', 68974),\n",
       " ('br', 52637),\n",
       " ('is', 50083),\n",
       " ('it', 48327),\n",
       " ('i', 46880),\n",
       " ('in', 43753),\n",
       " ('this', 40920),\n",
       " ('that', 37615),\n",
       " ('s', 31546),\n",
       " ('was', 26291),\n",
       " ('movie', 24965),\n",
       " ('for', 21927),\n",
       " ('but', 21781),\n",
       " ('with', 20878),\n",
       " ('as', 20625),\n",
       " ('t', 20361),\n",
       " ('film', 19218),\n",
       " ('you', 17549),\n",
       " ('on', 17192),\n",
       " ('not', 16354),\n",
       " ('have', 15144),\n",
       " ('are', 14623),\n",
       " ('be', 14541),\n",
       " ('he', 13856),\n",
       " ('one', 13134),\n",
       " ('they', 13011),\n",
       " ('\\n', 12500),\n",
       " ('at', 12279),\n",
       " ('his', 12147),\n",
       " ('all', 12036),\n",
       " ('so', 11463),\n",
       " ('like', 11238),\n",
       " ('there', 10775),\n",
       " ('just', 10619),\n",
       " ('by', 10549),\n",
       " ('or', 10272),\n",
       " ('an', 10266),\n",
       " ('who', 9969),\n",
       " ('from', 9731),\n",
       " ('if', 9518),\n",
       " ('about', 9061),\n",
       " ('out', 8979),\n",
       " ('what', 8422),\n",
       " ('some', 8306),\n",
       " ('no', 8143),\n",
       " ('her', 7947),\n",
       " ('even', 7687),\n",
       " ('can', 7653),\n",
       " ('has', 7604),\n",
       " ('good', 7423),\n",
       " ('bad', 7401),\n",
       " ('would', 7036),\n",
       " ('up', 6970),\n",
       " ('only', 6781),\n",
       " ('more', 6730),\n",
       " ('when', 6726),\n",
       " ('she', 6444),\n",
       " ('really', 6262),\n",
       " ('time', 6209),\n",
       " ('had', 6142),\n",
       " ('my', 6015),\n",
       " ('were', 6001),\n",
       " ('which', 5780),\n",
       " ('very', 5764),\n",
       " ('me', 5606),\n",
       " ('see', 5452),\n",
       " ('don', 5336),\n",
       " ('we', 5328),\n",
       " ('their', 5278),\n",
       " ('do', 5236),\n",
       " ('story', 5208),\n",
       " ('than', 5183),\n",
       " ('been', 5100),\n",
       " ('much', 5078),\n",
       " ('get', 5037),\n",
       " ('because', 4966),\n",
       " ('people', 4806),\n",
       " ('then', 4761),\n",
       " ('make', 4722),\n",
       " ('how', 4688),\n",
       " ('could', 4686),\n",
       " ('any', 4658),\n",
       " ('into', 4567),\n",
       " ('made', 4541),\n",
       " ('first', 4306),\n",
       " ('other', 4305),\n",
       " ('well', 4254),\n",
       " ('too', 4174),\n",
       " ('them', 4165),\n",
       " ('plot', 4154),\n",
       " ('movies', 4080),\n",
       " ('acting', 4056),\n",
       " ('will', 3993),\n",
       " ('way', 3989),\n",
       " ('most', 3919),\n",
       " ('him', 3858),\n",
       " ('after', 3838),\n",
       " ('its', 3655),\n",
       " ('think', 3643),\n",
       " ('also', 3608),\n",
       " ('characters', 3600),\n",
       " ('off', 3567),\n",
       " ('watch', 3550),\n",
       " ('character', 3506),\n",
       " ('did', 3506),\n",
       " ('why', 3463),\n",
       " ('being', 3393),\n",
       " ('better', 3358),\n",
       " ('know', 3334),\n",
       " ('over', 3316),\n",
       " ('seen', 3265),\n",
       " ('ever', 3263),\n",
       " ('never', 3259),\n",
       " ('your', 3233),\n",
       " ('where', 3219),\n",
       " ('two', 3173),\n",
       " ('little', 3096),\n",
       " ('films', 3077),\n",
       " ('here', 3027),\n",
       " ('m', 3000),\n",
       " ('nothing', 2990),\n",
       " ('say', 2982),\n",
       " ('end', 2954),\n",
       " ('something', 2942),\n",
       " ('should', 2920),\n",
       " ('many', 2909),\n",
       " ('does', 2871),\n",
       " ('thing', 2866),\n",
       " ('show', 2862),\n",
       " ('ve', 2829),\n",
       " ('scene', 2816),\n",
       " ('scenes', 2785),\n",
       " ('these', 2724),\n",
       " ('go', 2717),\n",
       " ('didn', 2646),\n",
       " ('great', 2640),\n",
       " ('watching', 2640),\n",
       " ('re', 2620),\n",
       " ('doesn', 2601),\n",
       " ('through', 2560),\n",
       " ('such', 2544),\n",
       " ('man', 2516),\n",
       " ('worst', 2480),\n",
       " ('actually', 2449),\n",
       " ('actors', 2437),\n",
       " ('life', 2429),\n",
       " ('back', 2424),\n",
       " ('while', 2418),\n",
       " ('director', 2405),\n",
       " ('funny', 2336),\n",
       " ('going', 2319),\n",
       " ('still', 2283),\n",
       " ('another', 2254),\n",
       " ('look', 2247),\n",
       " ('now', 2237),\n",
       " ('old', 2215),\n",
       " ('those', 2212),\n",
       " ('real', 2170),\n",
       " ('few', 2158),\n",
       " ('love', 2152),\n",
       " ('horror', 2150),\n",
       " ('before', 2147),\n",
       " ('want', 2141),\n",
       " ('minutes', 2126),\n",
       " ('pretty', 2115),\n",
       " ('best', 2094),\n",
       " ('though', 2091),\n",
       " ('same', 2081),\n",
       " ('script', 2074),\n",
       " ('work', 2027),\n",
       " ('every', 2025),\n",
       " ('seems', 2023),\n",
       " ('least', 2011),\n",
       " ('enough', 1997),\n",
       " ('down', 1988),\n",
       " ('original', 1983),\n",
       " ('guy', 1964),\n",
       " ('got', 1952),\n",
       " ('around', 1943),\n",
       " ('part', 1942),\n",
       " ('lot', 1892),\n",
       " ('anything', 1874),\n",
       " ('find', 1860),\n",
       " ('new', 1854),\n",
       " ('again', 1849),\n",
       " ('isn', 1849),\n",
       " ('point', 1845),\n",
       " ('things', 1839),\n",
       " ('fact', 1839),\n",
       " ('give', 1823),\n",
       " ('makes', 1814),\n",
       " ('take', 1800),\n",
       " ('thought', 1798),\n",
       " ('d', 1770),\n",
       " ('whole', 1768),\n",
       " ('long', 1761),\n",
       " ('years', 1759),\n",
       " ('however', 1740),\n",
       " ('gets', 1714),\n",
       " ('making', 1695),\n",
       " ('cast', 1694),\n",
       " ('big', 1662),\n",
       " ('might', 1658),\n",
       " ('interesting', 1648),\n",
       " ('money', 1638),\n",
       " ('us', 1628),\n",
       " ('right', 1625),\n",
       " ('far', 1619),\n",
       " ('quite', 1596),\n",
       " ('without', 1595),\n",
       " ('come', 1595),\n",
       " ('almost', 1574),\n",
       " ('ll', 1567),\n",
       " ('action', 1566),\n",
       " ('awful', 1557),\n",
       " ('kind', 1539),\n",
       " ('reason', 1534),\n",
       " ('am', 1530),\n",
       " ('looks', 1528),\n",
       " ('must', 1522),\n",
       " ('done', 1510),\n",
       " ('comedy', 1504),\n",
       " ('someone', 1490),\n",
       " ('trying', 1486),\n",
       " ('wasn', 1484),\n",
       " ('poor', 1481),\n",
       " ('boring', 1478),\n",
       " ('instead', 1478),\n",
       " ('saw', 1475),\n",
       " ('away', 1469),\n",
       " ('girl', 1463),\n",
       " ('probably', 1444),\n",
       " ('believe', 1434),\n",
       " ('sure', 1433),\n",
       " ('looking', 1430),\n",
       " ('stupid', 1428),\n",
       " ('anyone', 1418),\n",
       " ('times', 1406),\n",
       " ('maybe', 1404),\n",
       " ('world', 1404),\n",
       " ('rather', 1394),\n",
       " ('terrible', 1391),\n",
       " ('may', 1390),\n",
       " ('last', 1390),\n",
       " ('since', 1388),\n",
       " ('let', 1385),\n",
       " ('tv', 1382),\n",
       " ('hard', 1374),\n",
       " ('between', 1374),\n",
       " ('waste', 1358),\n",
       " ('woman', 1356),\n",
       " ('feel', 1354),\n",
       " ('effects', 1348),\n",
       " ('half', 1341),\n",
       " ('own', 1333),\n",
       " ('young', 1317),\n",
       " ('music', 1316),\n",
       " ('idea', 1312),\n",
       " ('sense', 1306),\n",
       " ('bit', 1298),\n",
       " ('having', 1280),\n",
       " ('book', 1278),\n",
       " ('found', 1267),\n",
       " ('put', 1263),\n",
       " ('series', 1263),\n",
       " ('goes', 1256),\n",
       " ('worse', 1249),\n",
       " ('said', 1230),\n",
       " ('comes', 1224),\n",
       " ('role', 1222),\n",
       " ('main', 1220),\n",
       " ('else', 1199),\n",
       " ('everything', 1197),\n",
       " ('yet', 1196),\n",
       " ('low', 1189),\n",
       " ('screen', 1188),\n",
       " ('supposed', 1186),\n",
       " ('actor', 1185),\n",
       " ('either', 1183),\n",
       " ('budget', 1179),\n",
       " ('ending', 1179),\n",
       " ('audience', 1178),\n",
       " ('set', 1177),\n",
       " ('family', 1170),\n",
       " ('left', 1169),\n",
       " ('completely', 1168),\n",
       " ('both', 1158),\n",
       " ('wrong', 1155),\n",
       " ('always', 1151),\n",
       " ('course', 1148),\n",
       " ('place', 1148),\n",
       " ('seem', 1147),\n",
       " ('watched', 1142),\n",
       " ('day', 1132),\n",
       " ('simply', 1130),\n",
       " ('shot', 1126),\n",
       " ('mean', 1117),\n",
       " ('special', 1102),\n",
       " ('dead', 1101),\n",
       " ('three', 1094),\n",
       " ('house', 1085),\n",
       " ('oh', 1084),\n",
       " ('night', 1083),\n",
       " ('read', 1082),\n",
       " ('less', 1067),\n",
       " ('high', 1066),\n",
       " ('year', 1064),\n",
       " ('camera', 1061),\n",
       " ('worth', 1057),\n",
       " ('our', 1056),\n",
       " ('try', 1051),\n",
       " ('horrible', 1046),\n",
       " ('sex', 1046),\n",
       " ('video', 1043),\n",
       " ('black', 1039),\n",
       " ('although', 1036),\n",
       " ('couldn', 1036),\n",
       " ('once', 1033),\n",
       " ('rest', 1022),\n",
       " ('dvd', 1021),\n",
       " ('line', 1018),\n",
       " ('played', 1017),\n",
       " ('fun', 1007),\n",
       " ('during', 1006),\n",
       " ('production', 1003),\n",
       " ('everyone', 1002),\n",
       " ('play', 993),\n",
       " ('mind', 990),\n",
       " ('version', 989),\n",
       " ('kids', 989),\n",
       " ('seeing', 988),\n",
       " ('american', 980),\n",
       " ('given', 978),\n",
       " ('used', 969),\n",
       " ('performance', 968),\n",
       " ('especially', 963),\n",
       " ('together', 963),\n",
       " ('tell', 959),\n",
       " ('women', 958),\n",
       " ('start', 956),\n",
       " ('need', 955),\n",
       " ('second', 953),\n",
       " ('takes', 950),\n",
       " ('each', 950),\n",
       " ('wife', 944),\n",
       " ('dialogue', 942),\n",
       " ('use', 940),\n",
       " ('problem', 938),\n",
       " ('star', 934),\n",
       " ('unfortunately', 931),\n",
       " ('himself', 929),\n",
       " ('doing', 926),\n",
       " ('death', 922),\n",
       " ('name', 921),\n",
       " ('lines', 919),\n",
       " ('killer', 914),\n",
       " ('getting', 913),\n",
       " ('help', 905),\n",
       " ('couple', 902),\n",
       " ('fan', 902),\n",
       " ('head', 898),\n",
       " ('crap', 895),\n",
       " ('guess', 888),\n",
       " ('piece', 884),\n",
       " ('nice', 880),\n",
       " ('different', 878),\n",
       " ('school', 876),\n",
       " ('later', 875),\n",
       " ('entire', 869),\n",
       " ('shows', 860),\n",
       " ('next', 858),\n",
       " ('john', 858),\n",
       " ('short', 857),\n",
       " ('seemed', 857),\n",
       " ('hollywood', 850),\n",
       " ('home', 848),\n",
       " ('true', 846),\n",
       " ('person', 846),\n",
       " ('absolutely', 842),\n",
       " ('sort', 840),\n",
       " ('care', 839),\n",
       " ('understand', 836),\n",
       " ('plays', 835),\n",
       " ('felt', 834),\n",
       " ('written', 829),\n",
       " ('title', 828),\n",
       " ('men', 822),\n",
       " ('until', 821),\n",
       " ('flick', 816),\n",
       " ('decent', 815),\n",
       " ('face', 814),\n",
       " ('friends', 810),\n",
       " ('stars', 807),\n",
       " ('job', 807),\n",
       " ('case', 807),\n",
       " ('itself', 804),\n",
       " ('yes', 801),\n",
       " ('perhaps', 800),\n",
       " ('went', 797),\n",
       " ('wanted', 797),\n",
       " ('called', 796),\n",
       " ('annoying', 795),\n",
       " ('ridiculous', 790),\n",
       " ('tries', 790),\n",
       " ('laugh', 788),\n",
       " ('evil', 787),\n",
       " ('along', 786),\n",
       " ('top', 785),\n",
       " ('hour', 784),\n",
       " ('full', 783),\n",
       " ('came', 780),\n",
       " ('writing', 780),\n",
       " ('keep', 770),\n",
       " ('totally', 767),\n",
       " ('playing', 766),\n",
       " ('god', 765),\n",
       " ('won', 764),\n",
       " ('guys', 763),\n",
       " ('already', 762),\n",
       " ('gore', 757),\n",
       " ('direction', 748),\n",
       " ('save', 746),\n",
       " ('lost', 745),\n",
       " ('example', 744),\n",
       " ('sound', 742),\n",
       " ('war', 741),\n",
       " ('attempt', 735),\n",
       " ('car', 733),\n",
       " ('except', 733),\n",
       " ('moments', 732),\n",
       " ('blood', 732),\n",
       " ('obviously', 730),\n",
       " ('act', 729),\n",
       " ('remember', 728),\n",
       " ('kill', 727),\n",
       " ('truly', 726),\n",
       " ('white', 726),\n",
       " ('father', 726),\n",
       " ('b', 725),\n",
       " ('thinking', 720),\n",
       " ('ok', 716),\n",
       " ('finally', 716),\n",
       " ('turn', 711),\n",
       " ('quality', 701),\n",
       " ('lack', 698),\n",
       " ('style', 694),\n",
       " ('wouldn', 693),\n",
       " ('cheap', 691),\n",
       " ('none', 690),\n",
       " ('kid', 686),\n",
       " ('please', 686),\n",
       " ('boy', 685),\n",
       " ('seriously', 684),\n",
       " ('lead', 680),\n",
       " ('dull', 677),\n",
       " ('children', 676),\n",
       " ('starts', 675),\n",
       " ('stuff', 673),\n",
       " ('hope', 672),\n",
       " ('looked', 670),\n",
       " ('recommend', 669),\n",
       " ('under', 668),\n",
       " ('run', 667),\n",
       " ('killed', 667),\n",
       " ('enjoy', 666),\n",
       " ('others', 666),\n",
       " ('etc', 663),\n",
       " ('myself', 663),\n",
       " ('beginning', 662),\n",
       " ('girls', 662),\n",
       " ('against', 662),\n",
       " ('obvious', 660),\n",
       " ('small', 660),\n",
       " ('hell', 659),\n",
       " ('slow', 657),\n",
       " ('hand', 656),\n",
       " ('wonder', 652),\n",
       " ('lame', 652),\n",
       " ('becomes', 651),\n",
       " ('picture', 651),\n",
       " ('based', 650),\n",
       " ('early', 648),\n",
       " ('behind', 646),\n",
       " ('poorly', 644),\n",
       " ('avoid', 642),\n",
       " ('apparently', 640),\n",
       " ('complete', 640),\n",
       " ('happens', 639),\n",
       " ('anyway', 638),\n",
       " ('classic', 637),\n",
       " ('several', 636),\n",
       " ('despite', 635),\n",
       " ('certainly', 635),\n",
       " ('episode', 635),\n",
       " ('often', 631),\n",
       " ('cut', 630),\n",
       " ('writer', 630),\n",
       " ('mother', 628),\n",
       " ('predictable', 628),\n",
       " ('gave', 628),\n",
       " ('become', 627),\n",
       " ('close', 625),\n",
       " ('fans', 624),\n",
       " ('saying', 621),\n",
       " ('scary', 619),\n",
       " ('stop', 618),\n",
       " ('live', 618),\n",
       " ('wants', 617),\n",
       " ('self', 615),\n",
       " ('mr', 612),\n",
       " ('jokes', 611),\n",
       " ('friend', 611),\n",
       " ('cannot', 610),\n",
       " ('overall', 609),\n",
       " ('cinema', 604),\n",
       " ('child', 603),\n",
       " ('silly', 601),\n",
       " ('beautiful', 596),\n",
       " ('human', 595),\n",
       " ('expect', 594),\n",
       " ('liked', 593),\n",
       " ('happened', 592),\n",
       " ('bunch', 590),\n",
       " ('entertaining', 590),\n",
       " ('actress', 588),\n",
       " ('final', 588),\n",
       " ('says', 584),\n",
       " ('performances', 584),\n",
       " ('turns', 577),\n",
       " ('humor', 577),\n",
       " ('themselves', 576),\n",
       " ('eyes', 576),\n",
       " ('hours', 574),\n",
       " ('happen', 573),\n",
       " ('basically', 572),\n",
       " ('days', 572),\n",
       " ('running', 571),\n",
       " ('involved', 569),\n",
       " ('disappointed', 569),\n",
       " ('call', 569),\n",
       " ('directed', 568),\n",
       " ('group', 568),\n",
       " ('fight', 567),\n",
       " ('daughter', 566),\n",
       " ('talking', 566),\n",
       " ('body', 566),\n",
       " ('badly', 565),\n",
       " ('sorry', 565),\n",
       " ('throughout', 563),\n",
       " ('viewer', 563),\n",
       " ('yourself', 562),\n",
       " ('extremely', 562),\n",
       " ('interest', 561),\n",
       " ('heard', 561),\n",
       " ('violence', 561),\n",
       " ('shots', 559),\n",
       " ('side', 557),\n",
       " ('word', 556),\n",
       " ('art', 555),\n",
       " ('possible', 554),\n",
       " ('dark', 551),\n",
       " ('game', 551),\n",
       " ('hero', 550),\n",
       " ('alone', 549),\n",
       " ('son', 547),\n",
       " ('type', 547),\n",
       " ('leave', 547),\n",
       " ('gives', 546),\n",
       " ('parts', 546),\n",
       " ('single', 546),\n",
       " ('started', 545),\n",
       " ('female', 543),\n",
       " ('rating', 541),\n",
       " ('mess', 541),\n",
       " ('voice', 541),\n",
       " ('aren', 540),\n",
       " ('town', 540),\n",
       " ('drama', 538),\n",
       " ('definitely', 537),\n",
       " ('unless', 536),\n",
       " ('review', 534),\n",
       " ('effort', 533),\n",
       " ('weak', 533),\n",
       " ('able', 533),\n",
       " ('took', 531),\n",
       " ('non', 530),\n",
       " ('five', 530),\n",
       " ('matter', 529),\n",
       " ('usually', 529),\n",
       " ('michael', 528),\n",
       " ('feeling', 526),\n",
       " ('huge', 523),\n",
       " ('sequel', 522),\n",
       " ('soon', 521),\n",
       " ('exactly', 520),\n",
       " ('past', 519),\n",
       " ('turned', 518),\n",
       " ('police', 518),\n",
       " ('tried', 515),\n",
       " ('middle', 513),\n",
       " ('talent', 513),\n",
       " ('genre', 512),\n",
       " ('zombie', 510),\n",
       " ('ends', 509),\n",
       " ('history', 509),\n",
       " ('straight', 503),\n",
       " ('opening', 501),\n",
       " ('serious', 501),\n",
       " ('coming', 501),\n",
       " ('moment', 500),\n",
       " ('lives', 499),\n",
       " ('sad', 499),\n",
       " ('dialog', 498),\n",
       " ('particularly', 498),\n",
       " ('editing', 493),\n",
       " ('clearly', 492),\n",
       " ('beyond', 491),\n",
       " ('earth', 491),\n",
       " ('taken', 490),\n",
       " ('cool', 490),\n",
       " ('level', 489),\n",
       " ('dumb', 489),\n",
       " ('okay', 488),\n",
       " ('major', 487),\n",
       " ('fast', 485),\n",
       " ('premise', 485),\n",
       " ('joke', 484),\n",
       " ('stories', 484),\n",
       " ('wasted', 483),\n",
       " ('minute', 483),\n",
       " ('across', 482),\n",
       " ('mostly', 482),\n",
       " ('rent', 482),\n",
       " ('late', 481),\n",
       " ('falls', 481),\n",
       " ('fails', 481),\n",
       " ('mention', 478),\n",
       " ('theater', 475),\n",
       " ('stay', 472),\n",
       " ('sometimes', 472),\n",
       " ('hit', 468),\n",
       " ('talk', 467),\n",
       " ('fine', 467),\n",
       " ('die', 466),\n",
       " ('storyline', 465),\n",
       " ('pointless', 465),\n",
       " ('taking', 464),\n",
       " ('order', 462),\n",
       " ('brother', 461),\n",
       " ('whatever', 460),\n",
       " ('told', 460),\n",
       " ('wish', 458),\n",
       " ('room', 456),\n",
       " ('career', 455),\n",
       " ('appears', 455),\n",
       " ('write', 455),\n",
       " ('known', 454),\n",
       " ('husband', 454),\n",
       " ('living', 451),\n",
       " ('sit', 450),\n",
       " ('ten', 450),\n",
       " ('words', 449),\n",
       " ('monster', 448),\n",
       " ('chance', 448),\n",
       " ('hate', 444),\n",
       " ('novel', 444),\n",
       " ('add', 443),\n",
       " ('english', 443),\n",
       " ('somehow', 441),\n",
       " ('strange', 440),\n",
       " ('imdb', 438),\n",
       " ('actual', 438),\n",
       " ('total', 437),\n",
       " ('material', 437),\n",
       " ('killing', 437),\n",
       " ('ones', 437),\n",
       " ('knew', 436),\n",
       " ('king', 434),\n",
       " ('number', 434),\n",
       " ('using', 433),\n",
       " ('lee', 431),\n",
       " ('power', 431),\n",
       " ('shown', 431),\n",
       " ('works', 431),\n",
       " ('giving', 431),\n",
       " ('points', 430),\n",
       " ('possibly', 430),\n",
       " ('kept', 430),\n",
       " ('four', 429),\n",
       " ('local', 427),\n",
       " ('usual', 426),\n",
       " ('including', 425),\n",
       " ('problems', 424),\n",
       " ('ago', 424),\n",
       " ('opinion', 424),\n",
       " ('nudity', 423),\n",
       " ('age', 422),\n",
       " ('due', 421),\n",
       " ('roles', 420),\n",
       " ('writers', 419),\n",
       " ('decided', 419),\n",
       " ('near', 418),\n",
       " ('flat', 418),\n",
       " ('easily', 418),\n",
       " ('murder', 417),\n",
       " ('experience', 417),\n",
       " ('reviews', 416),\n",
       " ('imagine', 415),\n",
       " ('feels', 413),\n",
       " ('plain', 411),\n",
       " ('somewhat', 411),\n",
       " ('class', 410),\n",
       " ('score', 410),\n",
       " ('song', 409),\n",
       " ('bring', 409),\n",
       " ('whether', 409),\n",
       " ('otherwise', 408),\n",
       " ('whose', 408),\n",
       " ('average', 408),\n",
       " ('pathetic', 407),\n",
       " ('nearly', 407),\n",
       " ('knows', 407),\n",
       " ('zombies', 407),\n",
       " ('cinematography', 406),\n",
       " ('cheesy', 406),\n",
       " ('upon', 406),\n",
       " ('city', 405),\n",
       " ('space', 405),\n",
       " ('credits', 404),\n",
       " ('james', 403),\n",
       " ('lots', 403),\n",
       " ('change', 403),\n",
       " ('entertainment', 402),\n",
       " ('nor', 402),\n",
       " ('wait', 401),\n",
       " ('released', 400),\n",
       " ('needs', 399),\n",
       " ('shame', 398),\n",
       " ('attention', 396),\n",
       " ('comments', 394),\n",
       " ('bored', 393),\n",
       " ('free', 393),\n",
       " ('lady', 393),\n",
       " ('expected', 392),\n",
       " ('needed', 392),\n",
       " ('clear', 392),\n",
       " ('view', 391),\n",
       " ('development', 390),\n",
       " ('check', 390),\n",
       " ('doubt', 390),\n",
       " ('figure', 389),\n",
       " ('mystery', 389),\n",
       " ('excellent', 388),\n",
       " ('garbage', 388),\n",
       " ('sequence', 386),\n",
       " ('television', 386),\n",
       " ('o', 385),\n",
       " ('sets', 385),\n",
       " ('laughable', 384),\n",
       " ('potential', 384),\n",
       " ('robert', 382),\n",
       " ('light', 382),\n",
       " ('country', 382),\n",
       " ('documentary', 382),\n",
       " ('reality', 382),\n",
       " ('general', 381),\n",
       " ('ask', 381),\n",
       " ('comic', 380),\n",
       " ('fall', 380),\n",
       " ('begin', 380),\n",
       " ('footage', 379),\n",
       " ('stand', 379),\n",
       " ('forced', 379),\n",
       " ('trash', 379),\n",
       " ('remake', 379),\n",
       " ('thriller', 378),\n",
       " ('songs', 378),\n",
       " ('gay', 377),\n",
       " ('within', 377),\n",
       " ('hardly', 376),\n",
       " ('above', 375),\n",
       " ('gone', 375),\n",
       " ('george', 374),\n",
       " ('means', 373),\n",
       " ('sounds', 373),\n",
       " ('directing', 372),\n",
       " ('move', 372),\n",
       " ('david', 372),\n",
       " ('buy', 372),\n",
       " ('rock', 371),\n",
       " ('forward', 371),\n",
       " ('important', 371),\n",
       " ('hot', 370),\n",
       " ('haven', 370),\n",
       " ('filmed', 370),\n",
       " ('british', 370),\n",
       " ('heart', 369),\n",
       " ('reading', 369),\n",
       " ('fake', 369),\n",
       " ('incredibly', 368),\n",
       " ('weird', 368),\n",
       " ('hear', 368),\n",
       " ('enjoyed', 367),\n",
       " ('hilarious', 367),\n",
       " ('cop', 367),\n",
       " ('musical', 367),\n",
       " ('message', 366),\n",
       " ('happy', 366),\n",
       " ('pay', 366),\n",
       " ('laughs', 365),\n",
       " ('box', 365),\n",
       " ('suspense', 363),\n",
       " ('sadly', 363),\n",
       " ('eye', 362),\n",
       " ('third', 361),\n",
       " ('similar', 361),\n",
       " ('named', 361),\n",
       " ('modern', 360),\n",
       " ('failed', 359),\n",
       " ('events', 359),\n",
       " ('forget', 358),\n",
       " ('question', 358),\n",
       " ('male', 357),\n",
       " ('finds', 357),\n",
       " ('perfect', 356),\n",
       " ('spent', 355),\n",
       " ('sister', 355),\n",
       " ('feature', 354),\n",
       " ('result', 354),\n",
       " ('comment', 353),\n",
       " ('girlfriend', 353),\n",
       " ('sexual', 352),\n",
       " ('attempts', 351),\n",
       " ('neither', 351),\n",
       " ('richard', 351),\n",
       " ('screenplay', 350),\n",
       " ('elements', 350),\n",
       " ('spoilers', 349),\n",
       " ('brain', 348),\n",
       " ('filmmakers', 348),\n",
       " ('showing', 348),\n",
       " ('miss', 347),\n",
       " ('dr', 347),\n",
       " ('christmas', 347),\n",
       " ('cover', 345),\n",
       " ('red', 344),\n",
       " ('sequences', 344),\n",
       " ('typical', 343),\n",
       " ('excuse', 343),\n",
       " ('crazy', 342),\n",
       " ('ideas', 342),\n",
       " ('baby', 342),\n",
       " ('loved', 341),\n",
       " ('meant', 341),\n",
       " ('worked', 340),\n",
       " ('fire', 340),\n",
       " ('unbelievable', 339),\n",
       " ('follow', 339),\n",
       " ('theme', 337),\n",
       " ('barely', 336),\n",
       " ('producers', 336),\n",
       " ('twist', 336),\n",
       " ('plus', 336),\n",
       " ('appear', 336),\n",
       " ('directors', 335),\n",
       " ('team', 335),\n",
       " ('viewers', 333),\n",
       " ('leads', 332),\n",
       " ('tom', 332),\n",
       " ('slasher', 332),\n",
       " ('wrote', 331),\n",
       " ('villain', 331),\n",
       " ('gun', 331),\n",
       " ('working', 331),\n",
       " ('island', 330),\n",
       " ('strong', 330),\n",
       " ('open', 330),\n",
       " ('realize', 330),\n",
       " ('positive', 329),\n",
       " ('disappointing', 329),\n",
       " ('yeah', 329),\n",
       " ('quickly', 329),\n",
       " ('weren', 328),\n",
       " ('release', 328),\n",
       " ('simple', 328),\n",
       " ('honestly', 328),\n",
       " ('eventually', 327),\n",
       " ('period', 327),\n",
       " ('tells', 327),\n",
       " ('kills', 327),\n",
       " ('doctor', 327),\n",
       " ('nowhere', 326),\n",
       " ('list', 326),\n",
       " ('acted', 326),\n",
       " ('herself', 326),\n",
       " ('dog', 326),\n",
       " ('walk', 325),\n",
       " ('air', 324),\n",
       " ('apart', 324),\n",
       " ('makers', 323),\n",
       " ('subject', 323),\n",
       " ('learn', 322),\n",
       " ('fi', 322),\n",
       " ('sci', 319),\n",
       " ('bother', 319),\n",
       " ('admit', 319),\n",
       " ('jack', 318),\n",
       " ('disappointment', 318),\n",
       " ('hands', 318),\n",
       " ('note', 318),\n",
       " ('certain', 317),\n",
       " ('e', 317),\n",
       " ('value', 317),\n",
       " ('casting', 317),\n",
       " ('grade', 316),\n",
       " ('peter', 316),\n",
       " ('suddenly', 315),\n",
       " ('missing', 315),\n",
       " ('form', 313),\n",
       " ('stick', 313),\n",
       " ('previous', 313),\n",
       " ('break', 313),\n",
       " ('soundtrack', 312),\n",
       " ('surprised', 311),\n",
       " ('front', 311),\n",
       " ('expecting', 311),\n",
       " ('parents', 310),\n",
       " ('surprise', 310),\n",
       " ('relationship', 310),\n",
       " ('shoot', 309),\n",
       " ('today', 309),\n",
       " ('painful', 308),\n",
       " ('ways', 308),\n",
       " ('leaves', 308),\n",
       " ('ended', 308),\n",
       " ('creepy', 308),\n",
       " ('concept', 308),\n",
       " ('somewhere', 308),\n",
       " ('vampire', 308),\n",
       " ('spend', 307),\n",
       " ('th', 307),\n",
       " ('future', 306),\n",
       " ('difficult', 306),\n",
       " ('effect', 306),\n",
       " ('fighting', 306),\n",
       " ('street', 306),\n",
       " ('c', 305),\n",
       " ('america', 305),\n",
       " ('accent', 304),\n",
       " ('truth', 302),\n",
       " ('project', 302),\n",
       " ('joe', 301),\n",
       " ('f', 301),\n",
       " ('deal', 301),\n",
       " ('indeed', 301),\n",
       " ('biggest', 300),\n",
       " ('rate', 300),\n",
       " ('paul', 299),\n",
       " ('japanese', 299),\n",
       " ('utterly', 298),\n",
       " ('begins', 298),\n",
       " ('redeeming', 298),\n",
       " ('college', 298),\n",
       " ('york', 297),\n",
       " ('fairly', 297),\n",
       " ('disney', 297),\n",
       " ('crew', 296),\n",
       " ('create', 296),\n",
       " ('cartoon', 296),\n",
       " ('revenge', 296),\n",
       " ('co', 295),\n",
       " ('outside', 295),\n",
       " ('computer', 295),\n",
       " ('interested', 295),\n",
       " ('stage', 295),\n",
       " ('considering', 294),\n",
       " ('speak', 294),\n",
       " ('among', 294),\n",
       " ('towards', 293),\n",
       " ('channel', 293),\n",
       " ('sick', 293),\n",
       " ('talented', 292),\n",
       " ('cause', 292),\n",
       " ('particular', 292),\n",
       " ('van', 292),\n",
       " ('hair', 292),\n",
       " ('bottom', 291),\n",
       " ('reasons', 291),\n",
       " ('mediocre', 290),\n",
       " ('cat', 290),\n",
       " ('telling', 290),\n",
       " ('supporting', 289),\n",
       " ('store', 289),\n",
       " ('hoping', 288),\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_count.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_neg_ratios = Counter()\n",
    "\n",
    "for term, count in list(total_count.most_common()):\n",
    "    if(count > 100):\n",
    "        pos_neg_ratio = positive_count[term] / (negative_count[term] + 1)\n",
    "        pos_neg_ratios[term] = pos_neg_ratio\n",
    "\n",
    "for word, ratio in pos_neg_ratios.most_common():\n",
    "    if(ratio > 1):\n",
    "        pos_neg_ratios[word] = np.log(ratio)\n",
    "    else:\n",
    "        pos_neg_ratios[word] = - np.log(1/(ratio+0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('edie', 4.6913478822291435),\n",
       " ('paulie', 4.0775374439057197),\n",
       " ('felix', 3.1527360223636558),\n",
       " ('polanski', 2.8233610476132043),\n",
       " ('matthau', 2.8067217286092401),\n",
       " ('victoria', 2.6810215287142909),\n",
       " ('mildred', 2.6026896854443837),\n",
       " ('gandhi', 2.5389738710582761),\n",
       " ('flawless', 2.451005098112319),\n",
       " ('superbly', 2.2600254785752498),\n",
       " ('perfection', 2.1594842493533721),\n",
       " ('astaire', 2.1400661634962708),\n",
       " ('captures', 2.0386195471595809),\n",
       " ('voight', 2.0301704926730531),\n",
       " ('wonderfully', 2.0218960560332353),\n",
       " ('powell', 1.9783454248084671),\n",
       " ('brosnan', 1.9547990964725592),\n",
       " ('lily', 1.9203768470501485),\n",
       " ('bakshi', 1.9029851043382795),\n",
       " ('lincoln', 1.9014583864844796),\n",
       " ('refreshing', 1.8551812956655511),\n",
       " ('breathtaking', 1.8481124057791867),\n",
       " ('bourne', 1.8478489358790986),\n",
       " ('lemmon', 1.8458266904983307),\n",
       " ('delightful', 1.8002701588959635),\n",
       " ('flynn', 1.7996646487351682),\n",
       " ('andrews', 1.7764919970972666),\n",
       " ('homer', 1.7692866133759964),\n",
       " ('beautifully', 1.7626953362841438),\n",
       " ('soccer', 1.7578579175523736)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_ratios.most_common()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boll', -4.0778152602708904),\n",
       " ('uwe', -3.9218753018711578),\n",
       " ('seagal', -3.3202501058581921),\n",
       " ('unwatchable', -3.0269848170580955),\n",
       " ('stinker', -2.9876839403711624),\n",
       " ('mst', -2.7753833211707968),\n",
       " ('incoherent', -2.7641396677532537),\n",
       " ('unfunny', -2.5545257844967644),\n",
       " ('waste', -2.4907515123361046),\n",
       " ('blah', -2.4475792789485005),\n",
       " ('horrid', -2.3715779644809971),\n",
       " ('pointless', -2.3451073877136341),\n",
       " ('atrocious', -2.3187369339642556),\n",
       " ('redeeming', -2.2667790015910296),\n",
       " ('prom', -2.2601040980178784),\n",
       " ('drivel', -2.2476029585766928),\n",
       " ('lousy', -2.2118080125207054),\n",
       " ('worst', -2.1930856334332267),\n",
       " ('laughable', -2.172468615469592),\n",
       " ('awful', -2.1385076866397488),\n",
       " ('poorly', -2.1326133844207011),\n",
       " ('wasting', -2.1178155545614512),\n",
       " ('remotely', -2.111046881095167),\n",
       " ('existent', -2.0024805005437076),\n",
       " ('boredom', -1.9241486572738005),\n",
       " ('miserably', -1.9216610938019989),\n",
       " ('sucks', -1.9166645809588516),\n",
       " ('uninspired', -1.9131499212248517),\n",
       " ('lame', -1.9117232884159072),\n",
       " ('insult', -1.9085323769376259)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reversed(pos_neg_ratios.most_common()))[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Text into Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74075\n"
     ]
    }
   ],
   "source": [
    "vocab = set(total_count.keys())\n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create empty vector\n",
    "import numpy as np\n",
    "layer_0 = np.zeros((1,vocab_size))\n",
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " 'province': 1,\n",
       " 'banner': 2,\n",
       " 'reprehensibly': 3,\n",
       " 'launius': 4,\n",
       " 'cameroonian': 5,\n",
       " 'pangborn': 6,\n",
       " 'ultimatums': 7,\n",
       " 'prominant': 8,\n",
       " 'heywood': 9,\n",
       " 'stuntwork': 10,\n",
       " 'murry': 11,\n",
       " 'crashed': 12,\n",
       " 'localize': 13,\n",
       " 'det': 14,\n",
       " 'southerland': 15,\n",
       " 'sofas': 16,\n",
       " 'genera': 17,\n",
       " 'camper': 18,\n",
       " 'gouge': 19,\n",
       " 'golino': 20,\n",
       " 'vinchenzo': 21,\n",
       " 'weddings': 22,\n",
       " 'hitched': 23,\n",
       " 'monochrome': 24,\n",
       " 'ej': 25,\n",
       " 'libidinal': 26,\n",
       " 'altering': 27,\n",
       " 'mayweather': 28,\n",
       " 'hesseman': 29,\n",
       " 'appropriating': 30,\n",
       " 'gentlemen': 31,\n",
       " 'concede': 32,\n",
       " 'motley': 33,\n",
       " 'candles': 34,\n",
       " 'pollination': 35,\n",
       " 'bhat': 36,\n",
       " 'hc': 37,\n",
       " 'dehaven': 38,\n",
       " 'incinerates': 39,\n",
       " 'nany': 40,\n",
       " 'scoobys': 41,\n",
       " 'sympathiser': 42,\n",
       " 'fenwick': 43,\n",
       " 'davidtz': 44,\n",
       " 'numbs': 45,\n",
       " 'fantasies': 46,\n",
       " 'underhanded': 47,\n",
       " 'dunce': 48,\n",
       " 'orla': 49,\n",
       " 'janset': 50,\n",
       " 'donnacha': 51,\n",
       " 'popularism': 52,\n",
       " 'power': 53,\n",
       " 'edits': 54,\n",
       " 'catchers': 55,\n",
       " 'need': 56,\n",
       " 'chaplinesque': 57,\n",
       " 'grifts': 58,\n",
       " 'macchesney': 59,\n",
       " 'pierson': 60,\n",
       " 'shyly': 61,\n",
       " 'unappealling': 62,\n",
       " 'condorwhich': 63,\n",
       " 'brocksmith': 64,\n",
       " 'piazza': 65,\n",
       " 'onto': 66,\n",
       " 'awards': 67,\n",
       " 'twoface': 68,\n",
       " 'ludvig': 69,\n",
       " 'piranhas': 70,\n",
       " 'agae': 71,\n",
       " 'luckett': 72,\n",
       " 'narrator': 73,\n",
       " 'batlike': 74,\n",
       " 'stoker': 75,\n",
       " 'infective': 76,\n",
       " 'waldis': 77,\n",
       " 'studmuffins': 78,\n",
       " 'saskatchewan': 79,\n",
       " 'ppl': 80,\n",
       " 'swithes': 81,\n",
       " 'backpacking': 82,\n",
       " 'tell': 83,\n",
       " 'azariah': 84,\n",
       " 'trudging': 85,\n",
       " 'lamented': 86,\n",
       " 'tin': 87,\n",
       " 'replying': 88,\n",
       " 'intermingled': 89,\n",
       " 'glacial': 90,\n",
       " 'brooklyn': 91,\n",
       " 'ebsen': 92,\n",
       " 'axton': 93,\n",
       " 'tembi': 94,\n",
       " 'psses': 95,\n",
       " 'undeserved': 96,\n",
       " 'restate': 97,\n",
       " 'whatch': 98,\n",
       " 'ewers': 99,\n",
       " 'powerhouse': 100,\n",
       " 'presbyterian': 101,\n",
       " 'lafanu': 102,\n",
       " 'adios': 103,\n",
       " 'twinkling': 104,\n",
       " 'arcadia': 105,\n",
       " 'englund': 106,\n",
       " 'conklin': 107,\n",
       " 'perplexedly': 108,\n",
       " 'sammo': 109,\n",
       " 'feminine': 110,\n",
       " 'ascerbic': 111,\n",
       " 'hoshino': 112,\n",
       " 'bedknob': 113,\n",
       " 'classroom': 114,\n",
       " 'arbitrary': 115,\n",
       " 'ould': 116,\n",
       " 'maharishi': 117,\n",
       " 'findus': 118,\n",
       " 'personnal': 119,\n",
       " 'brune': 120,\n",
       " 'pocketful': 121,\n",
       " 'rochfort': 122,\n",
       " 'afficionados': 123,\n",
       " 'bauman': 124,\n",
       " 'necromancy': 125,\n",
       " 'models': 126,\n",
       " 'duchess': 127,\n",
       " 'reverbed': 128,\n",
       " 'lowered': 129,\n",
       " 'minorly': 130,\n",
       " 'fomentation': 131,\n",
       " 'disgraced': 132,\n",
       " 'carribien': 133,\n",
       " 'deceptive': 134,\n",
       " 'tuggee': 135,\n",
       " 'damiella': 136,\n",
       " 'reoccurred': 137,\n",
       " 'divorce': 138,\n",
       " 'hoyberger': 139,\n",
       " 'goal': 140,\n",
       " 'ceases': 141,\n",
       " 'loiret': 142,\n",
       " 'bluto': 143,\n",
       " 'remaking': 144,\n",
       " 'silvio': 145,\n",
       " 'discolored': 146,\n",
       " 'soon': 147,\n",
       " 'porfirio': 148,\n",
       " 'pardu': 149,\n",
       " 'dyson': 150,\n",
       " 'intermixed': 151,\n",
       " 'adeptness': 152,\n",
       " 'kwon': 153,\n",
       " 'truncheons': 154,\n",
       " 'klaws': 155,\n",
       " 'humphries': 156,\n",
       " 'pearlstein': 157,\n",
       " 'correctness': 158,\n",
       " 'archaeologist': 159,\n",
       " 'horribleness': 160,\n",
       " 'linderby': 161,\n",
       " 'ridiculous': 162,\n",
       " 'nsync': 163,\n",
       " 'relative': 164,\n",
       " 'revulsion': 165,\n",
       " 'mimicry': 166,\n",
       " 'harks': 167,\n",
       " 'wyle': 168,\n",
       " 'mcmahon': 169,\n",
       " 'trivialize': 170,\n",
       " 'plum': 171,\n",
       " 'separate': 172,\n",
       " 'kimball': 173,\n",
       " 'furnishings': 174,\n",
       " 'glom': 175,\n",
       " 'jamon': 176,\n",
       " 'biding': 177,\n",
       " 'dano': 178,\n",
       " 'soles': 179,\n",
       " 'condense': 180,\n",
       " 'crossbows': 181,\n",
       " 'kavogianni': 182,\n",
       " 'nodded': 183,\n",
       " 'overdramatizes': 184,\n",
       " 'grays': 185,\n",
       " 'traumatize': 186,\n",
       " 'brighter': 187,\n",
       " 'clarinett': 188,\n",
       " 'mode': 189,\n",
       " 'innovates': 190,\n",
       " 'eradicating': 191,\n",
       " 'veterans': 192,\n",
       " 'mona': 193,\n",
       " 'goodfellas': 194,\n",
       " 'dashiel': 195,\n",
       " 'latine': 196,\n",
       " 'falsehoods': 197,\n",
       " 'civilian': 198,\n",
       " 'sickens': 199,\n",
       " 'eyeshadow': 200,\n",
       " 'albeit': 201,\n",
       " 'acs': 202,\n",
       " 'eerier': 203,\n",
       " 'eliott': 204,\n",
       " 'schlubs': 205,\n",
       " 'rents': 206,\n",
       " 'amerindian': 207,\n",
       " 'preference': 208,\n",
       " 'rebukes': 209,\n",
       " 'unease': 210,\n",
       " 'skinnings': 211,\n",
       " 'conure': 212,\n",
       " 'recherch': 213,\n",
       " 'costars': 214,\n",
       " 'hermione': 215,\n",
       " 'beg': 216,\n",
       " 'chastened': 217,\n",
       " 'fmvs': 218,\n",
       " 'imported': 219,\n",
       " 'occupents': 220,\n",
       " 'severities': 221,\n",
       " 'inlay': 222,\n",
       " 'lagos': 223,\n",
       " 'gaynor': 224,\n",
       " 'differents': 225,\n",
       " 'gangly': 226,\n",
       " 'bullion': 227,\n",
       " 'hasnt': 228,\n",
       " 'woodsball': 229,\n",
       " 'advent': 230,\n",
       " 'schneider': 231,\n",
       " 'hepcats': 232,\n",
       " 'kaante': 233,\n",
       " 'degenerate': 234,\n",
       " 'communion': 235,\n",
       " 'restrooms': 236,\n",
       " 'mindful': 237,\n",
       " 'mario': 238,\n",
       " 'sits': 239,\n",
       " 'charlies': 240,\n",
       " 'insubordinate': 241,\n",
       " 'ravings': 242,\n",
       " 'contretemps': 243,\n",
       " 'ventilation': 244,\n",
       " 'akim': 245,\n",
       " 'seriuosly': 246,\n",
       " 'cognates': 247,\n",
       " 'locoformovies': 248,\n",
       " 'inedible': 249,\n",
       " 'herring': 250,\n",
       " 'wacthing': 251,\n",
       " 'fuehrer': 252,\n",
       " 'moguls': 253,\n",
       " 'unmemorably': 254,\n",
       " 'manners': 255,\n",
       " 'lowball': 256,\n",
       " 'promoted': 257,\n",
       " 'luege': 258,\n",
       " 'possesor': 259,\n",
       " 'beetles': 260,\n",
       " 'london': 261,\n",
       " 'cridits': 262,\n",
       " 'sealer': 263,\n",
       " 'algorithm': 264,\n",
       " 'hagelin': 265,\n",
       " 'shrink': 266,\n",
       " 'wlaken': 267,\n",
       " 'shaw': 268,\n",
       " 'dalla': 269,\n",
       " 'lubricants': 270,\n",
       " 'producer': 271,\n",
       " 'briers': 272,\n",
       " 'enzos': 273,\n",
       " 'playmate': 274,\n",
       " 'ditsy': 275,\n",
       " 'asinine': 276,\n",
       " 'bremen': 277,\n",
       " 'harangued': 278,\n",
       " 'approachable': 279,\n",
       " 'ostensibly': 280,\n",
       " 'mendona': 281,\n",
       " 'strays': 282,\n",
       " 'obsesses': 283,\n",
       " 'macchu': 284,\n",
       " 'leontine': 285,\n",
       " 'punk': 286,\n",
       " 'surgeries': 287,\n",
       " 'thatseriously': 288,\n",
       " 'matthews': 289,\n",
       " 'stifle': 290,\n",
       " 'totem': 291,\n",
       " 'protoplasm': 292,\n",
       " 'rushworth': 293,\n",
       " 'subiaco': 294,\n",
       " 'quibble': 295,\n",
       " 'sardo': 296,\n",
       " 'exorcise': 297,\n",
       " 'mortality': 298,\n",
       " 'tapeworm': 299,\n",
       " 'spalding': 300,\n",
       " 'sabine': 301,\n",
       " 'hellman': 302,\n",
       " 'fabin': 303,\n",
       " 'multiplying': 304,\n",
       " 'edginess': 305,\n",
       " 'goodluck': 306,\n",
       " 'worthing': 307,\n",
       " 'starkest': 308,\n",
       " 'fixtures': 309,\n",
       " 'leonor': 310,\n",
       " 'magnitude': 311,\n",
       " 'mcclure': 312,\n",
       " 'lockup': 313,\n",
       " 'assisting': 314,\n",
       " 'kept': 315,\n",
       " 'overdirection': 316,\n",
       " 'supermoral': 317,\n",
       " 'masaru': 318,\n",
       " 'lashley': 319,\n",
       " 'surreptitious': 320,\n",
       " 'looney': 321,\n",
       " 'ryack': 322,\n",
       " 'kotia': 323,\n",
       " 'rokkuchan': 324,\n",
       " 'doughton': 325,\n",
       " 'cranking': 326,\n",
       " 'revolutionise': 327,\n",
       " 'intermittedly': 328,\n",
       " 'procrastination': 329,\n",
       " 'taxpayers': 330,\n",
       " 'governor': 331,\n",
       " 'cardella': 332,\n",
       " 'lionels': 333,\n",
       " 'fahey': 334,\n",
       " 'goundamani': 335,\n",
       " 'herder': 336,\n",
       " 'ratio': 337,\n",
       " 'chesticles': 338,\n",
       " 'killin': 339,\n",
       " 'coyotes': 340,\n",
       " 'chechens': 341,\n",
       " 'playschool': 342,\n",
       " 'headaches': 343,\n",
       " 'detect': 344,\n",
       " 'juggles': 345,\n",
       " 'hiasashi': 346,\n",
       " 'grandeurs': 347,\n",
       " 'pacifist': 348,\n",
       " 'recovery': 349,\n",
       " 'catastrophes': 350,\n",
       " 'paring': 351,\n",
       " 'elder': 352,\n",
       " 'dillinger': 353,\n",
       " 'boppity': 354,\n",
       " 'faddish': 355,\n",
       " 'signe': 356,\n",
       " 'bekker': 357,\n",
       " 'montplaisir': 358,\n",
       " 'subjectivity': 359,\n",
       " 'spiceworld': 360,\n",
       " 'makeups': 361,\n",
       " 'gunnery': 362,\n",
       " 'anu': 363,\n",
       " 'ariete': 364,\n",
       " 'gozilla': 365,\n",
       " 'gays': 366,\n",
       " 'goalkeeper': 367,\n",
       " 'medusan': 368,\n",
       " 'conaway': 369,\n",
       " 'weoponry': 370,\n",
       " 'lenin': 371,\n",
       " 'ebullient': 372,\n",
       " 'clutch': 373,\n",
       " 'invalidate': 374,\n",
       " 'controls': 375,\n",
       " 'heavyhanded': 376,\n",
       " 'shepley': 377,\n",
       " 'monters': 378,\n",
       " 'ali': 379,\n",
       " 'jfk': 380,\n",
       " 'sleazebags': 381,\n",
       " 'tiangle': 382,\n",
       " 'yawner': 383,\n",
       " 'lupin': 384,\n",
       " 'chan': 385,\n",
       " 'rehman': 386,\n",
       " 'piaf': 387,\n",
       " 'lied': 388,\n",
       " 'unbind': 389,\n",
       " 'sahib': 390,\n",
       " 'nobody': 391,\n",
       " 'volunteered': 392,\n",
       " 'parade': 393,\n",
       " 'foulata': 394,\n",
       " 'sens': 395,\n",
       " 'kumar': 396,\n",
       " 'khoda': 397,\n",
       " 'vajpai': 398,\n",
       " 'longs': 399,\n",
       " 'dedications': 400,\n",
       " 'horsemen': 401,\n",
       " 'keeffe': 402,\n",
       " 'oblivious': 403,\n",
       " 'alcoholism': 404,\n",
       " 'spectaculars': 405,\n",
       " 'rekindles': 406,\n",
       " 'repainted': 407,\n",
       " 'weepers': 408,\n",
       " 'musson': 409,\n",
       " 'globalism': 410,\n",
       " 'spurn': 411,\n",
       " 'boofs': 412,\n",
       " 'excelsior': 413,\n",
       " 'choreograph': 414,\n",
       " 'flava': 415,\n",
       " 'sexpot': 416,\n",
       " 'eick': 417,\n",
       " 'nordham': 418,\n",
       " 'bestselling': 419,\n",
       " 'technologies': 420,\n",
       " 'tingwell': 421,\n",
       " 'sugest': 422,\n",
       " 'gharanas': 423,\n",
       " 'strangulations': 424,\n",
       " 'baxtor': 425,\n",
       " 'ted': 426,\n",
       " 'predetermined': 427,\n",
       " 'thicker': 428,\n",
       " 'leathal': 429,\n",
       " 'rosencrantz': 430,\n",
       " 'yobs': 431,\n",
       " 'verry': 432,\n",
       " 'tvone': 433,\n",
       " 'sickie': 434,\n",
       " 'housman': 435,\n",
       " 'missiles': 436,\n",
       " 'munnera': 437,\n",
       " 'simulator': 438,\n",
       " 'eq': 439,\n",
       " 'endures': 440,\n",
       " 'eightball': 441,\n",
       " 'anywhere': 442,\n",
       " 'romcomic': 443,\n",
       " 'werewolfs': 444,\n",
       " 'blind': 445,\n",
       " 'kooks': 446,\n",
       " 'demi': 447,\n",
       " 'muerto': 448,\n",
       " 'cauldrons': 449,\n",
       " 'uncorrected': 450,\n",
       " 'bentivoglio': 451,\n",
       " 'disclamer': 452,\n",
       " 'motorcars': 453,\n",
       " 'whinge': 454,\n",
       " 'commotion': 455,\n",
       " 'scariest': 456,\n",
       " 'toofan': 457,\n",
       " 'realises': 458,\n",
       " 'scatty': 459,\n",
       " 'jampacked': 460,\n",
       " 'whacky': 461,\n",
       " 'hathor': 462,\n",
       " 'edition': 463,\n",
       " 'quintessential': 464,\n",
       " 'nelsons': 465,\n",
       " 'inculcated': 466,\n",
       " 'thence': 467,\n",
       " 'malleson': 468,\n",
       " 'cinematoraphy': 469,\n",
       " 'tungtvannet': 470,\n",
       " 'ohhh': 471,\n",
       " 'muckraker': 472,\n",
       " 'hypothesized': 473,\n",
       " 'mush': 474,\n",
       " 'dateness': 475,\n",
       " 'orgy': 476,\n",
       " 'insipidness': 477,\n",
       " 'extense': 478,\n",
       " 'disheartened': 479,\n",
       " 'sword': 480,\n",
       " 'occassional': 481,\n",
       " 'qualifiers': 482,\n",
       " 'roams': 483,\n",
       " 'contacting': 484,\n",
       " 'ifans': 485,\n",
       " 'notary': 486,\n",
       " 'takaya': 487,\n",
       " 'manfredi': 488,\n",
       " 'titled': 489,\n",
       " 'monsta': 490,\n",
       " 'heterosexuality': 491,\n",
       " 'einstien': 492,\n",
       " 'ribbing': 493,\n",
       " 'discourages': 494,\n",
       " 'centers': 495,\n",
       " 'mutt': 496,\n",
       " 'thine': 497,\n",
       " 'supers': 498,\n",
       " 'cody': 499,\n",
       " 'beleaguered': 500,\n",
       " 'druthers': 501,\n",
       " 'prepoire': 502,\n",
       " 'unmysterious': 503,\n",
       " 'violins': 504,\n",
       " 'intimacies': 505,\n",
       " 'bocabonita': 506,\n",
       " 'dandridge': 507,\n",
       " 'virtuostic': 508,\n",
       " 'jersey': 509,\n",
       " 'sulk': 510,\n",
       " 'parochialism': 511,\n",
       " 'duking': 512,\n",
       " 'eloquent': 513,\n",
       " 'swoons': 514,\n",
       " 'reconsider': 515,\n",
       " 'femur': 516,\n",
       " 'dips': 517,\n",
       " 'preetam': 518,\n",
       " 'grant': 519,\n",
       " 'walt': 520,\n",
       " 'balanchine': 521,\n",
       " 'eritated': 522,\n",
       " 'miko': 523,\n",
       " 'eastenders': 524,\n",
       " 'hiralal': 525,\n",
       " 'wards': 526,\n",
       " 'viju': 527,\n",
       " 'bridges': 528,\n",
       " 'transformed': 529,\n",
       " 'realizing': 530,\n",
       " 'outlooking': 531,\n",
       " 'fulfilment': 532,\n",
       " 'wronged': 533,\n",
       " 'deklerk': 534,\n",
       " 'nearside': 535,\n",
       " 'jutland': 536,\n",
       " 'beholder': 537,\n",
       " 'mannu': 538,\n",
       " 'hatcher': 539,\n",
       " 'pacified': 540,\n",
       " 'relationsip': 541,\n",
       " 'ginny': 542,\n",
       " 'soberingly': 543,\n",
       " 'modulation': 544,\n",
       " 'ceta': 545,\n",
       " 'keren': 546,\n",
       " 'hyrum': 547,\n",
       " 'whitch': 548,\n",
       " 'shagging': 549,\n",
       " 'flickerino': 550,\n",
       " 'aero': 551,\n",
       " 'overhyping': 552,\n",
       " 'saw': 553,\n",
       " 'remarque': 554,\n",
       " 'nonfiction': 555,\n",
       " 'oddities': 556,\n",
       " 'epitomized': 557,\n",
       " 'pessimistic': 558,\n",
       " 'writhing': 559,\n",
       " 'fink': 560,\n",
       " 'menaces': 561,\n",
       " 'marner': 562,\n",
       " 'menari': 563,\n",
       " 'rigging': 564,\n",
       " 'stepp': 565,\n",
       " 'scalia': 566,\n",
       " 'maccarthy': 567,\n",
       " 'criticisms': 568,\n",
       " 'mercs': 569,\n",
       " 'tiny': 570,\n",
       " 'naefe': 571,\n",
       " 'luca': 572,\n",
       " 'jawaharlal': 573,\n",
       " 'nth': 574,\n",
       " 'higuchi': 575,\n",
       " 'gimp': 576,\n",
       " 'fck': 577,\n",
       " 'urbaniak': 578,\n",
       " 'securities': 579,\n",
       " 'hillbillies': 580,\n",
       " 'iconography': 581,\n",
       " 'curative': 582,\n",
       " 'damn': 583,\n",
       " 'bowel': 584,\n",
       " 'jugars': 585,\n",
       " 'doogie': 586,\n",
       " 'cornish': 587,\n",
       " 'bombin': 588,\n",
       " 'chonopolisians': 589,\n",
       " 'propagated': 590,\n",
       " 'leonine': 591,\n",
       " 'renard': 592,\n",
       " 'performanceeven': 593,\n",
       " 'empt': 594,\n",
       " 'sailplane': 595,\n",
       " 'halprin': 596,\n",
       " 'smyrner': 597,\n",
       " 'irreproachable': 598,\n",
       " 'sweetin': 599,\n",
       " 'nudge': 600,\n",
       " 'hellenic': 601,\n",
       " 'bogdanovic': 602,\n",
       " 'injun': 603,\n",
       " 'danube': 604,\n",
       " 'profoundly': 605,\n",
       " 'hyped': 606,\n",
       " 'prodding': 607,\n",
       " 'youknowwhat': 608,\n",
       " 'greaest': 609,\n",
       " 'mahdist': 610,\n",
       " 'muscular': 611,\n",
       " 'someincredibly': 612,\n",
       " 'chronicled': 613,\n",
       " 'voluble': 614,\n",
       " 'wildcats': 615,\n",
       " 'vip': 616,\n",
       " 'heartbreaker': 617,\n",
       " 'bathed': 618,\n",
       " 'vulnerable': 619,\n",
       " 'kiyomasa': 620,\n",
       " 'wizardry': 621,\n",
       " 'dini': 622,\n",
       " 'behavioural': 623,\n",
       " 'tennesee': 624,\n",
       " 'reece': 625,\n",
       " 'artistically': 626,\n",
       " 'spririt': 627,\n",
       " 'handedness': 628,\n",
       " 'circuitous': 629,\n",
       " 'lifelike': 630,\n",
       " 'warningthis': 631,\n",
       " 'commuter': 632,\n",
       " 'faces': 633,\n",
       " 'badiel': 634,\n",
       " 'caprino': 635,\n",
       " 'unharmed': 636,\n",
       " 'slave': 637,\n",
       " 'incredulous': 638,\n",
       " 'lamont': 639,\n",
       " 'monthly': 640,\n",
       " 'retires': 641,\n",
       " 'languished': 642,\n",
       " 'acadamy': 643,\n",
       " 'itinerant': 644,\n",
       " 'taglialucci': 645,\n",
       " 'oberoi': 646,\n",
       " 'manitoba': 647,\n",
       " 'mourby': 648,\n",
       " 'toys': 649,\n",
       " 'unburied': 650,\n",
       " 'rubens': 651,\n",
       " 'lillihamer': 652,\n",
       " 'functionality': 653,\n",
       " 'hep': 654,\n",
       " 'croats': 655,\n",
       " 'frowning': 656,\n",
       " 'loyalists': 657,\n",
       " 'wilosn': 658,\n",
       " 'subgenera': 659,\n",
       " 'delamere': 660,\n",
       " 'seawater': 661,\n",
       " 'brew': 662,\n",
       " 'mistaken': 663,\n",
       " 'maratonci': 664,\n",
       " 'approached': 665,\n",
       " 'pricey': 666,\n",
       " 'kiowa': 667,\n",
       " 'grammatically': 668,\n",
       " 'cada': 669,\n",
       " 'rosalie': 670,\n",
       " 'leonowens': 671,\n",
       " 'killers': 672,\n",
       " 'tripod': 673,\n",
       " 'rejection': 674,\n",
       " 'caress': 675,\n",
       " 'protocols': 676,\n",
       " 'whalley': 677,\n",
       " 'preacher': 678,\n",
       " 'schygulla': 679,\n",
       " 'adherent': 680,\n",
       " 'intestinal': 681,\n",
       " 'tickets': 682,\n",
       " 'autograph': 683,\n",
       " 'pruned': 684,\n",
       " 'morningstar': 685,\n",
       " 'bene': 686,\n",
       " 'farnworth': 687,\n",
       " 'assignment': 688,\n",
       " 'familiars': 689,\n",
       " 'hier': 690,\n",
       " 'jenner': 691,\n",
       " 'tee': 692,\n",
       " 'fortunes': 693,\n",
       " 'scalps': 694,\n",
       " 'citizenx': 695,\n",
       " 'headless': 696,\n",
       " 'morphing': 697,\n",
       " 'comedies': 698,\n",
       " 'font': 699,\n",
       " 'wastebasket': 700,\n",
       " 'ministers': 701,\n",
       " 'krav': 702,\n",
       " 'kruishoop': 703,\n",
       " 'roodt': 704,\n",
       " 'richly': 705,\n",
       " 'rottens': 706,\n",
       " 'fictionalizes': 707,\n",
       " 'asswipe': 708,\n",
       " 'giulio': 709,\n",
       " 'blockbuster': 710,\n",
       " 'enriched': 711,\n",
       " 'denoting': 712,\n",
       " 'gothic': 713,\n",
       " 'harpsichordist': 714,\n",
       " 'herculean': 715,\n",
       " 'epiphanal': 716,\n",
       " 'delphy': 717,\n",
       " 'tite': 718,\n",
       " 'friction': 719,\n",
       " 'youngish': 720,\n",
       " 'curatola': 721,\n",
       " 'connecticute': 722,\n",
       " 'bebe': 723,\n",
       " 'buggy': 724,\n",
       " 'vidor': 725,\n",
       " 'mazurki': 726,\n",
       " 'lonelygirl': 727,\n",
       " 'unmarked': 728,\n",
       " 'piety': 729,\n",
       " 'mitsugoro': 730,\n",
       " 'melida': 731,\n",
       " 'macdonald': 732,\n",
       " 'horrifically': 733,\n",
       " 'license': 734,\n",
       " 'enchants': 735,\n",
       " 'dodeskaden': 736,\n",
       " 'silverado': 737,\n",
       " 'denials': 738,\n",
       " 'leisen': 739,\n",
       " 'updates': 740,\n",
       " 'itches': 741,\n",
       " 'metabolism': 742,\n",
       " 'neglecting': 743,\n",
       " 'dott': 744,\n",
       " 'favoritism': 745,\n",
       " 'titillating': 746,\n",
       " 'seafaring': 747,\n",
       " 'imaginable': 748,\n",
       " 'resold': 749,\n",
       " 'proffers': 750,\n",
       " 'fuchsias': 751,\n",
       " 'cincy': 752,\n",
       " 'imagina': 753,\n",
       " 'clemens': 754,\n",
       " 'kindergartener': 755,\n",
       " 'presumable': 756,\n",
       " 'giegud': 757,\n",
       " 'narnia': 758,\n",
       " 'sleazier': 759,\n",
       " 'gehrlich': 760,\n",
       " 'rebounding': 761,\n",
       " 'kelvin': 762,\n",
       " 'disillusionment': 763,\n",
       " 'sexualized': 764,\n",
       " 'valets': 765,\n",
       " 'imperfectionist': 766,\n",
       " 'gangsterism': 767,\n",
       " 'enumerated': 768,\n",
       " 'hokier': 769,\n",
       " 'guetary': 770,\n",
       " 'draught': 771,\n",
       " 'minimums': 772,\n",
       " 'bittersweetly': 773,\n",
       " 'codgers': 774,\n",
       " 'empahsise': 775,\n",
       " 'tersteeghe': 776,\n",
       " 'cannibalizing': 777,\n",
       " 'alternative': 778,\n",
       " 'yesit': 779,\n",
       " 'jacknife': 780,\n",
       " 'splintering': 781,\n",
       " 'redid': 782,\n",
       " 'kids': 783,\n",
       " 'grandin': 784,\n",
       " 'nutsack': 785,\n",
       " 'lindon': 786,\n",
       " 'clenching': 787,\n",
       " 'snide': 788,\n",
       " 'ruptured': 789,\n",
       " 'abanazer': 790,\n",
       " 'bogus': 791,\n",
       " 'soto': 792,\n",
       " 'decomposes': 793,\n",
       " 'chinese': 794,\n",
       " 'braid': 795,\n",
       " 'bulimia': 796,\n",
       " 'morays': 797,\n",
       " 'corbet': 798,\n",
       " 'lysol': 799,\n",
       " 'dubois': 800,\n",
       " 'andrs': 801,\n",
       " 'whiting': 802,\n",
       " 'shepherds': 803,\n",
       " 'fearhalloween': 804,\n",
       " 'tout': 805,\n",
       " 'silvester': 806,\n",
       " 'ourt': 807,\n",
       " 'charlene': 808,\n",
       " 'divergent': 809,\n",
       " 'jokiness': 810,\n",
       " 'lowbudget': 811,\n",
       " 'railways': 812,\n",
       " 'scan': 813,\n",
       " 'beethtoven': 814,\n",
       " 'logothethis': 815,\n",
       " 'conventexploitation': 816,\n",
       " 'unskilled': 817,\n",
       " 'misato': 818,\n",
       " 'stepmotherhood': 819,\n",
       " 'defecating': 820,\n",
       " 'rufus': 821,\n",
       " 'niceness': 822,\n",
       " 'cartoonish': 823,\n",
       " 'practises': 824,\n",
       " 'hereit': 825,\n",
       " 'tpm': 826,\n",
       " 'mike': 827,\n",
       " 'translated': 828,\n",
       " 'undoing': 829,\n",
       " 'universally': 830,\n",
       " 'domingo': 831,\n",
       " 'shied': 832,\n",
       " 'laxitive': 833,\n",
       " 'straithrain': 834,\n",
       " 'featherweight': 835,\n",
       " 'dresdel': 836,\n",
       " 'biochemical': 837,\n",
       " 'jayston': 838,\n",
       " 'rocket': 839,\n",
       " 'darkon': 840,\n",
       " 'seild': 841,\n",
       " 'bissell': 842,\n",
       " 'dissapionted': 843,\n",
       " 'jury': 844,\n",
       " 'costco': 845,\n",
       " 'story': 846,\n",
       " 'antwerp': 847,\n",
       " 'mermaid': 848,\n",
       " 'macfadyen': 849,\n",
       " 'progresses': 850,\n",
       " 'gaudenzi': 851,\n",
       " 'yoghurt': 852,\n",
       " 'dookie': 853,\n",
       " 'dorkiest': 854,\n",
       " 'matteo': 855,\n",
       " 'outward': 856,\n",
       " 'letterbox': 857,\n",
       " 'marquee': 858,\n",
       " 'destructs': 859,\n",
       " 'joyously': 860,\n",
       " 'binding': 861,\n",
       " 'spiro': 862,\n",
       " 'swooningly': 863,\n",
       " 'sabina': 864,\n",
       " 'cogently': 865,\n",
       " 'schiller': 866,\n",
       " 'fogies': 867,\n",
       " 'arnis': 868,\n",
       " 'croc': 869,\n",
       " 'viscerally': 870,\n",
       " 'mute': 871,\n",
       " 'slowest': 872,\n",
       " 'famkhee': 873,\n",
       " 'klause': 874,\n",
       " 'mulgrew': 875,\n",
       " 'alkie': 876,\n",
       " 'seawall': 877,\n",
       " 'foreigners': 878,\n",
       " 'stashes': 879,\n",
       " 'injuries': 880,\n",
       " 'blank': 881,\n",
       " 'venoms': 882,\n",
       " 'expelled': 883,\n",
       " 'rossilini': 884,\n",
       " 'clunkily': 885,\n",
       " 'infantilize': 886,\n",
       " 'infirm': 887,\n",
       " 'fernanda': 888,\n",
       " 'daughters': 889,\n",
       " 'bosom': 890,\n",
       " 'chemists': 891,\n",
       " 'ozzie': 892,\n",
       " 'pollinated': 893,\n",
       " 'madigan': 894,\n",
       " 'wolves': 895,\n",
       " 'easter': 896,\n",
       " 'vovchenko': 897,\n",
       " 'dvrd': 898,\n",
       " 'schlockmeister': 899,\n",
       " 'paled': 900,\n",
       " 'snuffed': 901,\n",
       " 'shareholders': 902,\n",
       " 'phony': 903,\n",
       " 'stench': 904,\n",
       " 'kosmos': 905,\n",
       " 'atleast': 906,\n",
       " 'freelancer': 907,\n",
       " 'bacula': 908,\n",
       " 'dumbvrille': 909,\n",
       " 'flambards': 910,\n",
       " 'batwomen': 911,\n",
       " 'lavagirl': 912,\n",
       " 'jetski': 913,\n",
       " 'farraginous': 914,\n",
       " 'prevailing': 915,\n",
       " 'loathed': 916,\n",
       " 'flores': 917,\n",
       " 'vento': 918,\n",
       " 'absoutley': 919,\n",
       " 'accomplishments': 920,\n",
       " 'downy': 921,\n",
       " 'overcome': 922,\n",
       " 'enigmatic': 923,\n",
       " 'gingerbread': 924,\n",
       " 'winston': 925,\n",
       " 'edgerton': 926,\n",
       " 'seizureific': 927,\n",
       " 'poetical': 928,\n",
       " 'shandling': 929,\n",
       " 'mcintire': 930,\n",
       " 'acids': 931,\n",
       " 'places': 932,\n",
       " 'righted': 933,\n",
       " 'unproductive': 934,\n",
       " 'deepening': 935,\n",
       " 'sena': 936,\n",
       " 'lindsley': 937,\n",
       " 'conde': 938,\n",
       " 'kalifornia': 939,\n",
       " 'bullfights': 940,\n",
       " 'placid': 941,\n",
       " 'calafornia': 942,\n",
       " 'palookaville': 943,\n",
       " 'rodney': 944,\n",
       " 'shiztz': 945,\n",
       " 'rails': 946,\n",
       " 'indescribable': 947,\n",
       " 'valli': 948,\n",
       " 'beachcombers': 949,\n",
       " 'awfully': 950,\n",
       " 'heftily': 951,\n",
       " 'profile': 952,\n",
       " 'infused': 953,\n",
       " 'normalcy': 954,\n",
       " 'forebodings': 955,\n",
       " 'uriah': 956,\n",
       " 'terminus': 957,\n",
       " 'teleprinter': 958,\n",
       " 'pictures': 959,\n",
       " 'deliver': 960,\n",
       " 'belief': 961,\n",
       " 'imo': 962,\n",
       " 'trucks': 963,\n",
       " 'lays': 964,\n",
       " 'caster': 965,\n",
       " 'wodka': 966,\n",
       " 'meiks': 967,\n",
       " 'lampio': 968,\n",
       " 'sandell': 969,\n",
       " 'lunge': 970,\n",
       " 'valentines': 971,\n",
       " 'praise': 972,\n",
       " 'colonisation': 973,\n",
       " 'implode': 974,\n",
       " 'saucers': 975,\n",
       " 'shelving': 976,\n",
       " 'ggauff': 977,\n",
       " 'impeccable': 978,\n",
       " 'representational': 979,\n",
       " 'minamoto': 980,\n",
       " 'minny': 981,\n",
       " 'tenebre': 982,\n",
       " 'mollusks': 983,\n",
       " 'amuro': 984,\n",
       " 'jodoworsky': 985,\n",
       " 'somwhat': 986,\n",
       " 'conformism': 987,\n",
       " 'therethat': 988,\n",
       " 'carolinas': 989,\n",
       " 'outwitted': 990,\n",
       " 'velvet': 991,\n",
       " 'hugged': 992,\n",
       " 'umdiscriminating': 993,\n",
       " 'reptilian': 994,\n",
       " 'inu': 995,\n",
       " 'unthinkable': 996,\n",
       " 'someday': 997,\n",
       " 'frankly': 998,\n",
       " 'mira': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create word to index\n",
    "word2index = {}\n",
    "\n",
    "for i, word in enumerate(vocab):\n",
    "    word2index[word] = i\n",
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18.,   0.,   0., ...,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_input_layer(review):\n",
    "    global layer_0\n",
    "    layer_0 *= 0\n",
    "    for word in review.split(\" \"):\n",
    "        layer_0[0][word2index[word]] += 1\n",
    "\n",
    "update_input_layer(reviews_clean[0])\n",
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_target_for_label(label):\n",
    "    if(label == \"positive\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "get_target_for_label(labels_clean[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Let's tweak our network from before to model these phenomena\n",
    "class SentimentNetwork:\n",
    "    def __init__(self, reviews,labels,hidden_nodes = 10, learning_rate = 0.1):\n",
    "       \n",
    "        # set our random number generator \n",
    "        np.random.seed(1)\n",
    "    \n",
    "        self.pre_process_data(reviews, labels)\n",
    "        \n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "        \n",
    "        \n",
    "    def pre_process_data(self, reviews, labels):\n",
    "        \n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                review_vocab.add(word)\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "         \n",
    "        \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "    \n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "    \n",
    "        \n",
    "    def update_input_layer(self,review):\n",
    "\n",
    "        # clear out previous state, reset the layer to be all 0s\n",
    "        self.layer_0 *= 0\n",
    "        for word in review.split(\" \"):\n",
    "            if(word in self.word2index.keys()):\n",
    "                self.layer_0[0][self.word2index[word]] += 1\n",
    "                \n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'positive'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def train(self, training_reviews, training_labels):\n",
    "        \n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        correct_so_far = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            #### Implement the forward pass here ####\n",
    "            ### Forward pass ###\n",
    "\n",
    "            # Input Layer\n",
    "            self.update_input_layer(review)\n",
    "\n",
    "            # Hidden layer\n",
    "            layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "            # Output layer\n",
    "            layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "\n",
    "            #### Implement the backward pass here ####\n",
    "            ### Backward pass ###\n",
    "\n",
    "            # TODO: Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # TODO: Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) # errors propagated to the hidden layer\n",
    "            layer_1_delta = layer_1_error # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "\n",
    "            # TODO: Update the weights\n",
    "            self.weights_1_2 -= layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "            self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
    "\n",
    "            if(np.abs(layer_2_error) < 0.5):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \n",
    "        correct = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                            + \"% #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \n",
    "        # Input Layer\n",
    "        self.update_input_layer(review.lower())\n",
    "\n",
    "        # Hidden layer\n",
    "        layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        if(layer_2[0] > 0.5):\n",
    "            return \"positive\"\n",
    "        else:\n",
    "            return \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp = SentimentNetwork(reviews_clean[:-1000], labels_clean[:-1000], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):736.1% #Correct:500 #Tested:1000 Testing Accuracy:50.0%"
     ]
    }
   ],
   "source": [
    "# evaluate our model before training (just to show how horrible it is)\n",
    "mlp.test(reviews_clean[-1000:],labels_clean[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n",
      "Progress:5.08% Speed(reviews/sec):127.6 #Correct:610 #Trained:1222 Training Accuracy:49.9%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-22fad3e31860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews_clean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_clean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-791649e0dc3b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_reviews, training_labels)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[1;31m# TODO: Update the weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights_1_2\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlayer_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_2_delta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;31m# update hidden-to-output weights with gradient descent step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights_0_1\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_1_delta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;31m# update input-to-hidden weights with gradient descent step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_2_error\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp.train(reviews_clean[:-1000],labels_clean[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = SentimentNetwork(reviews_clean[:-1000],labels_clean[:-1000], learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n",
      "Progress:1.87% Speed(reviews/sec):125.7 #Correct:224 #Trained:452 Training Accuracy:49.5%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-dccd702b61f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# train the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews_clean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_clean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-791649e0dc3b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_reviews, training_labels)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[1;31m# TODO: Update the weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights_1_2\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlayer_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_2_delta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;31m# update hidden-to-output weights with gradient descent step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights_0_1\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_1_delta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;31m# update input-to-hidden weights with gradient descent step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_2_error\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "mlp.train(reviews_clean[:-1000],labels_clean[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = SentimentNetwork(reviews_clean[:-1000],labels_clean[:-1000], learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n",
      "Progress:10.4% Speed(reviews/sec):128.9 #Correct:1245 #Trained:2501 Training Accuracy:49.7%\n",
      "Progress:14.8% Speed(reviews/sec):128.8 #Correct:1832 #Trained:3574 Training Accuracy:51.2%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-dccd702b61f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# train the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews_clean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_clean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-791649e0dc3b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_reviews, training_labels)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[1;31m# TODO: Update the weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights_1_2\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlayer_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_2_delta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;31m# update hidden-to-output weights with gradient descent step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights_0_1\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_1_delta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;31m# update input-to-hidden weights with gradient descent step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_2_error\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "mlp.train(reviews_clean[:-1000],labels_clean[:-1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By reducing the learning rate, the neural network is not improving the accuracy fast enough, so we need to change the structure to improve the model\n",
    "\n",
    "### Analyze the signal vs. noise\n",
    "\n",
    "## Understand Neural Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18.,   0.,   0., ...,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vocab)[0]\n",
    "# A noise here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bromwell',\n",
       " 'high',\n",
       " 'is',\n",
       " 'a',\n",
       " 'cartoon',\n",
       " 'comedy',\n",
       " '.',\n",
       " 'it',\n",
       " 'ran',\n",
       " 'at',\n",
       " 'the',\n",
       " 'same',\n",
       " 'time',\n",
       " 'as',\n",
       " 'some',\n",
       " 'other',\n",
       " 'programs',\n",
       " 'about',\n",
       " 'school',\n",
       " 'life',\n",
       " '',\n",
       " 'such',\n",
       " 'as',\n",
       " '',\n",
       " 'teachers',\n",
       " '',\n",
       " '.',\n",
       " 'my',\n",
       " '',\n",
       " '',\n",
       " 'years',\n",
       " 'in',\n",
       " 'the',\n",
       " 'teaching',\n",
       " 'profession',\n",
       " 'lead',\n",
       " 'me',\n",
       " 'to',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'bromwell',\n",
       " 'high',\n",
       " '',\n",
       " 's',\n",
       " 'satire',\n",
       " 'is',\n",
       " 'much',\n",
       " 'closer',\n",
       " 'to',\n",
       " 'reality',\n",
       " 'than',\n",
       " 'is',\n",
       " '',\n",
       " 'teachers',\n",
       " '',\n",
       " '.',\n",
       " 'the',\n",
       " 'scramble',\n",
       " 'to',\n",
       " 'survive',\n",
       " 'financially',\n",
       " '',\n",
       " 'the',\n",
       " 'insightful',\n",
       " 'students',\n",
       " 'who',\n",
       " 'can',\n",
       " 'see',\n",
       " 'right',\n",
       " 'through',\n",
       " 'their',\n",
       " 'pathetic',\n",
       " 'teachers',\n",
       " '',\n",
       " 'pomp',\n",
       " '',\n",
       " 'the',\n",
       " 'pettiness',\n",
       " 'of',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'situation',\n",
       " '',\n",
       " 'all',\n",
       " 'remind',\n",
       " 'me',\n",
       " 'of',\n",
       " 'the',\n",
       " 'schools',\n",
       " 'i',\n",
       " 'knew',\n",
       " 'and',\n",
       " 'their',\n",
       " 'students',\n",
       " '.',\n",
       " 'when',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'the',\n",
       " 'episode',\n",
       " 'in',\n",
       " 'which',\n",
       " 'a',\n",
       " 'student',\n",
       " 'repeatedly',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'burn',\n",
       " 'down',\n",
       " 'the',\n",
       " 'school',\n",
       " '',\n",
       " 'i',\n",
       " 'immediately',\n",
       " 'recalled',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'at',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'high',\n",
       " '.',\n",
       " 'a',\n",
       " 'classic',\n",
       " 'line',\n",
       " 'inspector',\n",
       " 'i',\n",
       " '',\n",
       " 'm',\n",
       " 'here',\n",
       " 'to',\n",
       " 'sack',\n",
       " 'one',\n",
       " 'of',\n",
       " 'your',\n",
       " 'teachers',\n",
       " '.',\n",
       " 'student',\n",
       " 'welcome',\n",
       " 'to',\n",
       " 'bromwell',\n",
       " 'high',\n",
       " '.',\n",
       " 'i',\n",
       " 'expect',\n",
       " 'that',\n",
       " 'many',\n",
       " 'adults',\n",
       " 'of',\n",
       " 'my',\n",
       " 'age',\n",
       " 'think',\n",
       " 'that',\n",
       " 'bromwell',\n",
       " 'high',\n",
       " 'is',\n",
       " 'far',\n",
       " 'fetched',\n",
       " '.',\n",
       " 'what',\n",
       " 'a',\n",
       " 'pity',\n",
       " 'that',\n",
       " 'it',\n",
       " 'isn',\n",
       " '',\n",
       " 't',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_clean[0].split(\" \")\n",
    "# A lot of empty, period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 27),\n",
       " ('', 18),\n",
       " ('the', 9),\n",
       " ('to', 6),\n",
       " ('high', 5),\n",
       " ('i', 5),\n",
       " ('bromwell', 4),\n",
       " ('is', 4),\n",
       " ('a', 4),\n",
       " ('teachers', 4),\n",
       " ('that', 4),\n",
       " ('of', 4),\n",
       " ('it', 2),\n",
       " ('at', 2),\n",
       " ('as', 2),\n",
       " ('school', 2),\n",
       " ('my', 2),\n",
       " ('in', 2),\n",
       " ('me', 2),\n",
       " ('students', 2),\n",
       " ('their', 2),\n",
       " ('student', 2),\n",
       " ('cartoon', 1),\n",
       " ('comedy', 1),\n",
       " ('ran', 1),\n",
       " ('same', 1),\n",
       " ('time', 1),\n",
       " ('some', 1),\n",
       " ('other', 1),\n",
       " ('programs', 1),\n",
       " ('about', 1),\n",
       " ('life', 1),\n",
       " ('such', 1),\n",
       " ('years', 1),\n",
       " ('teaching', 1),\n",
       " ('profession', 1),\n",
       " ('lead', 1),\n",
       " ('believe', 1),\n",
       " ('s', 1),\n",
       " ('satire', 1),\n",
       " ('much', 1),\n",
       " ('closer', 1),\n",
       " ('reality', 1),\n",
       " ('than', 1),\n",
       " ('scramble', 1),\n",
       " ('survive', 1),\n",
       " ('financially', 1),\n",
       " ('insightful', 1),\n",
       " ('who', 1),\n",
       " ('can', 1),\n",
       " ('see', 1),\n",
       " ('right', 1),\n",
       " ('through', 1),\n",
       " ('pathetic', 1),\n",
       " ('pomp', 1),\n",
       " ('pettiness', 1),\n",
       " ('whole', 1),\n",
       " ('situation', 1),\n",
       " ('all', 1),\n",
       " ('remind', 1),\n",
       " ('schools', 1),\n",
       " ('knew', 1),\n",
       " ('and', 1),\n",
       " ('when', 1),\n",
       " ('saw', 1),\n",
       " ('episode', 1),\n",
       " ('which', 1),\n",
       " ('repeatedly', 1),\n",
       " ('tried', 1),\n",
       " ('burn', 1),\n",
       " ('down', 1),\n",
       " ('immediately', 1),\n",
       " ('recalled', 1),\n",
       " ('classic', 1),\n",
       " ('line', 1),\n",
       " ('inspector', 1),\n",
       " ('m', 1),\n",
       " ('here', 1),\n",
       " ('sack', 1),\n",
       " ('one', 1),\n",
       " ('your', 1),\n",
       " ('welcome', 1),\n",
       " ('expect', 1),\n",
       " ('many', 1),\n",
       " ('adults', 1),\n",
       " ('age', 1),\n",
       " ('think', 1),\n",
       " ('far', 1),\n",
       " ('fetched', 1),\n",
       " ('what', 1),\n",
       " ('pity', 1),\n",
       " ('isn', 1),\n",
       " ('t', 1)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many period is in the review\n",
    "review_counter = Counter()\n",
    "for word in reviews_clean[0].split(\" \"):\n",
    "    review_counter[word] += 1\n",
    "review_counter.most_common()\n",
    "# The result below shows the dominant word has nothing to do\n",
    "# with the sentiment, the weighting has a dominant effect on the hidden layer\n",
    "# the count weighs heavily on the noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Noise in the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Let's tweak our network from before to model these phenomena\n",
    "class SentimentNetwork_2:\n",
    "    def __init__(self, reviews,labels,hidden_nodes = 10, learning_rate = 0.1):\n",
    "       \n",
    "        # set our random number generator \n",
    "        np.random.seed(1)\n",
    "    \n",
    "        self.pre_process_data(reviews, labels)\n",
    "        \n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "        \n",
    "        \n",
    "    def pre_process_data(self, reviews, labels):\n",
    "        \n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                review_vocab.add(word)\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "         \n",
    "        \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "    \n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "    \n",
    "        \n",
    "    def update_input_layer(self,review):\n",
    "\n",
    "        # clear out previous state, reset the layer to be all 0s\n",
    "        self.layer_0 *= 0\n",
    "        for word in review.split(\" \"):\n",
    "            if(word in self.word2index.keys()):\n",
    "                self.layer_0[0][self.word2index[word]] = 1\n",
    "        # While update layers, do not increment, change the counts to binary\n",
    "        # eliminate neural noises\n",
    "        \n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'positive'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def train(self, training_reviews, training_labels):\n",
    "        \n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        correct_so_far = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            #### Implement the forward pass here ####\n",
    "            ### Forward pass ###\n",
    "\n",
    "            # Input Layer\n",
    "            self.update_input_layer(review)\n",
    "\n",
    "            # Hidden layer\n",
    "            layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "            # Output layer\n",
    "            layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "\n",
    "            #### Implement the backward pass here ####\n",
    "            ### Backward pass ###\n",
    "\n",
    "            # TODO: Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # TODO: Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) # errors propagated to the hidden layer\n",
    "            layer_1_delta = layer_1_error # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "\n",
    "            # TODO: Update the weights\n",
    "            self.weights_1_2 -= layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "            self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
    "\n",
    "            if(np.abs(layer_2_error) < 0.5):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \n",
    "        correct = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                            + \"% #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \n",
    "        # Input Layer\n",
    "        self.update_input_layer(review.lower())\n",
    "\n",
    "        # Hidden layer\n",
    "        layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        if(layer_2[0] > 0.5):\n",
    "            return \"positive\"\n",
    "        else:\n",
    "            return \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_2 = SentimentNetwork_2(reviews_clean[:-1000], labels_clean[:-1000], learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n",
      "Progress:10.4% Speed(reviews/sec):130.3 #Correct:1768 #Trained:2501 Training Accuracy:70.6%\n",
      "Progress:20.8% Speed(reviews/sec):130.2 #Correct:3755 #Trained:5001 Training Accuracy:75.0%\n",
      "Progress:21.9% Speed(reviews/sec):130.2 #Correct:3980 #Trained:5267 Training Accuracy:75.5%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-9f357b6ebc51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews_clean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_clean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;31m#Significant improvement after removing noise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;31m#But the training speed seems really slow a.k.a inefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-87e087a17398>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_reviews, training_labels)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[1;31m# TODO: Update the weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights_1_2\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlayer_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_2_delta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;31m# update hidden-to-output weights with gradient descent step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights_0_1\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_1_delta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;31m# update input-to-hidden weights with gradient descent step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_2_error\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp_2.train(reviews_clean[:-1000], labels_clean[:-1000])\n",
    "#Significant improvement after removing noise\n",
    "#But the training speed seems really slow a.k.a inefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):831.0% #Correct:807 #Tested:1000 Testing Accuracy:80.7%"
     ]
    }
   ],
   "source": [
    "mlp_2.test(reviews_clean[-1000:], labels_clean[-1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inefficiency is caused by the large zeros input\n",
    "1. Only care about the non-zero input calculation in the neural network\n",
    "2. 1 multiplication is also wasting time\n",
    "\n",
    "## Increase code efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Let's tweak our network from before to model these phenomena\n",
    "class SentimentNetwork_3:\n",
    "    def __init__(self, reviews,labels,hidden_nodes = 10, learning_rate = 0.1):\n",
    "       \n",
    "        # set our random number generator \n",
    "        np.random.seed(1)\n",
    "    \n",
    "        self.pre_process_data(reviews, labels)\n",
    "        \n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "        \n",
    "        \n",
    "    def pre_process_data(self, reviews, labels):\n",
    "        \n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                review_vocab.add(word)\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "         \n",
    "        \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "    \n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "        self.layer_1 = np.zeros((1,hidden_nodes))\n",
    "        \n",
    "    def update_input_layer(self,review):\n",
    "\n",
    "        # clear out previous state, reset the layer to be all 0s\n",
    "        self.layer_0 *= 0\n",
    "        for word in review.split(\" \"):\n",
    "            if(word in self.word2index.keys()):\n",
    "                self.layer_0[0][self.word2index[word]] = 1\n",
    "        # While update layers, do not increment, change the counts to binary\n",
    "        # eliminate neural noises\n",
    "        \n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'positive'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def train(self, training_reviews_raw, training_labels):\n",
    "        \n",
    "        training_reviews = list()\n",
    "        \n",
    "        for review in training_reviews_raw:\n",
    "            indices = set()\n",
    "            for word in review.split(\" \"):\n",
    "                if(word in self.word2index.keys()):\n",
    "                    indices.add(self.word2index[word])\n",
    "            training_reviews.append(list(indices))\n",
    "        \n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        correct_so_far = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            #### Implement the forward pass here ####\n",
    "            ### Forward pass ###\n",
    "\n",
    "            # Input Layer\n",
    "            # Can completely skip generating input layer\n",
    "            # self.update_input_layer(review)\n",
    "\n",
    "            # Hidden layer\n",
    "            # layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "            self.layer_1 *= 0\n",
    "            for index in review:\n",
    "                self.layer_1 += self.weights_0_1[index]\n",
    "            \n",
    "            # Output layer\n",
    "            layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))\n",
    "\n",
    "            #### Implement the backward pass here ####\n",
    "            ### Backward pass ###\n",
    "\n",
    "            # TODO: Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # TODO: Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) # errors propagated to the hidden layer\n",
    "            layer_1_delta = layer_1_error # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "\n",
    "            # TODO: Update the weights\n",
    "            self.weights_1_2 -= self.layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "            #self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
    "            \n",
    "            for index in review:\n",
    "                self.weights_0_1[index] -= layer_1_delta[0] * self.learning_rate\n",
    "            \n",
    "            if(np.abs(layer_2_error) < 0.5):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \n",
    "        start = time.time()\n",
    "        correct = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start + 0.000001)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                            + \"% #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \n",
    "        # Input Layer\n",
    "        \n",
    "\n",
    "        # Hidden layer\n",
    "        self.layer_1 *= 0\n",
    "        unique_indices = set()\n",
    "        \n",
    "        for word in review.lower().split(\" \"):\n",
    "            if word in self.word2index.keys():\n",
    "                unique_indices.add(self.word2index[word])\n",
    "        for index in unique_indices:\n",
    "            self.layer_1 += self.weights_0_1[index]\n",
    "            \n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        if(layer_2[0] > 0.5):\n",
    "            return \"positive\"\n",
    "        else:\n",
    "            return \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp_3 = SentimentNetwork_3(reviews_clean[:-1000], labels_clean[:-1000], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n",
      "Progress:10.4% Speed(reviews/sec):1010. #Correct:1819 #Trained:2501 Training Accuracy:72.7%\n",
      "Progress:20.8% Speed(reviews/sec):963.1 #Correct:3825 #Trained:5001 Training Accuracy:76.4%\n",
      "Progress:31.2% Speed(reviews/sec):953.2 #Correct:5918 #Trained:7501 Training Accuracy:78.8%\n",
      "Progress:41.6% Speed(reviews/sec):960.2 #Correct:8048 #Trained:10001 Training Accuracy:80.4%\n",
      "Progress:52.0% Speed(reviews/sec):951.3 #Correct:10175 #Trained:12501 Training Accuracy:81.3%\n",
      "Progress:62.5% Speed(reviews/sec):949.1 #Correct:12300 #Trained:15001 Training Accuracy:81.9%\n",
      "Progress:72.9% Speed(reviews/sec):943.1 #Correct:14424 #Trained:17501 Training Accuracy:82.4%\n",
      "Progress:83.3% Speed(reviews/sec):939.2 #Correct:16606 #Trained:20001 Training Accuracy:83.0%\n",
      "Progress:93.7% Speed(reviews/sec):927.0 #Correct:18798 #Trained:22501 Training Accuracy:83.5%\n",
      "Progress:99.9% Speed(reviews/sec):928.3 #Correct:20120 #Trained:24000 Training Accuracy:83.8%"
     ]
    }
   ],
   "source": [
    "mlp_3.train(reviews_clean[:-1000], labels_clean[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):1389.% #Correct:848 #Tested:1000 Testing Accuracy:84.8%"
     ]
    }
   ],
   "source": [
    "mlp_3.test(reviews_clean[-1000:], labels_clean[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "# Let's tweak our network from before to model these phenomena\n",
    "class SentimentNetwork_3T:\n",
    "    def __init__(self, reviews,labels,hidden_nodes = 10, learning_rate = 0.1):\n",
    "       \n",
    "        np.random.seed(1)\n",
    "    \n",
    "        self.pre_process_data(reviews)\n",
    "        \n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "        \n",
    "        \n",
    "    def pre_process_data(self,reviews):\n",
    "        \n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                review_vocab.add(word)\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "         \n",
    "        \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "    \n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "        self.layer_1 = np.zeros((1,hidden_nodes))\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def update_input_layer(self,review):\n",
    "\n",
    "        # clear out previous state, reset the layer to be all 0s\n",
    "        self.layer_0 *= 0\n",
    "        for word in review.split(\" \"):\n",
    "            self.layer_0[0][self.word2index[word]] = 1\n",
    "\n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'positive'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def train(self, training_reviews_raw, training_labels):\n",
    "        \n",
    "        training_reviews = list()\n",
    "        for review in training_reviews_raw:\n",
    "            indices = set()\n",
    "            for word in review.split(\" \"):\n",
    "                if(word in self.word2index.keys()):\n",
    "                    indices.add(self.word2index[word])\n",
    "            training_reviews.append(list(indices))\n",
    "        \n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        correct_so_far = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            #### Implement the forward pass here ####\n",
    "            ### Forward pass ###\n",
    "\n",
    "            # Input Layer\n",
    "\n",
    "            # Hidden layer\n",
    "#             layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "            self.layer_1 *= 0\n",
    "            for index in review:\n",
    "                self.layer_1 += self.weights_0_1[index]\n",
    "            \n",
    "            # Output layer\n",
    "            layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))\n",
    "\n",
    "            #### Implement the backward pass here ####\n",
    "            ### Backward pass ###\n",
    "\n",
    "            # Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) # errors propagated to the hidden layer\n",
    "            layer_1_delta = layer_1_error # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "\n",
    "            # Update the weights\n",
    "            self.weights_1_2 -= self.layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "            \n",
    "            for index in review:\n",
    "                self.weights_0_1[index] -= layer_1_delta[0] * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
    "\n",
    "            if(np.abs(layer_2_error) < 0.5):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "        \n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \n",
    "        correct = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start + 0.0000001)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                            + \"% #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \n",
    "        # Input Layer\n",
    "\n",
    "\n",
    "        # Hidden layer\n",
    "        self.layer_1 *= 0\n",
    "        unique_indices = set()\n",
    "        for word in review.lower().split(\" \"):\n",
    "            if word in self.word2index.keys():\n",
    "                unique_indices.add(self.word2index[word])\n",
    "        for index in unique_indices:\n",
    "            self.layer_1 += self.weights_0_1[index]\n",
    "        \n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        if(layer_2[0] > 0.5):\n",
    "            return \"positive\"\n",
    "        else:\n",
    "            return \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_3_T = SentimentNetwork_3T(reviews_clean[:-1000], labels_clean[:-1000], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):937.4 #Correct:20120 #Trained:24000 Training Accuracy:83.8%"
     ]
    }
   ],
   "source": [
    "mlp_3_T.train(reviews_clean[:-1000], labels_clean[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):912.1 #Correct:43864 #Trained:48000 Training Accuracy:91.3%"
     ]
    }
   ],
   "source": [
    "mlp_3_T.train(reviews_clean[:-1000] * 2, labels_clean[:-1000] * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):1509.% #Correct:1728 #Tested:2000 Testing Accuracy:86.4%"
     ]
    }
   ],
   "source": [
    "mlp_3_T.test(reviews_clean[-1000:]*2, labels_clean[-1000:]*2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
